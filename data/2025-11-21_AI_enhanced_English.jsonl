{"id": "2511.15819", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15819", "abs": "https://arxiv.org/abs/2511.15819", "authors": ["Bohdan Liesnikov", "David Binder", "Tim S\u00fcberkr\u00fcb"], "title": "Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments", "comment": null, "summary": "The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.", "AI": {"tldr": "This paper introduces a type system and inference algorithm for implicit arguments in the Polarity language, which aims to symmetrically support both inductive and coinductive types. It provides detailed algorithms for reduction, conversion checking, and unification, with an initial implementation available. The work offers a template for other languages seeking similar extensibility.", "motivation": "The motivation of the paper arises from the limitations in dependently typed languages regarding extensibility. While these languages handle the addition of new operations to types well (via inductive types), adding new constructors (via coinductive types) is not as well-supported. The authors are motivated to address this asymmetry and provide richer language features, particularly implicit arguments, to a language (Polarity) that treats both extensions symmetrically.", "method": "The paper presents a detailed, algorithmic type system and an inference algorithm for handling implicit arguments in the Polarity language, while maintaining the language's core symmetry between inductive and coinductive types. It further provides formal rules for reduction semantics, conversion checking, and a unification algorithm tailored for pattern-matching on arbitrary inductive and coinductive types. These are essential steps towards a practical implementation.", "result": "The main results are (1) a full algorithmic description of the Polarity type system with support for implicit arguments and (2) a comprehensive unification algorithm for inductive and coinductive types. An initial working implementation is also available online. The work serves as a potential blueprint for other dependently typed languages aiming for symmetrical support of inductive and coinductive types.", "conclusion": "The paper concludes that their approach provides a practical and theoretically complete account of handling both inductive and coinductive types with implicit arguments in a dependently typed language. Their unification algorithm and design choices could guide future implementations seeking this symmetry."}}
{"id": "2511.15820", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15820", "abs": "https://arxiv.org/abs/2511.15820", "authors": ["Ashton Wiersdorf", "Ben Greenman"], "title": "Chorex: Restartable, Language-Integrated Choreographies", "comment": null, "summary": "We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.", "AI": {"tldr": "Chorex is a choreographic language for Elixir enabling robust distributed applications by tolerating actor failures through automatic process restart and state recovery. Implemented via metaprogramming for tight Elixir integration, it catches code mismatches statically, and its methods could be reused in other languages.", "motivation": "Building robust distributed applications in Elixir is challenging due to potential failures of actors during execution. Existing choreographic approaches lack resilience to such failures, and integrating choreographies tightly with host languages (like Elixir) remains a practical challenge.", "method": "The authors designed Chorex, a choreographic programming language for Elixir, that uses metaprogramming to create choreographies. Chorex automatically manages actor failures by spawning new processes and restoring state from checkpoints, updating the network configuration as needed. It reports implementation mismatches at the source code level, facilitating debugging and integration.", "result": "Chorex tolerates actor failures by automatic restart and state recovery. It provides static reporting of code mismatches, tight Elixir integration, and demonstrates its use in various examples. The paper also measures checkpointing overhead and proposes a projection strategy (outputting stateless function sets) potentially applicable to other languages.", "conclusion": "Chorex demonstrates that full-featured choreographic programming with robust actor failure handling is possible in Elixir via metaprogramming, achieving strong language integration and resilience. Its strategies offer potential foundations for similar approaches in other languages."}}
{"id": "2511.15821", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15821", "abs": "https://arxiv.org/abs/2511.15821", "authors": ["Fumika Mochizuki", "Tetsuro Yamazaki", "Shigeru Chiba"], "title": "BlueScript: A Disaggregated Virtual Machine for Microcontrollers", "comment": null, "summary": "Virtual machines (VMs) are highly beneficial for microcontroller development. \nIn particular, interactive programming environments greatly facilitate iterative development processes, \nand higher execution speeds expand the range of applications that can be developed. \nHowever, due to their limited memory size, microcontroller VMs provide a limited set of features. \nWidely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. \nWhile researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. \nIn this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. \nThis makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. \nAs an instance of a disaggregated VM, we design and implement a BlueScript VM. \nThe BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. \nWe offload most of the components of the BlueScript VM to a host machine. \nTo reduce communication overhead between the host machine and the microcontroller,  \nwe employed a data structure called a shadow machine on the host machine, \nwhich mirrors the execution state of the microcontroller. \nThrough our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  \nWe assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  \nwhile keeping interactivity comparable with MicroPython.  \nIn addition, our experiments observe that the offloaded dynamic compiler improves VM performance. \nThrough this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.", "AI": {"tldr": "The paper proposes a disaggregated VM system for microcontrollers that offloads components to a host machine, enabling rich, interactive, and fast virtual machines even on memory-limited devices. Experiments show improved speed and comparable interactivity over leading microcontroller VMs.", "motivation": "Microcontroller-based virtual machines (VMs) are limited by small memory, restricting features, interactivity, and execution speed. Traditional solutions offer either responsiveness or performance, but rarely both, and offloading VM components has been limited in scope.", "method": "The authors propose and implement a disaggregated VM architecture for microcontrollers, offloading as many VM components as possible to a powerful host machine. They introduce BlueScript VM as an instantiation, using a 'shadow machine' data structure to synchronize the microcontroller's execution state with the host to minimize communication overhead. They conduct experiments comparing execution speed and interactivity with existing solutions like MicroPython and Espruino.", "result": "Experiments show that the offloaded incremental compiler yields faster execution than MicroPython and Espruino and achieves interactivity similar to MicroPython. The offloaded dynamic compiler further boosts VM performance, demonstrating that rich features can be provided to memory-limited microcontrollers without significant drawbacks.", "conclusion": "Offloading extensive VM components to a host machine via the proposed disaggregated VM architecture enables memory-constrained microcontrollers to support feature-rich, interactive, and speedy VMs. This is achieved without sacrificing the advantages of microcontroller development environments."}}
{"id": "2511.16080", "categories": ["cs.PL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16080", "abs": "https://arxiv.org/abs/2511.16080", "authors": ["Sungbin Moon", "Jiho Park", "Suyoung Hwang", "Donghyun Koh", "Seunghyun Moon", "Minhyeong Lee"], "title": "Operon: Incremental Construction of Ragged Data via Named Dimensions", "comment": null, "summary": "Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.", "AI": {"tldr": "Operon is a new Rust-based workflow engine that natively tracks variable-shaped (ragged) data and dependencies. It gives users flexible, checked pipeline construction and handles workload scaling far more efficiently than older engines, making it ideal for complex data generation in machine learning and similar fields.", "motivation": "Modern data workflows often work with 'ragged data'\u2014collections where elements have variable lengths, common in areas like NLP and scientific data. Existing workflow engines do not handle these data shapes and dependencies natively, making users manage complex tracking and bookkeeping.", "method": "The authors introduce Operon, a Rust-based workflow engine utilizing a novel named-dimension formalism with explicit dependency relations. Users specify pipelines with annotations checked at compile time; the engine incrementally discovers and schedules tasks according to evolving data shapes, with a mathematically formalized, deterministic, and confluent algorithm. Operon features robust persistence, recovery via explicit partial state modeling, and a multi-queue architecture for efficient parallelism.", "result": "Operon significantly reduces baseline overhead (by 14.94x) compared to an existing workflow engine. It also maintains near-linear performance scaling as workloads grow, especially for large-scale machine learning data generation pipelines.", "conclusion": "Operon represents a major step forward in natively handling ragged data workflows. Its formal framework, static correctness guarantees, and efficient execution make it well-suited for modern large-scale, heterogeneous data pipelines\u2014outperforming current solutions."}}
{"id": "2511.15733", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15733", "abs": "https://arxiv.org/abs/2511.15733", "authors": ["Eitan Farchi", "Kiran Nayak", "Papia Ghosh Majumdar", "Saritha Route"], "title": "Technique to Baseline QE Artefact Generation Aligned to Quality Metrics", "comment": null, "summary": "Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.", "AI": {"tldr": "The paper presents a robust technique for evaluating QE artefacts generated by LLMs using systematic metrics, reverse generation, and rubric-guided refinement, delivering validated, high-quality outputs in both low- and high-quality project contexts.", "motivation": "LLMs have revolutionized QE by automating artefact generation, but the challenge is to ensure the quality of these outputs.", "method": "The paper introduces a systematic framework that includes LLM-driven generation, reverse generation, and iterative refinement guided by rubrics to assess artefact quality on clarity, completeness, consistency, and testability.", "result": "Experiments across 12 projects show reverse-generated artefacts often outperform low-quality inputs and retain high quality for strong inputs.", "conclusion": "The proposed framework offers scalable, reliable validation for QE artefacts, effectively combining automation with accountability."}}
{"id": "2511.15757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15757", "abs": "https://arxiv.org/abs/2511.15757", "authors": ["Kareem Shehada", "Yifan Wu", "Wyatt D. Feng", "Adithya Iyer", "Gryphon Kumfert", "Yangruibo Ding", "Zhiyun Qian"], "title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling", "summary": "Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.", "AI": {"tldr": "This paper presents RGym, a new open-source APR framework for the Linux kernel, enabling efficient and affordable bug fixing using LLMs on standard hardware. The approach yields substantially better success rates and insights into debuggability factors, lowering the barrier for kernel bug repair research.", "motivation": "Existing automated program repair (APR) benchmarks focus mainly on userspace applications and neglect kernel-space, which presents unique challenges due to concurrency, low-level hardware interactions, and monolithic structure. Prior kernel APR efforts are either ineffective or resource-intensive, requiring expensive infrastructures.", "method": "The authors introduce RGym, a lightweight and platform-agnostic APR evaluation framework tailored for the Linux kernel, designed for local, commodity hardware. They propose a pipeline using specialized bug localization via call stacks and blamed commits, avoiding reliance on unrealistic oracles.", "result": "On a filtered dataset of 143 bugs, the proposed method achieves up to a 43.36% repair pass rate with GPT-5 Thinking, at a cost under $0.20 per bug. An ablation study shows localization techniques, prompt structure, and model choice all contribute to success, with feedback-based retries notably improving outcomes.", "conclusion": "RGym provides an effective and cost-efficient solution for Linux kernel APR, demonstrating significant improvements over prior methods and offering practical accessibility for research and development."}}
{"id": "2511.15817", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15817", "abs": "https://arxiv.org/abs/2511.15817", "authors": ["Alejandro Velasco", "Daniel Rodriguez-Cardenas", "Dipin Khati", "David N. Palacio", "Luftar Rahman Alif", "Denys Poshyvanyk"], "title": "A Causal Perspective on Measuring, Explaining and Mitigating Smells in \\llm-Generated Code", "comment": null, "summary": "Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.\n  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.", "AI": {"tldr": "The paper introduces a probabilistic metric (PSC) to measure and analyze code smell tendencies in LLM-generated code, finding that prompt and architecture choices greatly impact code quality. The metric helps both mitigation and developer assessment, paving the way for quality-focused LLM evaluations.", "motivation": "Large language models (LLMs) are increasingly used in software engineering, but they often generate code with structural issues, known as code smells, which hinder code quality. There is limited understanding of how and when these code smells appear in LLM-generated code.", "method": "The authors utilize the Propensity Smelly Score (PSC), a probabilistic metric for estimating the likelihood of different code smell types in generated code. They employ PSC for causal analysis to investigate how various factors\u2014generation strategy, model size, model architecture, and prompt design\u2014impact code smell propensity. The robustness of PSC as a quality signal is validated, and its practical effectiveness is assessed through a user study.", "result": "Prompt design and model architecture significantly influence the likelihood of code smells in LLM-generated code. Practical mitigation strategies informed by these insights can reduce code smell occurrence. The user study shows that PSC aids developers in interpreting model behavior and judging code quality.", "conclusion": "PSC is a robust metric for structural quality in code generated by LLMs. Integrating smell propensity signals like PSC can help developers evaluate and improve code quality, and guide the future deployment of LLMs in software engineering by making them more quality-aware."}}
{"id": "2511.15852", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15852", "abs": "https://arxiv.org/abs/2511.15852", "authors": ["Monu Sharma"], "title": "AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises", "comment": "10 Pages, 6 figures , 2 Tables", "summary": "The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.\n  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.\n  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.", "AI": {"tldr": "Integrating AI-driven, event-based workflow orchestration into Workday ERP systems significantly improves efficiency and adaptability in healthcare operations, setting a benchmark for next-gen intelligent ERP automation.", "motivation": "Healthcare operations have become increasingly complex and data-driven, yet traditional ERP systems lack the adaptability to manage dynamic, event-driven scenarios typical in healthcare environments. This paper seeks to address the need for more intelligent, responsive workflow orchestration within ERP systems to better support healthcare organizations.", "method": "The study designs and proposes an AI-enabled, event-driven orchestration framework within the Workday ERP platform. This framework integrates machine-learning triggers, anomaly detection, and process mining analytics to synchronize financial and supply-chain workflows. A multi-organization case analysis is used to evaluate the framework's performance and impact.", "result": "The adoption of the AI-enabled orchestration framework resulted in measurable improvements in process efficiency, cost visibility, and decision accuracy across multiple healthcare organizations. The framework also improved operational resilience, governance, and system scalability.", "conclusion": "Embedding AI-powered orchestration capabilities into Workday's ERP enhances its ability to manage event-driven healthcare operations, providing a scalable, resilient, and intelligent solution for modern healthcare enterprises. This model serves as a reference for future intelligent ERP automation strategies."}}
{"id": "2511.15859", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15859", "abs": "https://arxiv.org/abs/2511.15859", "authors": ["Hina Saeeda", "Mazen Mohamad", "Eric Knauss", "Jennifer Horkoff", "Ali Nouri"], "title": "RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems", "comment": null, "summary": "High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.", "AI": {"tldr": "This paper investigates the challenges and solutions for data annotation requirements in autonomous driving AI systems through industry and research interviews. It identifies key challenges and best practices, highlights the impact on system reliability and regulatory compliance, and offers practical guidance to improve annotation quality and bridge the gap between requirements engineering and AI development.", "motivation": "The motivation for this paper is to address the underexplored issues surrounding the formulation and management of data annotation requirements in AI-enabled perception systems for autonomous driving. The authors highlight the crucial role of high-quality annotation requirements in reducing bias, enhancing system performance, and mitigating safety and regulatory risks. However, inconsistencies in current practices create challenges in ensuring reliable and safe AI systems.", "method": "The study employs semi-structured interviews with 19 participants from six international companies and four research organisations. Thematic analysis is used to distill main challenges and recommended practices from both industry and research perspectives.", "result": "The results reveal five key challenges in annotation requirements: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints. The research also identifies three main categories of best practices: ethical compliance, improved guidelines, and embedded quality assurance. Additionally, the study illustrates critical interrelationships between annotation requirements, annotation practices, data quality, and the performance of AI-enabled perception systems, showing how flaws can propagate through the development pipeline.", "conclusion": "This paper is the first to offer empirically grounded, actionable guidance for improving annotation requirements. It significantly enhances understanding of how to improve annotation quality, meet regulatory standards, and increase system reliability in autonomous driving AI. The work also bridges gaps between requirements engineering and AI, contributing to both software engineering and AI requirement fields."}}
{"id": "2511.16004", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16004", "abs": "https://arxiv.org/abs/2511.16004", "authors": ["KeFan Li", "Mengfei Wang", "Hengzhi Zhang", "Zhichao Li", "Yuan Yuan", "Mu Li", "Xiang Gao", "Hailong Sun", "Chunming Hu", "Weifeng Lv"], "title": "InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution", "comment": null, "summary": "Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.", "AI": {"tldr": "InfCode is a new adversarial multi-agent framework for automatic software issue resolution. It refines code and test patches through agent interactions and robust verification in realistic environments, outperforming previous methods and setting new benchmarks on SWE-bench datasets.", "motivation": "Existing methods for automated software issue resolution often rely on weak tests, resulting in patches that pass verification but fail to actually resolve code defects. Real-world issues require deeper repository-level analysis and stronger verification.", "method": "InfCode introduces an adversarial multi-agent framework consisting of a Test Patch Generator, Code Patch Generator, and Selector agent. The agents iteratively refine tests and patches through adversarial interactions in a containerized environment, enabling realistic inspection, modification, and validation.", "result": "InfCode outperforms strong baselines on SWE-bench Lite and SWE-bench Verified datasets, achieving 79.4% on SWE-bench Verified and setting a new state-of-the-art.", "conclusion": "InfCode significantly improves automated repository-level issue resolution by combining adversarial multi-agent interaction and strong verification signals, leading to more reliable software fixes. The framework is released as open-source for community use."}}
{"id": "2511.16005", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16005", "abs": "https://arxiv.org/abs/2511.16005", "authors": ["Qingao Dong", "Mengfei Wang", "Hengzhi Zhang", "Zhichao Li", "Yuan Yuan", "Mu Li", "Xiang Gao", "Hailong Sun", "Chunming Hu", "Weifeng Lv"], "title": "InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution", "comment": null, "summary": "Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \\texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.", "AI": {"tldr": "Most LLM agents work well for Python but fail on C++. INFCODE-C++ uses smarter semantic and structural code retrieval to fix C++ issues much better, setting a new benchmark and proving the need for language-aware approaches.", "motivation": "Current LLM-based agents excel at resolving issues in Python codebases but struggle with C++ due to its complexity, such as overloaded identifiers, templates, and deep control flow. Existing methods relying on lexical retrieval do not adapt well to the unique challenges of C++.", "method": "INFCODE-C++ combines semantic code-intent retrieval and deterministic AST-structured querying to build accurate, language-aware context for repairing C++ code. These mechanisms enable precise localization and patch synthesis.", "result": "INFCODE-C++ achieves a 25.58% issue resolution rate on the MultiSWE-bench-CPP benchmark, outperforming previous agents by 10.85 percentage points and doubling MSWE-agent's performance. Ablation and behavioral studies confirm the necessity of its core components.", "conclusion": "Semantic and structural code retrieval are critical for successful autonomous issue resolution in complex, statically typed languages like C++. INFCODE-C++ sets a new standard for multi-language LLM agents and opens up future research directions."}}
{"id": "2511.16092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16092", "abs": "https://arxiv.org/abs/2511.16092", "authors": ["Xing Hu", "Raula Gaikovina Kula", "Christoph Treude"], "title": "The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report", "AI": {"tldr": "Experts from multiple domains met to discuss how GenAI is changing the landscape of IDEs, focusing on its opportunities and the challenges it presents for software development workflows.", "motivation": "GenAI is transforming software development by automating tasks like code generation and review, raising questions about its integration and impact within IDEs.", "method": "33 experts from Software Engineering, AI, and HCI convened at a dedicated meeting to discuss and analyze challenges and opportunities presented by GenAI in IDEs.", "result": "Key challenges and opportunities related to GenAI's integration into IDEs were identified and debated by domain experts.", "conclusion": "GenAI holds promise for revolutionizing human-AI interaction in IDEs, but careful consideration of its challenges and potential is necessary."}}
{"id": "2511.16123", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16123", "abs": "https://arxiv.org/abs/2511.16123", "authors": ["Linyi Han", "Shidong Pan", "Zhenchang Xing", "Sofonias Yitagesu", "Xiaowang Zhang", "Zhiyong Feng", "Jiamou Sun", "Qing Huang"], "title": "Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions", "comment": null, "summary": "Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.", "AI": {"tldr": "The paper proposes an LLM-based, domain-constrained three-stage framework for unifying and improving textual vulnerability descriptions from multiple sources, raising synthesis accuracy and usability with measurable gains in performance and human comprehension.", "motivation": "Textual vulnerability descriptions (TVDs) are essential for security analysts, but inconsistencies between sources make them hard to interpret and use effectively. Existing solutions lose valuable information and fail to create unified representations.", "method": "The paper introduces a domain-constrained large language model (LLM)-based synthesis framework with three stages: extraction (using rule-based templates), self-evaluation (using anchor words to measure semantic variability), and fusion (using information entropy to resolve inconsistencies and prioritize relevant information). It also presents Digest Labels, a visualization tool for TVDs.", "result": "The proposed framework improves synthesis performance, demonstrated by an increase in the F1 score for key aspect augmentation from 0.82 to 0.87, and enhances comprehension and efficiency by over 30%. Human evaluations show that Digest Labels significantly improve usability.", "conclusion": "The domain-constrained LLM-based synthesis framework effectively unifies key aspects of TVDs and improves their practical usability and richness, addressing the issue of inconsistencies without losing important information."}}
{"id": "2511.16224", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16224", "abs": "https://arxiv.org/abs/2511.16224", "authors": ["Francesco Salzano", "Simone Scalabrino", "Rocco Oliveto", "Simone Scalabrino"], "title": "Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts", "comment": "20 pages", "summary": "Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.", "AI": {"tldr": "LLMs can generate smart contract code with structure similar to existing implementations, but these often miss key functional requirements. Retrieval-Augmented Generation greatly improves correctness, yet expert review is still critical for production use due to persistent limitations.", "motivation": "The motivation of this paper arises from the growing importance of Smart Contracts in blockchain ecosystems and the increasing use of LLMs (Large Language Models) for code generation. However, Smart Contracts have unique requirements like gas efficiency, security, and determinism, which are not commonly addressed in typical code generation evaluations. Previous studies haven't systematically analyzed both functional and non-functional aspects of LLM-generated Solidity code.", "method": "The authors benchmark four state-of-the-art language models under zero-shot and retrieval-augmented generation (RAG) scenarios. They conduct experiments on 500 real-world smart contract functions and assess the results using a range of metrics: code similarity, semantic embeddings, automated test execution, gas consumption profiling, and both cognitive and cyclomatic complexity analysis.", "result": "LLMs produce Solidity code with high semantic similarity to reference contracts, but functional correctness is notably low (20%\u201326% in zero-shot mode). The models often generate simpler code with lower complexity and gas consumption, primarily because they omit important validation logic. Retrieval-Augmented Generation (RAG) significantly increases functional correctness (up to 45%) and produces more concise, efficient code.", "conclusion": "Despite improvements with RAG, there is a substantial gap between semantic similarity and true functional correctness in LLM-generated smart contracts. Achieving production-ready, reliable code with LLMs remains challenging, and expert validation is essential for deployment."}}
{"id": "2511.16410", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16410", "abs": "https://arxiv.org/abs/2511.16410", "authors": ["Hina Saeeda", "Tommy Johansson", "Mazen Mohamad", "Eric Knauss"], "title": "Data Annotation Quality Problems in AI-Enabled Perception System Development", "comment": null, "summary": "Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.", "AI": {"tldr": "This paper presents an empirically validated taxonomy of 18 annotation error types affecting AI data quality for automated driving, based on interviews and thematic analysis across multiple organisations. It offers practical tools and guidance for diagnosing, preventing, and addressing data annotation issues in industry supply chains.", "motivation": "Annotation errors significantly impact the reliability and safety of automated driving systems, yet there is a lack of empirical understanding of how these errors arise and propagate within the industry's supply chain.", "method": "A multi-organisation case study was conducted with six companies and four research institutes across Europe and the UK, using 19 semi-structured interviews with 20 experts and six-phase thematic analysis to create and validate the taxonomy.", "result": "Developed and industry-validated a comprehensive taxonomy of 18 recurring annotation error types under completeness, accuracy, and consistency dimensions, and confirmed its usefulness for root cause analysis, supplier reviews, onboarding, and guideline improvements.", "conclusion": "The study provides a validated taxonomy of annotation error types affecting AI-enabled perception systems in automated driving, delivering a shared vocabulary and practical guidance to improve data quality across the automotive supply chain."}}
{"id": "2511.16593", "categories": ["cs.SE", "cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.16593", "abs": "https://arxiv.org/abs/2511.16593", "authors": ["Diaeddin Rimawi"], "title": "Green Resilience of Cyber-Physical Systems: Doctoral Dissertation", "comment": null, "summary": "Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.", "AI": {"tldr": "The paper introduces the GResilience framework to enable OL-CAIS to recover from disruptions by optimizing both resilience and eco-friendliness. It combines multi-objective optimization, game theory, and reinforcement learning. Empirical results show improved recovery, steady performance, less human input, and reduced emissions with containerization. The work offers tools for balancing robust recovery and green operation in collaborative AI.", "motivation": "Online Collaborative AI Systems (OL-CAIS), as a form of cyber-physical systems involving human collaboration, can suffer performance degradation from disruptive events. Decision-makers must restore system performance while minimizing energy consumption, creating a challenge to balance resilience with environmental sustainability.", "method": "The study proposes the GResilience framework for OL-CAIS. It includes multi-objective optimization for single-agent scenarios, game-theoretic approaches for two-agent cases, and reinforcement learning for RL-agents. The framework models system behavior across steady, disruptive, and final states, and introduces measurement tools for resilience and greenness. Empirical validation involves real and simulated experiments with a collaborative robot performing object classification in partnership with humans.", "result": "The resilience model accurately tracks performance changes during disruptions. GResilience policies promote faster green recovery, greater performance stability, and less human intervention. RL-agent policies result in the best overall performance, slightly increasing CO2 emissions. Catastrophic forgetting is observed but mitigated by the proposed strategies. Containerization reduces CO2 emissions by half compared to standard execution.", "conclusion": "This research provides novel models, metrics, and recovery strategies that help OL-CAIS recover from disruptions in a manner that balances resilience with greenness, while addressing performance consistency and energy efficiency. The approaches are empirically validated and show promise in real-world collaborative AI scenarios."}}
