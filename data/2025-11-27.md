<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [DUALGUAGE: Automated Joint Security-Functionality Benchmarking for Secure Code Generation](https://arxiv.org/abs/2511.20709)
*Abhijeet Pathak,Suvadra Barua,Dinesh Gudimetla,Rupam Patir,Jiawei Guo,Hongxin Hu,Haipeng Cai*

Main category: cs.SE

TL;DR: The paper introduces DUALGAUGE, a new automated framework and dataset for rigorously assessing both security and correctness in code generated by large language models, revealing substantial shortcomings in existing models and offering tools to drive future improvement.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks for secure code generation by LLMs often fail to jointly evaluate both security and functional correctness, leading to incomplete measures of real-world code safety and effectiveness.

Method: The authors introduce DUALGAUGE, an automated benchmarking framework for simultaneous assessment of security and correctness in LLM-generated code, and DUALGAUGE-BENCH, a new curated benchmark suite featuring coding tasks with validated test suites for security and functionality.

Result: DUALGAUGE was used to evaluate ten leading LLMs across thousands of test scenarios. The results showed significant gaps in the ability of these models to generate code that is both correct and secure.

Conclusion: The DUALGAUGE framework and benchmark suite address the limitations of previous evaluation tools and datasets, providing a reproducible, scalable way to jointly measure security and correctness. This work serves to accelerate advances in secure code generation by LLMs.

Abstract: Large language models (LLMs) and autonomous coding agents are increasingly used to generate software across a wide range of domains. Yet a core requirement remains unmet: ensuring that generated code is secure without compromising its functional correctness. Existing benchmarks and evaluations for secure code generation fall short-many measure only vulnerability reduction, disregard correctness preservation, or evaluate security and functionality on separate datasets, violating the fundamental need for simultaneous joint evaluation. We present DUALGAUGE, the first fully automated benchmarking framework designed to rigorously evaluate the security and correctness of LLM-generated code in unison. Given the lack of datasets enabling joint evaluation of secure code generation, we also present DUALGAUGE-BENCH, a curated benchmark suite of diverse coding tasks, each paired with manually validated test suites for both security and functionality, designed for full coverage of specification requirements. At the core of DUALGAUGE is an agentic program executor, which runs a program against given tests in sandboxed environments, and an LLM-based evaluator, which assesses both correctness and vulnerability behavior against expected outcomes. We rigorously evaluated and ensured the quality of DUALGAUGE-BENCH and the accuracy of DUALGAUGE, and applied DUALGAUGE to benchmarking ten leading LLMs on DUALGAUGE-BENCH across thousands of test scenarios. Our results reveal critical gaps in correct and secure code generation by these LLMs, for which our open-source system and datasets help accelerate progress via reproducible, scalable, and rigorous evaluation.

</details>


### [2] [Data-Driven Methods and AI in Engineering Design: A Systematic Literature Review Focusing on Challenges and Opportunities](https://arxiv.org/abs/2511.20730)
*Nehal Afifi,Christoph Wittig,Lukas Paehler,Andreas Lindenmann,Kai Wolter,Felix Leitenberger,Melih Dogru,Patric Grauberger,Tobias Düser,Albert Albers,Sven Matthiesen*

Main category: cs.SE

TL;DR: The paper reviews how data-driven methods are used in engineering design, noting fragmentation, dominance of ML/statistics, growing deep learning use, and key challenges around interpretability and validation. It calls for clearer guidelines and future work linking computing methods to design tasks.


<details>
  <summary>Details</summary>
Motivation: Data-driven methods (DDMs) are increasingly used in product development due to more available data and better computational tools. However, their adoption is fragmented because there's uncertainty about which DDMs to use, at what stage, and for which applications. This presents a need for clarity and guidance.

Method: The paper conducts a PRISMA systematic literature review using the V-model of product development, dividing the process into four stages. Literature from 2014-2024 is collected from Scopus, Web of Science, and IEEE Xplore. A total of 1,689 records are screened, and 114 are comprehensively analyzed.

Result: Machine learning and statistical methods are the most commonly used DDMs in product development. Deep learning has less adoption but is growing. Methods like supervised learning, clustering, regression, and surrogate modeling are widely used in the earlier and middle stages of development, but less so in validation. Key challenges include lack of interpretability, poor traceability between stages, and inadequate real-world validation.

Conclusion: There are significant knowledge gaps and challenges in the application of DDMs across the product lifecycle, particularly in interpretability and validation. The review highlights the need for guidelines and interpretable, hybrid models, and suggests future work to map specific algorithms to engineering problems and activities.

Abstract: The increasing availability of data and advancements in computational intelligence have accelerated the adoption of data-driven methods (DDMs) in product development. However, their integration into product development remains fragmented. This fragmentation stems from uncertainty, particularly the lack of clarity on what types of DDMs to use and when to employ them across the product development lifecycle. To address this, a necessary first step is to investigate the usage of DDM in engineering design by identifying which methods are being used, at which development stages, and for what application. This paper presents a PRISMA systematic literature review. The V-model as a product development framework was adopted and simplified into four stages: system design, system implementation, system integration, and validation. A structured search across Scopus, Web of Science, and IEEE Xplore (2014--2024) retrieved 1{,}689 records. After screening, 114 publications underwent full-text analysis. Findings show that machine learning (ML) and statistical methods dominate current practice, whereas deep learning (DL), though still less common, exhibits a clear upward trend in adoption. Additionally, supervised learning, clustering, regression analysis, and surrogate modeling are prevalent in design, implementation, and integration system stages but contributions to validation remain limited. Key challenges in existing applications include limited model interpretability, poor cross-stage traceability, and insufficient validation under real-world conditions. Additionally, it highlights key limitations and opportunities such as the need for interpretable hybrid models. This review is a first step toward design-stage guidelines; a follow-up synthesis should map computer science algorithms to engineering design problems and activities.

</details>


### [3] [Train While You Fight -- Technical Requirements for Advanced Distributed Learning Platforms](https://arxiv.org/abs/2511.20813)
*Simon Hacks*

Main category: cs.SE

TL;DR: This paper analyzes how distributed learning platforms can support real-time, operation-embedded training (TWYF). By identifying seven technical challenges and matching them to established software engineering patterns—using NATO guidance and a German military case—the authors show how robust, scalable, and secure ADL solutions can be designed for continuous learning during missions.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the need to enable continuous learning (Train While You Fight) for personnel during actual operations, rather than restricting learning to before or after activities. This requires rethinking how advanced distributed learning (ADL) platforms are designed and operated to meet operational needs.

Method: The study uses a Design Science Research approach. Specifically, it involves (i) identifying challenges from NATO and PfPC documentation and current practice, (ii) defining objectives for technical solutions, and (iii) systematically mapping technical challenges to established software engineering patterns. A national case study from the German armed forces is used to illustrate the approach.

Result: Seven key technical challenges for ADL platforms are identified: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. The mapping of these challenges to proven software engineering design patterns is demonstrated with a real-world military case.

Conclusion: Existing software engineering patterns can be systematically mapped to the technical challenges faced by ADL platforms in supporting continuous in-operation learning. Addressing these challenges with appropriate design patterns can help realize TWYF in operational contexts, as shown by the German armed forces use case.

Abstract: "Train While You Fight" (TWYF) advocates for continuous learning that occurs during operations, not just before or after. This paper examines the technical requirements that advanced distributed learning (ADL) platforms must meet to support TWYF, and how existing software engineering patterns can fulfill these requirements. Using a Design Science Research approach, we (i) derive challenges from PfPC/NATO documentation and recent practice, (ii) define solution objectives, and (iii) conduct a systematic mapping from challenges to proven patterns. We identify seven technical challenges: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. We illustrate the patterns with a national use case from the German armed forces.

</details>


### [4] [Application of machine learning for infrastructure reconstruction programs management](https://arxiv.org/abs/2511.20916)
*Illia Khudiakov,Vladyslav Pliuhin,Sergiy Plankovskyy,Yevgen Tsegelnyk*

Main category: cs.SE

TL;DR: This article introduces an adaptive decision-making model using machine learning to optimize infrastructure program management. The system models program architecture and WBS, learns from historical data, and adapts workflows for specific engineering projects (e.g., heat, gas, electricity, water systems). Implementation and evaluation via Azure Machine Learning Studio show improved process efficiency and flexibility.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance the efficiency of managing engineering infrastructure reconstruction programs, particularly by improving the program architecture and work breakdown structure (WBS) through adaptive decision-making support.

Method: The authors analyze existing adaptive program management tools and justify the integration of infrastructure systems modeling. They review available models and select machine learning, specifically artificial neural networks, as the technical foundation. The development involves defining model components, system modeling, and value prediction using historical engineering data, with functional implementation in Microsoft Azure Machine Learning Studio.

Result: The paper presents an adaptive decision-making model, with defined parameters and implementation details. Evaluation results for neural network predictions are shown, and the model is demonstrated to be applicable across various infrastructure systems (heating, gas, electricity, water supply, drainage).

Conclusion: The adaptive decision-making support model, leveraging machine learning and neural networks, can improve program management efficiency for engineering infrastructure reconstruction by tailoring processes to specific project characteristics and goals.

Abstract: The purpose of this article is to describe an adaptive decision-making support model aimed at improving the efficiency of engineering infrastructure reconstruction program management in the context of developing the architecture and work breakdown structure of programs. As part of the study, the existing adaptive program management tools are analyzed, the use of infrastructure systems modelling tools is justified for program architecture and WBS creation. Existing models and modelling methods are viewed, and machine learning and artificial neural networks are selected for the model. The main components of the model are defined, which include a set of decision-maker preferences, decision-making tasks, sets of input data, and applied software components of the model. To support decision-making, the adaptive model applies the method of system modeling and predicting the value of the objective function at a given system configuration. Prediction is done using machine learning methods based on a dataset consisting of historical data related to existing engineering systems. The work describes the components of the redistribution of varied model parameters, which modify the model dataset based on the selected object type, which allows adapting the decision-making process to the existing program implementation goals. The functional composition done in Microsoft Azure Machine Learning Studio is described. The neural network parameters and evaluation results are given. The application of the developed adaptive model is possible in the management of programs for the reconstruction of such engineering systems as systems of heat, gas, electricity supply, water supply, and drainage, etc.

</details>


### [5] [Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code](https://arxiv.org/abs/2511.20933)
*Mootez Saad,Boqi Chen,José Antonio Hernández López,Dániel Varró,Tushar Sharma*

Main category: cs.SE

TL;DR: LLMs can help spot software design flaws under ideal conditions but struggle to reason about them autonomously when code is noisy or guidance is missing, limiting their practical reliability.


<details>
  <summary>Details</summary>
Motivation: Despite LLMs' increasing use in software engineering, it is unclear how robustly they understand key design principles like cohesion and coupling. The study aims to clarify these limitations for practical application.

Method: The authors conducted an empirical study using the DeepSeek-R1 model family. They programmatically generated poorly designed code and evaluated the models under different types of guidance and varying contextual noise, analyzing performance (e.g., F1 scores) and reasoning traces.

Result: Models perform well in optimal, guided conditions but fail significantly in noisy or open-ended tasks, especially regarding coupling. Resilience in cohesion analysis persists only in guided settings. When guidance is removed, performance drops for both concepts. Reasoning-trace analysis highlights cognitive shortcutting as a core failure mode.

Conclusion: LLMs show solid understanding of design concepts like cohesion and coupling in ideal, guided scenarios, but their capabilities deteriorate in realistic, noisy, and open-ended tasks. Their reasoning is asymmetric and often relies on shortcuts, especially for coupling.

Abstract: Large language models (LLMs) are being increasingly adopted in the software engineering domain, yet the robustness of their grasp on core software design concepts remains unclear. We conduct an empirical study to systematically evaluate their understanding of cohesion (intra-module) and coupling (inter-module). We programmatically generate poorly designed code fragments and test the DeepSeek-R1 model family ($14$B, $32$B, $70$B) under varying levels of guidance, from simple \textit{Verification} to \textit{Guided} and \textit{Open-ended Generation}, while varying contextual noise by injecting distractor elements. While models exhibit a solid baseline understanding of both concepts in ideal conditions, their practical knowledge is fragile and highly asymmetrical. Reasoning about coupling proves brittle; performance collapses in noisy, open-ended scenarios, with F1 scores dropping by over $50\%$. In contrast, the models' analysis of cohesion is remarkably robust to internal noise in guided tasks, showing little performance degradation. However, this resilience also fails when all guidance is removed. Reasoning-trace analysis confirms these failure modes, revealing \textit{cognitive shortcutting} for coupling versus a more exhaustive (yet still failing) analysis for cohesion. To summarize, while LLMs can provide reliable assistance for recognizing design flaws, their ability to reason autonomously in noisy, realistic contexts is limited, highlighting the critical need for more scalable and robust program understanding capabilities.

</details>


### [6] [SpaceX: Exploring metrics with the SPACE model for developer productivity](https://arxiv.org/abs/2511.20955)
*Sanchit Kaul,Kevin Nhu,Jason Eissayou,Ivan Eser,Victor Borup*

Main category: cs.SE

TL;DR: This paper uses the SPACE framework, advanced analytics, and sentiment analysis on open-source data to show that developer productivity is more complex than simple metrics suggest. Negative emotions can drive more commits, and social interaction patterns provide better insights than commit counts. The authors propose a new Composite Productivity Score for richer evaluation.


<details>
  <summary>Details</summary>
Motivation: There is a need to overcome the limitations of simple, single-dimensional productivity metrics in assessing developer effectiveness. The authors aim to create a more holistic assessment using the SPACE framework.

Method: The study mines open-source repository data and applies advanced statistical methods (GLMM) and RoBERTa (sentiment classification) to build a multi-faceted productivity metric. It also analyzes contributor interaction topology.

Result: Negative affective states are significantly correlated with higher commit frequency, suggesting frustration can drive more frequent code changes. Contributor interaction patterns better reflect collaborative dynamics than commit volume. A Composite Productivity Score (CPS) is proposed to capture developer efficacy more accurately.

Conclusion: Traditional single-dimensional productivity metrics are insufficient for assessing developer performance. A multi-dimensional, interaction and sentiment-aware approach offers deeper insight, as shown by the proposed CPS metric.

Abstract: This empirical investigation elucidates the limitations of deterministic, unidimensional productivity heuristics by operationalizing the SPACE framework through extensive repository mining. Utilizing a dataset derived from open-source repositories, the study employs rigorous statistical methodologies including Generalized Linear Mixed Models (GLMM) and RoBERTa-based sentiment classification to synthesize a holistic, multi-faceted productivity metric. Analytical results reveal a statistically significant positive correlation between negative affective states and commit frequency, implying a cycle of iterative remediation driven by frustration. Furthermore, the investigation has demonstrated that analyzing the topology of contributor interactions yields superior fidelity in mapping collaborative dynamics compared to traditional volume-based metrics. Ultimately, this research posits a Composite Productivity Score (CPS) to address the heterogeneity of developer efficacy.

</details>


### [7] [Lightweight Model Editing for LLMs to Correct Deprecated API Recommendations](https://arxiv.org/abs/2511.21022)
*Guancheng Lin,Xiao Yu,Jacky Keung,Xing Hu,Xin Xia,Alex X. Liu*

Main category: cs.SE

TL;DR: The paper introduces EDAPIBench and systematically studies 10 model editing methods for updating deprecated API knowledge in LLMs. It finds AdaLoRA works best but affects unrelated knowledge, and proposes AdaLoRA-L, a novel approach that restricts edits to API-specific layers, greatly improving editing specificity without sacrificing overall performance.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the challenge of outdated and deprecated API knowledge present in Large Language Models (LLMs) used for code completion, due to their training on stale datasets. Retraining full models is costly, and it's unclear if lightweight model editing can efficiently and effectively update deprecated APIs without unintended effects.

Method: The authors conduct a systematic study by evaluating 10 state-of-the-art model editing techniques on three code-focused LLMs (Qwen2.5-Coder, StarCoder2, DeepSeek-Coder), using a new benchmark, EDAPIBench, which targets over 70 deprecated APIs through 3,000+ editing instances. They further propose AdaLoRA-L, a novel technique that restricts edits to 'Specific API Layers' within LLMs, preserving general knowledge in 'Common API Layers.'

Result: Their study finds that AdaLoRA is the best at updating deprecated API knowledge but suffers from influencing unrelated model knowledge. The proposed AdaLoRA-L technique substantially improves specificity (affecting only intended API knowledge) while maintaining similar overall performance in generating up-to-date APIs.

Conclusion: AdaLoRA-L offers a promising solution for efficiently updating LLMs’ API knowledge in a targeted way, minimizing unintended side-effects while ensuring accurate and current code completions. The work provides both a systematic evaluation of model editing and a new benchmark (EDAPIBench) for future research.

Abstract: Pre-trained or fine-tuned on large code corpora, Large Language Models (LLMs) have demonstrated strong performance in code completion tasks. However, their embedded knowledge is constrained by the timeliness of training data, which often includes code using deprecated APIs. Consequently, LLMs frequently generate deprecated APIs that will no longer be supported in future versions of third-party libraries. While retraining LLMs on updated codebases could refresh their API knowledge, this approach is computationally expensive. Recently, lightweight model editing methods have emerged to efficiently correct specific knowledge in LLMs. However, it remains unclear whether these methods can effectively update deprecated API knowledge and enable edited models to generate up-to-date APIs. To address this gap, we conduct the first systematic study applying 10 state-of-the-art model editing techniques to update deprecated API knowledge in three LLMs: Qwen2.5-Coder, StarCoder2, and DeepSeek-Coder. We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances. Our results show that the parameter-efficient fine-tuning method AdaLoRA achieves the best performance in enabling edited models to generate correct, up-to-date APIs, but falls short in Specificity (i.e., the editing influences untargeted knowledge). To resolve this, we propose AdaLoRA-L, which defines "Common API Layers" (layers within the LLMs with high importance across all APIs, storing general knowledge and excluded from editing) and restricts edits exclusively to "Specific API Layers" (layers with high importance only for the target API, storing the API-specific knowledge). Experimental results demonstrate that AdaLoRA-L significantly improves Specificity while maintaining comparable performance across other evaluation metrics.

</details>


### [8] [Exploring Hidden Geographic Disparities in Android Apps](https://arxiv.org/abs/2511.21151)
*M. Alecci,P. Jiménez,J. Samhi,T. Bissyandé,J. Klein*

Main category: cs.SE

TL;DR: The paper reveals that Android apps, even when branded and functionally identical across regions, often have hidden technical differences affecting security and privacy. These regional variants undermine study reproducibility and pose ethical challenges, highlighting a need for greater transparency in app distribution.


<details>
  <summary>Details</summary>
Motivation: Mobile app evolution is well-researched, but how apps differ in behavior across geographical regions—particularly regarding security and fairness—has not been thoroughly explored. Addressing this gap is essential due to growing concerns over app transparency, consent, and potential biases in regional app distributions.

Method: The authors built a distributed app collection pipeline spanning multiple regions to gather and analyze thousands of Android apps. They specifically investigated: 1) 'GeoTwins'—functionally similar apps released under different package names in various countries, and 2) regional variation in supposedly uniform Android App Bundle base.apk files. They also released a large dataset of GeoTwins for the research community.

Result: The study revealed widespread regional disparities: GeoTwins often differed in permissions, third-party libraries, and privacy disclosures depending on country. Even the base.apk files—assumed to be consistent—varied by region. Such discrepancies cause the same app to be labeled as benign in certain malware studies but suspicious in others, due to where it was downloaded. This regional variation undermines study reproducibility and introduces geographic bias in app assessments.

Conclusion: Regional differences in Android apps are substantial, impacting privacy, security, and transparency. This hidden variation raises ethical issues and affects reproducibility, security assessments, and fair treatment in the global app marketplace. Both the technical and ethical implications should concern developers, researchers, and policymakers.

Abstract: While mobile app evolution has been widely studied, geographical variation in app behavior remains largely unexplored. This paper presents a large-scale study of location-based Android app differentiation, uncovering two important and underexamined phenomena with security and fairness implications. First, we introduce GeoTwins: apps that are functionally similar and share branding but are released under different package names across countries. Despite their similarity, GeoTwins often diverge in requested permissions, third-party libraries, and privacy disclosures. Second, we examine the Android App Bundle ecosystem and reveal unexpected regional differences in supposedly consistent base.apk files. Contrary to common assumptions, even base.apk files vary by region, exposing hidden customizations that may affect app behavior or security.
  These discrepancies have concrete consequences. Geographically distinct variants can lead the same app to be labeled benign in one malware study but suspicious in another, depending on the region of download. Such hidden variation undermines reproducibility and introduces geographic bias into assessments of security, privacy, and functionality. It also raises ethical concerns about transparency and consent: visually identical Google Play listings may mask subtle but important differences.
  To study these issues, we built a distributed app collection pipeline spanning multiple regions and analyzed thousands of apps. We also release a dataset of 81,963 GeoTwins to support future work. Our findings reveal systemic regional disparities in mobile software, with implications for researchers, developers, platform architects, and policymakers.

</details>


### [9] [Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools](https://arxiv.org/abs/2511.21197)
*Paolo Buono,Mary Cerullo,Stefano Cirillo,Giuseppe Desolda,Francesco Greco,Emanuela Guglielmi,Grazia Margarella,Giuseppe Polese,Simone Scalabrino,Cesare Tucci*

Main category: cs.SE

TL;DR: Developers see AI bug detection tools as detectives and readability tools as coaches—trust depends on clear, timely explanations and user control. The paper proposes design principles for better human-AI collaboration in IDEs.


<details>
  <summary>Details</summary>
Motivation: To understand how developers conceptualize AI-assisted tools, and how mismatches in mental models impact trust and use, guiding better design of human-centered AI in software development.

Method: Six co-design workshops with 58 developers were conducted to gather insights on their mental models regarding AI-assisted bug detection and readability features.

Result: Developers have unique mental models for AI-assisted bug detection (viewed as 'bug detectives') and readability tools ('quality coaches'). Trust is influenced by explanation clarity, timing, and user control. Successful adoption hinges on matching these mental models with tool design.

Conclusion: Aligning AI tool design with developers' mental models improves trust and adoption. Principles for human-centered AI emphasize balancing support/disruption, conciseness/depth, and automation/human agency in development environments.

Abstract: AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.

</details>


### [10] [Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions](https://arxiv.org/abs/2511.21380)
*Jingyi Chen,Xiaoyan Guo,Songqiang Chen,Shing-Chi Cheung,Jiasi Shen*

Main category: cs.SE

TL;DR: This paper empirically evaluates LLM-based multi-agent systems for automating software engineering dataset adaptation. While these systems can partially complete tasks, they seldom achieve fully correct results. However, providing targeted feedback (errors and reference code) greatly improves performance. The study identifies strengths and current limitations, suggesting practical ways to make future SE adaptation agents more reliable.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of automating the adaptation of software engineering research artifacts across different datasets, which is fundamental for scalability and reproducibility in SE research but remains underexplored.

Method: The study conducts an empirical evaluation of state-of-the-art multi-agent large language model (LLM) systems (specifically Copilot with GPT-4.1 and Claude Sonnet 4) on dataset adaptation tasks. It uses a five-stage evaluation pipeline: file comprehension, code editing, command generation, validation, and final execution, measuring their performance on established benchmarks (ROCODE and LogHub2.0). It also tests prompt-based interventions to improve agent performance.

Result: Current multi-agent systems can identify relevant files and partially adapt code, but often fail to produce functionally correct outcomes. Prompt-level interventions, such as error messages and reference code, significantly improve structural similarity to ground truth results (from 7.25% to 67.14%).

Conclusion: Multi-agent LLM systems show potential in automating dataset adaptation in SE research, but they face notable limitations in accuracy and robustness. Contextual feedback and reference prompts are necessary to improve outcomes and make such systems more reliable and self-correcting for future research.

Abstract: Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.

</details>


### [11] [Large Language Models for Unit Test Generation: Achievements, Challenges, and the Road Ahead](https://arxiv.org/abs/2511.21382)
*Bei Chu,Yang Feng,Kui Liu,Zifan Nan,Zhaoqiang Guo,Baowen Xu*

Main category: cs.SE

TL;DR: This survey reviews recent literature on LLM use in automatic unit test generation, identifying prompt engineering and validation loops as key strategies that enhance test realism and reliability. Despite progress, improvements are needed in fault detection and standardization. The paper outlines future directions for developing autonomous, hybrid testing solutions leveraging LLMs.


<details>
  <summary>Details</summary>
Motivation: Classic automated unit test generation methods often lack semantic understanding, resulting in unrealistic test inputs and assertions. The rise of LLMs offers a potential solution by utilizing code semantics and programming patterns.

Method: A systematic literature review of 115 recent publications (May 2021 to August 2025) was conducted. The authors established a unified taxonomy of test generation stages and analyzed strategies and enhancement techniques involving LLMs, including engineering constraints, prompt design, and validation loops.

Result: Prompt engineering is the most popular approach, present in 89% of studies, due to its adaptability. Iterative validation and repair have improved test pass rates. However, issues remain with weak fault detection and a lack of standardized benchmarks.

Conclusion: LLMs significantly advance unit test generation but face ongoing challenges in fault detection and evaluation standards. The recommended research direction involves developing autonomous testing agents and integrating LLMs with conventional engineering tools for robust real-world applications.

Abstract: Unit testing is an essential yet laborious technique for verifying software and mitigating regression risks. Although classic automated methods effectively explore program structures, they often lack the semantic information required to produce realistic inputs and assertions. Large Language Models (LLMs) address this limitation by utilizing by leveraging their data-driven knowledge of code semantics and programming patterns. To analyze the state of the art in this domain, we conducted a systematic literature review of 115 publications published between May 2021 and August 2025. We propose a unified taxonomy based on the unit test generation lifecycle that treats LLMs as stochastic generators requiring systematic engineering constraints. This framework analyzes the literature regarding core generative strategies and a set of enhancement techniques ranging from pre-generation context enrichment to post-generation quality assurance. Our analysis reveals that prompt engineering has emerged as the dominant utilization strategy and accounts for 89% of the studies due to its flexibility. We find that iterative validation and repair loops have become the standard mechanism to ensure robust usability and lead to significant improvements in compilation and execution pass rates. However, critical challenges remain regarding the weak fault detection capabilities of generated tests and the lack of standardized evaluation benchmarks. We conclude with a roadmap for future research that emphasizes the progression towards autonomous testing agents and hybrid systems combining LLMs with traditional software engineering tools. This survey provides researchers and practitioners with a comprehensive perspective on converting the potential of LLMs into industrial-grade testing solutions.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [12] [Optimism in Equality Saturation](https://arxiv.org/abs/2511.20782)
*Russel Arbore,Alvin Cheung,Max Willsey*

Main category: cs.PL

TL;DR: The paper presents a new abstract interpretation algorithm for equality saturation that better analyzes cyclic programs, significantly improving precision over existing compilers for simple cases.


<details>
  <summary>Details</summary>
Motivation: The current pessimistic approach to e-class analysis in equality saturation struggles with cyclic programs, motivating a more effective technique that can handle such cases.

Method: They introduce an abstract interpretation algorithm that works with equality saturation and e-class analysis, applying it specifically to programs in SSA form using a new SSA semantics.

Result: Their prototype abstract interpreter for SSA programs can analyze certain examples more precisely than established compilers like clang and gcc.

Conclusion: The proposed abstract interpretation algorithm enables precise analysis of cyclic programs during equality saturation, improving upon current pessimistic methods.

Abstract: Equality saturation is a technique for program optimization based on non-destructive rewriting and a form of program analysis called e-class analysis. The current form of e-class analysis is pessimistic and therefore ineffective at analyzing cyclic programs, such as those in SSA form. We propose an abstract interpretation algorithm that can precisely analyze cycles during equality saturation. This results in a unified algorithm for optimistic analysis and non-destructive rewriting. We instantiate this approach on a prototype abstract interpreter for SSA programs using a new semantics of SSA. Our prototype can analyze simple example programs more precisely than clang and gcc.

</details>


### [13] [Towards Computational UIP in Cubical Agda](https://arxiv.org/abs/2511.21209)
*Yee-Jian Tan,Andreas Nuyts,Dominique Devriese*

Main category: cs.PL

TL;DR: This paper explores how to restrict Cubical Type Theory to h-Sets in Cubical Agda, preserving key features (QITs, functional extensionality) but making equalities simpler. It analyzes approaches for implementing the Uniqueness of Identity Proofs (UIP), proposes better computation rules, and presents a variant of Cubical Agda compatible with UIP.


<details>
  <summary>Details</summary>
Motivation: Cubical Type Theory has advantages over traditional type theories, such as supporting Quotient Inductive Types and provable functional extensionality. However, its infinite hierarchy of equalities can complicate formalizations. The motivation is to retain key features like QITs and functional extensionality while making equality handling simpler and more tractable.

Method: The authors analyze different ways to achieve h-Set Cubical Type Theory in Cubical Agda, focusing on how to formulate and implement the Uniqueness of Identity Proofs (UIP) axiom. They study computation rules and assess manual and automatic methods for UIP implementation, including removing Glue Types and evaluating a variant of Cubical Agda compatible with UIP.

Result: The study identifies two current, but unsatisfactory, approaches to achieve h-Set Cubical Type Theory in Cubical Agda: naive postulation of UIP (giving up on canonicity) and laboriously proving UIP for each type using h-level preservation. The authors provide an analysis of computation rules for UIP, and implement a Cubical Agda variant without Glue, facilitating UIP postulation and future implementation.

Conclusion: A Cubical Type Theory limited to h-Set level equalities effectively retains important features like functional extensionality and QITs, even without univalence. Nonetheless, current methods to implement this in Cubical Agda are lacking; thus, the paper's work on computation rules and a Glue-less Cubical Agda is a step toward a more practical and robust h-Set Cubical Type Theory.

Abstract: Some advantages of Cubical Type Theory, as implemented by Cubical Agda, over intensional Martin-Löf Type Theory include Quotient Inductive Types (QITs), which exist as instances of Higher Inductive Types, and functional extensionality, which is provable in Cubical Type Theory. However, HoTT features an infinite hierarchy of equalities that may become unwieldy in formalisations. Fortunately, QITs and functional extensionality are both preserved even if the equality levels of Cubical Type Theory are truncated to only homotopical Sets (h-Sets). In other words, removing the univalence axiom from Cubical Type Theory and instead postulating a conflicting axiom: the Uniqueness of Identity Proofs (UIP) postulate. Since univalence is proved in Cubical Type Theory from the so-called Glue Types, therefore, it is known that one can first remove the Glue Types (thus removing univalence) and then set-truncate all equalities (essentially assuming UIP), à la XTT. The result is a "h-Set Cubical Type Theory" that retains features such as functional extensionality and QITs.
  However, in Cubical Agda, there are currently only two unsatisfying ways to achieve h-Set Cubical Type Theory. The first is to give up on the canonicity of the theory and simply postulate the UIP axiom, while the second way is to use a standard result stating "type formers preserve h-levels" to manually prove UIP for every defined type. The latter is, however, laborious work best suited for an automatic implementation by the proof assistant. In this project, we analyse formulations of UIP and detail their computation rules for Cubical Agda, and evaluate their suitability for implementation. We also implement a variant of Cubical Agda without Glue, which is already compatible with postulated UIP, in anticipation of a future implementation of UIP in Cubical Agda.

</details>


### [14] [SV-LIB 1.0: A Standard Exchange Format for Software-Verification Tasks](https://arxiv.org/abs/2511.21509)
*Dirk Beyer,Gidon Ernst,Martin Jonáš,Marian Lingsch-Rosenfeld*

Main category: cs.PL

TL;DR: SV-LIB offers a common exchange format for software verification tasks across languages, aiming to increase interoperability between verification tools, simplify integration, and enable witness validation. The paper introduces its first version and outlines future enhancements.


<details>
  <summary>Details</summary>
Motivation: There is an abundance of verification tools for individual programming languages, but many verification techniques are actually language-agnostic, making broader applicability desirable. The lack of a common format inhibits technology transfer among verification tools and languages.

Method: The authors propose SV-LIB, an exchange format and intermediate language for software verification tasks. SV-LIB incorporates well-known imperative programming language concepts and leverages SMT-LIB for expression and type representation. It also defines witness formats for program correctness and incorrectness, as well as means to specify witness-validation tasks.

Result: SV-LIB version 1.0 is presented, detailing its design goals, syntax, and informal semantics. The format makes it easier to parse and integrate with existing verification infrastructures. It also enables the development of independent witness validators and the reuse of verifiers for witness validation.

Conclusion: SV-LIB bridges gaps between verification tools for different programming and modeling languages, supporting interoperability and technology transfer. Future work will address formal semantics and concurrency extensions.

Abstract: In the past two decades, significant research and development effort went into the development of verification tools for individual languages, such asC, C++, and Java. Many of the used verification approaches are in fact language-agnostic and it would be beneficial for the technology transfer to allow for using the implementations also for other programming and modeling languages. To address the problem, we propose SV-LIB, an exchange format and intermediate language for software-verification tasks, including programs, specifications, and verification witnesses. SV-LIBis based on well-known concepts from imperative programming languages and uses SMT-LIB to represent expressions and sorts used in the program. This makes it easy to parse and to build into existing infrastructure, since many verification tools are based on SMT solvers already. Furthermore, SV-LIBdefines a witness format for both correct and incorrect SV-LIB programs, together with means for specifying witness-validation tasks. This makes it possible both to implement independent witness validators and to reuse some verifiers also as validators for witnesses. This paper presents version 1.0 of the SV-LIBformat, including its design goals, the syntax, and informal semantics. Formal semantics and further extensions to concurrency are planned for future versions.

</details>
