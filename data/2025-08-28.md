<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Stack Trace-Based Crash Deduplication with Transformer Adaptation](https://arxiv.org/abs/2508.19449)
*Md Afif Al Mamun,Gias Uddin,Lan Xia,Longyu Zhang*

Main category: cs.SE

TL;DR: dedupT, a transformer-based crash deduplication approach, outperforms current methods in ranking duplicates and detecting unique crash reports, reducing developer workload and improving issue-tracking efficiency.


<details>
  <summary>Details</summary>
Motivation: Automated crash reporting systems produce many duplicate reports, overwhelming issue-tracking systems and increasing developer workload. Existing deduplication methods often fail to capture the full context and relationships in stack traces.

Method: The paper introduces dedupT, a transformer-based method. It adapts a pretrained language model (PLM) to stack traces and uses the resulting embeddings with a fully-connected network (FCN) to rank duplicate crashes more effectively.

Result: dedupT outperforms both traditional and existing deep learning methods in duplicate ranking and unique crash detection across four public datasets, showing over 15% improvement in Mean Reciprocal Rank compared to the best DL baseline and up to 9% versus traditional techniques, along with higher ROC-AUC for unique report detection.

Conclusion: dedupT provides a more accurate and efficient solution for stack trace-based crash deduplication, lowering manual triage efforts and advancing the use of NLP in software engineering.

Abstract: Automated crash reporting systems generate large volumes of duplicate
reports, overwhelming issue-tracking systems and increasing developer workload.
Traditional stack trace-based deduplication methods, relying on string
similarity, rule-based heuristics, or deep learning (DL) models, often fail to
capture the contextual and structural relationships within stack traces. We
propose dedupT, a transformer-based approach that models stack traces
holistically rather than as isolated frames. dedupT first adapts a pretrained
language model (PLM) to stack traces, then uses its embeddings to train a
fully-connected network (FCN) to rank duplicate crashes effectively. Extensive
experiments on real-world datasets show that dedupT outperforms existing DL and
traditional methods (e.g., sequence alignment and information retrieval
techniques) in both duplicate ranking and unique crash detection, significantly
reducing manual triage effort. On four public datasets, dedupT improves Mean
Reciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up
to 9% over traditional methods while achieving higher Receiver Operating
Characteristic Area Under the Curve (ROC-AUC) in detecting unique crash
reports. Our work advances the integration of modern natural language
processing (NLP) techniques into software engineering, providing an effective
solution for stack trace-based crash deduplication.

</details>


### [2] [Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking](https://arxiv.org/abs/2508.19558)
*Zhuohao Li,Wenqing Chen,Jianxing Yu,Zhichao Lu*

Main category: cs.SE

TL;DR: The paper proposes a novel data synthesis framework that generates functionally diverse code benchmarks, enabling embedding models to better capture code functionalities (not just syntax) and improving their performance across various code-related tasks.


<details>
  <summary>Details</summary>
Motivation: Current embedding models are strong in text-related tasks but their ability to capture code-level functional semantics is unclear. Previous work focuses mostly on syntactic similarity (like clone detection) rather than on functional equivalence in code, which is a significant gap.

Method: The authors introduce a new data synthesis framework called Functionality-Oriented Code Self-Evolution. This framework creates benchmarks by defining code examples across four semantic and syntactic categories, and generates four unique variations from a single code instance to better reflect functional differences. Extensive experiments are conducted on tasks like code clone detection, functional consistency identification, and code retrieval.

Result: When embedding models are trained on the evolved datasets generated by the proposed framework, their performance on downstream tasks improves significantly. The framework broadens the scope of code variations to include more functionally informative examples.

Conclusion: The framework effectively advances the training and evaluation of embedding models towards functional understanding of code. It outperforms traditional datasets that focus too much on syntax, and promotes generalization across multiple tasks.

Abstract: Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

</details>


### [3] [The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts](https://arxiv.org/abs/2508.19610)
*Kathrin Figl,Maria Kirchner,Sebastian Baltes,Michael Felderer*

Main category: cs.SE

TL;DR: Code snippets with comments (especially block comments for novices) are rated as much more helpful on Stack Overflow than those without, suggesting that effective commenting is crucial for useful code sharing and can inform both platform design and AI code generation.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand how code comments affect the perceived helpfulness of answers on Q&A platforms like Stack Overflow, given that poorly understood code can lead to problems like bugs or vulnerabilities.

Method: The researchers conducted an online experiment simulating Stack Overflow, with 91 participants evaluating code snippets with different types of comments (block, inline, none) and other answer features (such as position and score).

Result: Both block and inline comments made code snippets appear significantly more helpful than uncommented code. Novices in particular found block comments more helpful than inline ones. Other answer features like position and score were less important to perceived helpfulness.

Conclusion: Code comments play a vital role in making code snippets more helpful on Stack Overflow. These insights can guide improvements for both human advice on community-driven platforms and AI-based coding assistants, by highlighting the importance of commenting style and content over superficial features.

Abstract: Question-and-answer platforms such as Stack Overflow have become an important
way for software developers to share and retrieve knowledge. However, reusing
poorly understood code can lead to serious problems, such as bugs or security
vulnerabilities. To better understand how code comments affect the perceived
helpfulness of Stack Overflow answers, we conducted an online experiment
simulating a Stack Overflow environment (n=91). The results indicate that both
block and inline comments are perceived as significantly more helpful than
uncommented source code. Moreover, novices rated code snippets with block
comments as more helpful than those with inline comments. Interestingly, other
surface features, such as the position of an answer and its answer score, were
considered less important. The content of Stack Overflow has been a major
source for training large language models. AI-based coding assistants such as
GitHub Copilot, which are based on these models, might change the way Stack
Overflow is used. However, our findings have implications beyond this specific
platform. First, they may help to improve the relevance of community-driven
platforms such as Stack Overflow, which provide human advice and explanations
of code solutions, complementing AI-based support for software developers.
Second, since chat-based AI tools can be prompted to generate code in different
ways, knowing which properties influence perceived helpfulness might lead to
targeted prompting strategies to generate more readable code snippets.

</details>


### [4] [Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation](https://arxiv.org/abs/2508.19663)
*Lola Solovyeva,Eduardo Carneiro Oliveira,Shiyu Fan,Alper Tuncay,Shamil Gareev,Andrea Capiluppi*

Main category: cs.SE

TL;DR: This paper explores using large language models to translate PL/SQL legacy code to Java for easier modernization, showing promising initial results but noting limitations due to a small dataset and limited testing.


<details>
  <summary>Details</summary>
Motivation: The legacy VT system, consisting of 2.5 million PL/SQL lines, has poor documentation and lacks automated tests, making modernization and refactoring very difficult.

Method: The study used a dataset of 10 PL/SQL-to-Java code pairs and 15 Java classes to evaluate several large language models (LLMs). A custom prompting strategy was developed that combines chain-of-guidance reasoning and n-shot prompting to improve translation quality.

Result: The proposed methodology successfully guided LLMs to produce syntactically correct and functionally accurate PL/SQL-to-Java translations. However, the results are restricted by the small dataset and lack of comprehensive testing resources.

Conclusion: LLMs, when guided by a tailored prompting strategy, can be effective in modernizing legacy codebases by translating PL/SQL to Java, but further research with larger datasets and better test coverage is needed for scalable adoption.

Abstract: The VT legacy system, comprising approximately 2.5 million lines of PL/SQL
code, lacks consistent documentation and automated tests, posing significant
challenges for refactoring and modernisation. This study investigates the
feasibility of leveraging large language models (LLMs) to assist in translating
PL/SQL code into Java for the modernised "VTF3" system. By leveraging a dataset
comprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively
established a domain model for the translated files, multiple LLMs were
evaluated. Furthermore, we propose a customized prompting strategy that
integrates chain-of-guidance reasoning with $n$-shot prompting. Our findings
indicate that this methodology effectively guides LLMs in generating
syntactically accurate translations while also achieving functional
correctness. However, the findings are limited by the small sample size of
available code files and the restricted access to test cases used for
validating the correctness of the generated code. Nevertheless, these findings
lay the groundwork for scalable, automated solutions in modernising large
legacy systems.

</details>


### [5] [Enabling Content Management Systems as an Information Source in Model-driven Projects](https://arxiv.org/abs/2508.19797)
*Joan Giner-Miguelez,Abel GÃ³mez,Jordi Cabot*

Main category: cs.SE

TL;DR: Headless CMSs are powerful yet tricky to integrate due to their custom schemas. This paper presents an open-source, model-based framework that automates schema discovery and generates middleware, making integration easier and less error-prone.


<details>
  <summary>Details</summary>
Motivation: Headless CMSs have become increasingly important for delivering content to a variety of applications, not just web browsers. However, discovering and managing their highly customized schemas is still a complex, manual, and error-prone process.

Method: The authors introduce a model-based framework that automatically discovers and explicitly represents the information schema of a headless CMS. This framework also generates middleware for platform-agnostic access to the CMS for all client applications.

Result: The framework enables easier integration of headless CMSs into software development workflows by simplifying schema discovery and providing reusable middleware. The solution is open-source and publicly available.

Conclusion: The proposed framework provides a systematic and efficient approach for integrating headless CMSs, improving schema management, reducing manual effort, and enabling broader and easier consumption of CMS-provided content.

Abstract: Content Management Systems (CMSs) are the most popular tool when it comes to
create and publish content across the web. Recently, CMSs have evolved,
becoming \emph{headless}. Content served by a \emph{headless CMS} aims to be
consumed by other applications and services through REST APIs rather than by
human users through a web browser. This evolution has enabled CMSs to become a
notorious source of content to be used in a variety of contexts beyond pure web
navigation. As such, CMS have become an important component of many information
systems. Unfortunately, we still lack the tools to properly discover and manage
the information stored in a CMS, often highly customized to the needs of a
specific domain. Currently, this is mostly a time-consuming and error-prone
manual process.
  In this paper, we propose a model-based framework to facilitate the
integration of headless CMSs in software development processes. Our framework
is able to discover and explicitly represent the information schema behind the
CMS. This facilitates designing the interaction between the CMS model and other
components consuming that information. These interactions are then generated as
part of a middleware library that offers platform-agnostic access to the CMS to
all the client applications. The complete framework is open-source and
available online.

</details>


### [6] [Towards a fundamental theory of modeling discrete systems](https://arxiv.org/abs/2508.19803)
*Peter Fettke,Wolfgang Reisig*

Main category: cs.SE

TL;DR: This paper highlights the need for a new modeling theory for digital challenges and proposes the Heraklit framework to address these issues, setting the stage for future research.


<details>
  <summary>Details</summary>
Motivation: Traditional modeling approaches struggle to address challenges unique to the digital era, such as complexity, correctness, and dynamic information.

Method: The paper introduces and explains a new theoretical framework called Heraklit for modeling.

Result: Heraklit framework is presented as a novel approach, aiming to serve as a basis for further development in modeling theories for the digital age.

Conclusion: The paper provides foundational groundwork, with plans for future research into correctness, information theory, and invariance in modeling.

Abstract: Modeling is a central concern in both science and engineering. However, we
need a new fundamental theory to address the challenges of the digital age. In
this paper, we first explain why modeling is fundamental and which challenges
must be addressed in the digital world. As a main contribution, we introduce
the Heraklit modeling framework as a new approach to modeling. We conclude with
some general remarks. Future work will involve the correctness of modeling, the
notion of information, and the description of invariance in modeling.

</details>


### [7] [On the Future of Software Reuse in the Era of AI Native Software Engineering](https://arxiv.org/abs/2508.19834)
*Antero Taivalsaari,Tommi Mikkonen,Cesare Pautasso*

Main category: cs.SE

TL;DR: AI-driven generative software reuse is transforming development, creating new challenges similar to cargo cult programming. This paper discusses these issues and suggests future research directions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the rapid paradigm shift towards AI Native software development, where AI-generated code is increasingly trusted and reused, raising concerns similar to cargo cult development.

Method: The authors discuss the implications of AI-assisted generative software reuse, raise relevant questions, and propose a research agenda to address the central challenges.

Result: The paper identifies the central issues of AI-assisted generative software reuse, outlines relevant questions, and provides a research agenda for further inquiry.

Conclusion: The paper concludes that AI-assisted generative software reuse is fundamentally changing software development practices, warranting critical examination and a dedicated research agenda to address emerging challenges.

Abstract: Software development is currently under a paradigm shift in which artificial
intelligence and generative software reuse are taking the center stage in
software creation. Earlier opportunistic software reuse practices and organic
software development methods are rapidly being replaced by "AI Native"
approaches in which developers place their trust on code that has been
generated by artificial intelligence. This is leading to a new form of software
reuse that is conceptually not all that different from cargo cult development.
In this paper we discuss the implications of AI-assisted generative software
reuse, bring forth relevant questions, and define a research agenda for
tackling the central issues associated with this emerging approach.

</details>


### [8] [Generative AI for Testing of Autonomous Driving Systems: A Survey](https://arxiv.org/abs/2508.19882)
*Qunying Song,He Ye,Mark Harman,Federica Sarro*

Main category: cs.SE

TL;DR: Generative AI is increasingly used for testing autonomous driving systems, mainly for generating diverse test scenarios. This survey of 91 studies summarizes application areas, effectiveness, and evaluation tools, while also highlighting key challenges and future research opportunities.


<details>
  <summary>Details</summary>
Motivation: Autonomous driving systems (ADS) promise significant societal benefits but require thorough testing to ensure safety and reliability before widespread deployment. Traditional testing faces challenges in covering diverse scenarios efficiently and effectively, sparking interest in new approaches like generative AI.

Method: The authors conducted a systematic analysis of 91 relevant studies, synthesizing their findings into six major categories related to scenario-based testing of ADS. They reviewed the effectiveness of generative AI approaches, cataloged datasets, simulators, ADS, metrics, and benchmarks used, and identified key limitations in current research.

Result: Generative AI is mainly applied in scenario-based testing for ADS, offering advantages in generating diverse and complex testing scenarios. The survey organizes the current landscape, highlights application areas, reviews evaluation tools, and identifies 27 significant limitations in the field.

Conclusion: Generative AI holds substantial promise for enhancing the testing of ADS but faces notable challenges and limitations. The survey provides a comprehensive overview, identifies gaps, and suggests future research directions for the effective integration of generative AI in ADS testing.

Abstract: Autonomous driving systems (ADS) have been an active area of research, with
the potential to deliver significant benefits to society. However, before
large-scale deployment on public roads, extensive testing is necessary to
validate their functionality and safety under diverse driving conditions.
Therefore, different testing approaches are required, and achieving effective
and efficient testing of ADS remains an open challenge. Recently, generative AI
has emerged as a powerful tool across many domains, and it is increasingly
being applied to ADS testing due to its ability to interpret context, reason
about complex tasks, and generate diverse outputs. To gain a deeper
understanding of its role in ADS testing, we systematically analyzed 91
relevant studies and synthesized their findings into six major application
categories, primarily centered on scenario-based testing of ADS. We also
reviewed their effectiveness and compiled a wide range of datasets, simulators,
ADS, metrics, and benchmarks used for evaluation, while identifying 27
limitations. This survey provides an overview and practical insights into the
use of generative AI for testing ADS, highlights existing challenges, and
outlines directions for future research in this rapidly evolving field.

</details>


### [9] [Smart Contract Intent Detection with Pre-trained Programming Language Model](https://arxiv.org/abs/2508.20086)
*Youwei Huang,Jianwen Li,Sen Fang,Yao Li,Peng Yang,Bin Hu,Tao Zhang*

Main category: cs.SE

TL;DR: The paper introduces SmartIntentNN2, a deep learning model that improves smart contract intent detection using BERT and BiLSTM. Trained on 16,000 real contracts, it achieves an F1 score of 0.927, outperforming earlier models and establishing itself as state-of-the-art in detecting malicious or unsafe intent in smart contract code.


<details>
  <summary>Details</summary>
Motivation: Malicious intent in smart contracts can cause severe economic damage. Detecting such unsafe intentions during smart contract development is crucial to improving blockchain security and trust.

Method: The paper presents SmartIntentNN2, an upgraded deep learning model for smart contract intent detection. It integrates a BERT-based pre-trained language model (trained on 16,000 contracts with a Masked Language Modeling objective) alongside a Bidirectional Long Short-Term Memory (BiLSTM) network for multi-label classification. The approach builds on earlier architectures (Universal Sentence Encoder, K-means clustering for intent highlighting) while focusing on improved intent detection.

Result: SmartIntentNN2 achieves a high F1 score of 0.927 in detecting ten different intent categories within smart contracts, outperforming its predecessor SmartIntentNN (F1 of 0.8633).

Conclusion: SmartIntentNN2 sets a new benchmark for smart contract intent detection, offering state-of-the-art performance thanks to the integration of a BERT-based pretrained language model and a BiLSTM classifier.

Abstract: Malicious intent in smart contract development can lead to substantial
economic losses. SmartIntentNN is a deep learning model specifically designed
to identify unsafe intents in smart contracts. This model integrates the
Universal Sentence Encoder, a K-means clustering-based intent highlighting
mechanism, and a Bidirectional Long Short-Term Memory network for multi-label
classification, achieving an F1 of 0.8633 in distinguishing ten different
intent categories. In this study, we present an upgraded version of this model,
SmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant
enhancement in V2 is the incorporation of a BERT-based pre-trained language
model, which has been trained on a dataset of 16,000 real smart contracts using
a Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based
multi-label classification network. With an improved F1 of 0.927, V2
demonstrates enhanced performance compared to its predecessor, establishing
itself as the state-of-the-art model for smart contract intent detection.

</details>
