{"id": "2511.11939", "categories": ["cs.PL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.11939", "abs": "https://arxiv.org/abs/2511.11939", "authors": ["Manya Bansal", "Daniel Sainati", "Joseph W. Cutler", "Saman Amarasinghe", "Jonathan Ragan-Kelley"], "title": "Modular GPU Programming with Typed Perspectives", "comment": null, "summary": "To achieve peak performance on modern GPUs, one must balance two frames of mind: issuing instructions to individual threads to control their behavior, while simultaneously tracking the convergence of many threads acting in concert to perform collective operations like Tensor Core instructions. The tension between these two mindsets makes modular programming error prone. Functions that encapsulate collective operations, despite being called per-thread, must be executed cooperatively by groups of threads.\n  In this work, we introduce Prism, a new GPU language that restores modularity while still giving programmers the low-level control over collective operations necessary for high performance. Our core idea is typed perspectives, which materialize, at the type level, the granularity at which the programmer is controlling the behavior of threads. We describe the design of Prism, implement a compiler for it, and lay its theoretical foundations in a core calculus called Bundl. We implement state-of-the-art GPU kernels in Prism and find that it offers programmers the safety guarantees needed to confidently write modular code without sacrificing performance."}
{"id": "2511.12253", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12253", "abs": "https://arxiv.org/abs/2511.12253", "authors": ["Harrison Goldstein", "Hila Peleg", "Cassia Torczon", "Daniel Sainati", "Leonidas Lampropoulos", "Benjamin C. Pierce"], "title": "The Search for Constrained Random Generators", "comment": null, "summary": "Among the biggest challenges in property-based testing (PBT) is the constrained random generation problem: given a predicate on program values, randomly sample from the set of all values satisfying that predicate, and only those values. Efficient solutions to this problem are critical, since the executable specifications used by PBT often have preconditions that input values must satisfy in order to be valid test cases, and satisfying values are often sparsely distributed.\n  We propose a novel approach to this problem using ideas from deductive program synthesis. We present a set of synthesis rules, based on a denotational semantics of generators, that give rise to an automatic procedure for synthesizing correct generators. Our system handles recursive predicates by rewriting them as catamorphisms and then matching with appropriate anamorphisms; this is theoretically simpler than other approaches to synthesis for recursive functions, yet still extremely expressive.\n  Our implementation, Palamedes, is an extensible library for the Lean theorem prover. The synthesis algorithm itself is built on standard proof-search tactics, reducing implementation burden and allowing the algorithm to benefit from further advances in Lean proof automation."}
{"id": "2511.12638", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12638", "abs": "https://arxiv.org/abs/2511.12638", "authors": ["Kshitij Dubey", "Benjamin Driscoll", "Anjiang Wei", "Neeraj Kayal", "Rahul Sharma", "Alex Aiken"], "title": "Equivalence Checking of ML GPU Kernels", "comment": null, "summary": "With the rapid progress of deep learning and large language models (LLMs), companies now spend enormous sums executing GPU kernels. These kernels have, therefore, become prime targets for aggressive optimization. Recent efforts increasingly leverage LLMs to generate GPU kernels, but make no formal guarantees about the generated kernels. We present the first equivalence checker for GPU kernels and use it to formally verify the correctness of machine learning (ML) kernels optimized by hand, by LLMs, and by compilers. We show that our equivalence checker is sound and, for a well-defined class of GPU kernels which includes the programs of interest, complete. Our implementation, VOLTA, can verify ML computations such as convolutions, matrix multiplications, and various attention mechanisms."}
{"id": "2511.13663", "categories": ["cs.PL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13663", "abs": "https://arxiv.org/abs/2511.13663", "authors": ["Qiuhan Gu", "Avaljot Singh", "Gagandeep Singh"], "title": "Cost-Driven Synthesis of Sound Abstract Interpreters", "comment": "37 pages, 20 figures", "summary": "Constructing abstract interpreters that provide global soundness guarantees remains a major obstacle in abstract interpretation. We investigate whether modern LLMs can reduce this burden by leveraging them to synthesize sound, non-trivial abstract interpreters across multiple abstract domains in the setting of neural network verification. We formulate synthesis as a constrained optimization problem and introduce a novel mathematically grounded cost function for measuring unsoundness under strict syntactic and semantic constraints. Based on this formulation, we develop a unified framework that unifies LLM-based generation with syntactic and semantic validation and a quantitative cost-guided feedback mechanism. Empirical results demonstrate that our framework not only matches the quality of handcrafted transformers, but more importantly, discovers sound, high-precision transformers for complex nonlinear operators that are absent from existing literature."}
{"id": "2511.11999", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.11999", "abs": "https://arxiv.org/abs/2511.11999", "authors": ["Zeyu Lu", "Peng Zhang", "Chun Yong Chong", "Shan Gao", "Yibiao Yang", "Yanhui Li", "Lin Chen", "Yuming Zhou"], "title": "WITNESS: A lightweight and practical approach to fine-grained predictive mutation testing", "comment": null, "summary": "Existing fine-grained predictive mutation testing studies predominantly rely on deep learning, which faces two critical limitations in practice: (1) Exorbitant computational costs. The deep learning models adopted in these studies demand significant computational resources for training and inference acceleration. This introduces high costs and undermines the cost-reduction goal of predictive mutation testing. (2) Constrained applicability. Although modern mutation testing tools generate mutants both inside and outside methods, current fine-grained predictive mutation testing approaches handle only inside-method mutants. As a result, they cannot predict outside-method mutants, limiting their applicability in real-world scenarios. We propose WITNESS, a new fine-grained predictive mutation testing approach. WITNESS adopts a twofold design: (1) With collected features from both inside-method and outside-method mutants, WITNESS is suitable for all generated mutants. (2) Instead of using computationally expensive deep learning, WITNESS employs lightweight classical machine learning models for training and prediction. This makes it more cost-effective and enabling straightforward explanations of the decision-making processes behind the adopted models. Evaluations on Defects4J projects show that WITNESS consistently achieves state-of-the-art predictive performance across different scenarios. Additionally, WITNESS significantly enhances the efficiency of kill matrix prediction. Post-hoc analysis reveals that features incorporating information from before and after the mutation are the most important among those used in WITNESS. Test case prioritization based on the predicted kill matrix shows that WITNESS delivers results much closer to those obtained by using the actual kill matrix, outperforming baseline approaches."}
{"id": "2511.12276", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12276", "abs": "https://arxiv.org/abs/2511.12276", "authors": ["L. Thomas van Binsbergen", "Christopher A. Esterhuyse", "Tim Müller"], "title": "Reflections on the design, applications and implementations of the normative specification language eFLINT", "comment": "27 pages", "summary": "Checking the compliance of software against laws, regulations and contracts is increasingly important and costly as the embedding of software into societal practices is getting more pervasive. Moreover, the digitalised services provided by governmental organisations and companies are governed by an increasing amount of laws and regulations, requiring highly adaptable compliance practices. A potential solution is to automate compliance using software. However, automating compliance is difficult for various reasons. Legal practices involve subjective processes such as interpretation and qualification. New laws and regulations come into effect regularly and laws and regulations, as well as their interpretations, are subjected to constant revision. In addition, computational reasoning with laws requires a cross-disciplinary process involving both legal and software expertise.\n  This paper reflects on the domain-specific software language eFLINT developed to experiment with novel solutions. The language combines declarative and procedural elements to reason about situations and scenarios respectively, explicates and formalises connections between legal concepts and computational concepts, and is designed to automate compliance checks both before, during and after a software system runs. The various goals and applications areas for the language give rise to (conflicting) requirements. This paper reflects on the current design of the language by recalling various applications, the requirements they imposed, and subsequent design decisions. As such, this paper reports on results and insights of an investigation that can benefit language developers within the field of automated compliance."}
{"id": "2511.12069", "categories": ["cs.SE", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.12069", "abs": "https://arxiv.org/abs/2511.12069", "authors": ["HanYu Zhang", "Tomoji Kishi"], "title": "A Code Smell Refactoring Approach using GNNs", "comment": null, "summary": "Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past decades, a variety of refactoring approaches have been proposed, which can be broadly classified into metrics-based, rule-based, and machine learning-based approaches. Recent years, deep learning-based approaches have also attracted widespread attention. However, existing techniques exhibit various limitations. Metrics- and rule-based approaches rely heavily on manually defined heuristics and thresholds, whereas deep learning-based approaches are often constrained by dataset availability and model design. In this study, we proposed a graph-based deep learning approach for code smell refactoring. Specifically, we designed two types of input graphs (class-level and method-level) and employed both graph classification and node classification tasks to address the refactoring of three representative code smells: long method, large class, and feature envy. In our experiment, we propose a semi-automated dataset generation approach that could generate a large-scale dataset with minimal manual effort. We implemented the proposed approach with three classical GNN (graph neural network) architectures: GCN, GraphSAGE, and GAT, and evaluated its performance against both traditional and state-of-the-art deep learning approaches. The results demonstrate that proposed approach achieves superior refactoring performance."}
{"id": "2511.12823", "categories": ["cs.SE", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12823", "abs": "https://arxiv.org/abs/2511.12823", "authors": ["Sajed Jalil", "Shuvo Saha", "Hossain Mohammad Seym"], "title": "Enhancing LLM Code Generation Capabilities through Test-Driven Development and Code Interpreter", "comment": "AACL-IJCNLP 2025 Workshop BLP Shared Task 2, 6 pages, 7 figures, 3 tables", "summary": "Over the past few years, improving LLM code generation capabilities has been a key focus in NLP research. Despite Bengali having 242 million native speakers worldwide, it receives little attention when it comes to training LLMs. More recently, various fine-tuning and augmented generation techniques have been employed to significantly enhance code generation performance. However, they require considerable expertise and resources to utilize effectively as an end user. The goal of our work is to democratize access to powerful code generation tools in resource-constrained emerging markets, enabling users to leverage them in their native language.\n  We introduce a novel approach that combines Test-Driven Development (TDD) and Code Interpreter (CI), utilizing open-weight models, which improves the baseline accuracy for code generation with Bengali prompts and achieves an overall accuracy of 85%. Our approach requires no finetuning and proves that even the smallest models in the same family can attain up to 98% accuracy compared to the largest models. All of our results are publicly shared in GitHub for validation and reproducibility."}
{"id": "2511.12229", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12229", "abs": "https://arxiv.org/abs/2511.12229", "authors": ["Zhipeng Xue", "Zhipeng Gao", "Tongtong Xu", "Xing Hu", "Xin Xia", "Shanping Li"], "title": "Actionable Warning Is Not Enough: Recommending Valid Actionable Warnings with Weak Supervision", "comment": null, "summary": "The use of static analysis tools has gained increasing popularity among developers in the last few years. However, the widespread adoption of static analysis tools is hindered by their high false alarm rates. Previous studies have introduced the concept of actionable warnings and built a machine-learning method to distinguish actionable warnings from false alarms. However, according to our empirical observation, the current assumption used for actionable warning(s) collection is rather shaky and inaccurate, leading to a large number of invalid actionable warnings. To address this problem, in this study, we build the first large actionable warning dataset by mining 68,274 reversions from Top-500 GitHub C repositories, we then take one step further by assigning each actionable warning a weak label regarding its likelihood of being a real bug. Following that, we propose a two-stage framework called ACWRecommender to automatically recommend the actionable warnings with high probability to be real bugs (AWHB). Our approach warms up the pre-trained model UniXcoder by identifying actionable warnings task (coarse-grained detection stage) and rerank AWHB to the top by weakly supervised learning (fine-grained reranking stage). Experimental results show that our proposed model outperforms several baselines by a large margin in terms of nDCG and MRR for AWHB recommendation. Moreover, we ran our tool on 6 randomly selected projects and manually checked the top-ranked warnings from 2,197 reported warnings, we reported top-10 recommended warnings to developers, 27 of them were already confirmed by developers as real bugs. Developers can quickly find real bugs among the massive amount of reported warnings, which verifies the practical usage of our tool."}
{"id": "2511.12276", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12276", "abs": "https://arxiv.org/abs/2511.12276", "authors": ["L. Thomas van Binsbergen", "Christopher A. Esterhuyse", "Tim Müller"], "title": "Reflections on the design, applications and implementations of the normative specification language eFLINT", "comment": "27 pages", "summary": "Checking the compliance of software against laws, regulations and contracts is increasingly important and costly as the embedding of software into societal practices is getting more pervasive. Moreover, the digitalised services provided by governmental organisations and companies are governed by an increasing amount of laws and regulations, requiring highly adaptable compliance practices. A potential solution is to automate compliance using software. However, automating compliance is difficult for various reasons. Legal practices involve subjective processes such as interpretation and qualification. New laws and regulations come into effect regularly and laws and regulations, as well as their interpretations, are subjected to constant revision. In addition, computational reasoning with laws requires a cross-disciplinary process involving both legal and software expertise.\n  This paper reflects on the domain-specific software language eFLINT developed to experiment with novel solutions. The language combines declarative and procedural elements to reason about situations and scenarios respectively, explicates and formalises connections between legal concepts and computational concepts, and is designed to automate compliance checks both before, during and after a software system runs. The various goals and applications areas for the language give rise to (conflicting) requirements. This paper reflects on the current design of the language by recalling various applications, the requirements they imposed, and subsequent design decisions. As such, this paper reports on results and insights of an investigation that can benefit language developers within the field of automated compliance."}
{"id": "2511.12288", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12288", "abs": "https://arxiv.org/abs/2511.12288", "authors": ["Yihan Dai", "Sijie Liang", "Haotian Xu", "Peichu Xie", "Sergey Mechtaev"], "title": "Reducing Hallucinations in LLM-Generated Code via Semantic Triangulation", "comment": null, "summary": "When generating code from natural language prompts, an LLM samples programs from a probability distribution, many of which might be incorrect. Sample consensus techniques - such as majority voting or validation against generated tests or specifications - aim to identify a correct program in the sample or abstain if none is valid. However, existing methods often fail to select a correct solution when its sampling probability is low, or when the problem permits multiple valid but non-equivalent solutions. Additionally, they often fail to abstain when no correct solution is present in the sample. To overcome these limitations, we introduce semantic triangulation, which transforms a programming problem in a way that non-trivially alters its semantics while preserving an exact, verifiable mapping between solutions before and after transformation. We theoretically establish that verifying consistency across such problem transformations increases confidence that generated programs reflect accurate generalization rather than spurious statistical correlations, enabling more reliable sample consensus and abstention. On the LiveCodeBench and CodeElo benchmarks, using GPT-4o and DeepSeek-V3 models, semantic triangulation increases reliability of generated code by 21% compared to the method that selects only high-confidence solutions with the probability threshold 0.5, while being able to pinpoint correct solutions at sampling probabilities as low as 0.14. Apart from that, it is also the only approach to consistently form true consensus on tasks with multiple valid but non-equivalent solutions."}
{"id": "2511.12294", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12294", "abs": "https://arxiv.org/abs/2511.12294", "authors": ["Bodhisatwa Chatterjee", "Drew Zagieboylo", "Sana Damani", "Siva Hari", "Christos Kozyrakis"], "title": "ProofWright: Towards Agentic Formal Verification of CUDA", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to automatically generate optimized CUDA kernels, substantially improving developer productivity. However, despite rapid generation, these kernels often contain subtle correctness bugs and lack formal safety guarantees. Runtime testing is inherently unreliable - limited input coverage and reward hacking can mask incorrect behavior - while manual formal verification is reliable but cannot scale to match LLM output rates, creating a critical validation bottleneck.\n  We present ProofWright, an agentic verification framework that bridges this gap by integrating automated formal verification with LLM-based code generation. ProofWright provides end-to-end guarantees of memory safety, thread safety, and semantic correctness for LLM-generated CUDA kernels. On KernelBench L1, ProofWright verifies safety properties for 74% of generated kernels, uncovers subtle correctness errors missed by conventional testing, and establishes semantic equivalence for a class of element-wise kernels. With a modest overhead of 3 minutes per kernel, ProofWright demonstrates that scalable, automated formal verification of LLM-generated GPU code is feasible - offering a path toward trustworthy high-performance code generation without sacrificing developer productivity."}
{"id": "2511.12543", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12543", "abs": "https://arxiv.org/abs/2511.12543", "authors": ["Burak Karaduman", "Baris Tekin Tezel", "Moharram Challenger"], "title": "High-level reasoning while low-level actuation in Cyber-Physical Systems: How efficient is it?", "comment": null, "summary": "The increasing complexity of industrial information-integration systems demands software technologies that enable intelligent behaviour, real-time response, and efficient development. Although many programming languages and frameworks exist, engineers still lack sufficient empirical evidence to guide the choice of tools for advanced industrial applications. This study addresses that need by measuring and comparing worst-case execution time (WCET) and development time across six languages and frameworks: C++, Java, Jade, Jason, and fuzzy Jason BDI with both loosely and tightly coupled integration. These technologies reflect a progression from procedural and object-oriented programming to agent-based frameworks capable of symbolic and fuzzy reasoning.\n  Rather than relying on broad concepts such as paradigms or orientations, the study adopts a developer-centred approach grounded in measurable outcomes. The structured comparison examines how rising abstraction levels and reasoning capabilities affect both development effort and runtime behaviour. By analysing these dimensions, the study highlights concrete trade-offs between engineering workload and execution efficiency.\n  The findings show how abstraction and reasoning mechanisms shape system performance and developer productivity, offering practical insight for designing intelligent, agent-based solutions that must operate under real-time constraints and complex decision-making requirements. Overall, the study contributes evidence-based guidance for selecting software technologies in industrial informatization, supporting improved integration efficiency, maintainability, and responsiveness, and laying groundwork for future research on the interplay between language features, development dynamics, and runtime behaviour in cyber-physical and smart manufacturing systems."}
{"id": "2511.12576", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12576", "abs": "https://arxiv.org/abs/2511.12576", "authors": ["Mohammad Meymani", "Hamed Jelodar", "Parisa Hamedi", "Roozbeh Razavi-Far", "Ali A. Ghorbani"], "title": "Can Small GenAI Language Models Rival Large Language Models in Understanding Application Behavior?", "comment": null, "summary": "Generative AI (GenAI) models, particularly large language models (LLMs), have transformed multiple domains, including natural language processing, software analysis, and code understanding. Their ability to analyze and generate code has enabled applications such as source code summarization, behavior analysis, and malware detection. In this study, we systematically evaluate the capabilities of both small and large GenAI language models in understanding application behavior, with a particular focus on malware detection as a representative task. While larger models generally achieve higher overall accuracy, our experiments show that small GenAI models maintain competitive precision and recall, offering substantial advantages in computational efficiency, faster inference, and deployment in resource-constrained environments. We provide a detailed comparison across metrics such as accuracy, precision, recall, and F1-score, highlighting each model's strengths, limitations, and operational feasibility. Our findings demonstrate that small GenAI models can effectively complement large ones, providing a practical balance between performance and resource efficiency in real-world application behavior analysis."}
{"id": "2511.12635", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12635", "abs": "https://arxiv.org/abs/2511.12635", "authors": ["Lech Madeyski", "Barbara Kitchenham", "Martin Shepperd"], "title": "LLM4SCREENLIT: Recommendations on Assessing the Performance of Large Language Models for Screening Literature in Systematic Reviews", "comment": "19 pages, 4 figures", "summary": "Context: Large language models (LLMs) are released faster than users' ability to evaluate them rigorously. When LLMs underpin research, such as identifying relevant literature for systematic reviews (SRs), robust empirical assessment is essential. Objective: We identify and discuss key challenges in assessing LLM performance for selecting relevant literature, identify good (evaluation) practices, and propose recommendations. Method: Using a recent large-scale study as an example, we identify problems with the use of traditional metrics for assessing the performance of Gen-AI tools for identifying relevant literature in SRs. We analyzed 27 additional papers investigating this issue, extracted the performance metrics, and found both good practices and widespread problems, especially with the use and reporting of performance metrics for SR screening. Results: Major weaknesses included: i) a failure to use metrics that are robust to imbalanced data and do not directly indicate whether results are better than chance, e.g., the use of Accuracy, ii) a failure to consider the impact of lost evidence when making claims concerning workload savings, and iii) pervasive failure to report the full confusion matrix (or performance metrics from which it can be reconstructed) which is essential for future meta-analyses. On the positive side, we extract good (evaluation) practices on which our recommendations for researchers and practitioners, as well as policymakers, are built. Conclusions: SR screening evaluations should prioritize lost evidence/recall alongside chance-anchored and cost-sensitive Weighted MCC (WMCC) metric, report complete confusion matrices, treat unclassifiable outputs as referred-back positives for assessment, adopt leakage-aware designs with non-LLM baselines and open artifacts, and ground conclusions in cost-benefit analysis where FNs carry higher penalties than FPs."}
{"id": "2511.12823", "categories": ["cs.SE", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.12823", "abs": "https://arxiv.org/abs/2511.12823", "authors": ["Sajed Jalil", "Shuvo Saha", "Hossain Mohammad Seym"], "title": "Enhancing LLM Code Generation Capabilities through Test-Driven Development and Code Interpreter", "comment": "AACL-IJCNLP 2025 Workshop BLP Shared Task 2, 6 pages, 7 figures, 3 tables", "summary": "Over the past few years, improving LLM code generation capabilities has been a key focus in NLP research. Despite Bengali having 242 million native speakers worldwide, it receives little attention when it comes to training LLMs. More recently, various fine-tuning and augmented generation techniques have been employed to significantly enhance code generation performance. However, they require considerable expertise and resources to utilize effectively as an end user. The goal of our work is to democratize access to powerful code generation tools in resource-constrained emerging markets, enabling users to leverage them in their native language.\n  We introduce a novel approach that combines Test-Driven Development (TDD) and Code Interpreter (CI), utilizing open-weight models, which improves the baseline accuracy for code generation with Bengali prompts and achieves an overall accuracy of 85%. Our approach requires no finetuning and proves that even the smallest models in the same family can attain up to 98% accuracy compared to the largest models. All of our results are publicly shared in GitHub for validation and reproducibility."}
{"id": "2511.12856", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12856", "abs": "https://arxiv.org/abs/2511.12856", "authors": ["Anuradha Madugalla", "Jixuan Dong", "Kai Lyne Loi", "Matthew Crossman", "John Grundy"], "title": "Human-Centred Requirements Engineering for Critical Systems: Insights from Disaster Early Warning Applications", "comment": null, "summary": "Critical systems, such as those used in healthcare, defence, and disaster management, demand rigorous requirements engineering to ensure safety and reliability. Yet, much of this rigour has traditionally focused on technical assurance, often overlooking the human and social contexts in which these systems operate. This paper argues that considering human-centric aspects is an essential dimension of dependability, and presents a human-centred RE process designed to integrate social responsibility into critical system development. Drawing from a literature review, we identified a set of guidelines for designing software for vulnerable communities and translated these into sixty-two functional and non-functional requirements. These requirements were operationalised through the design of an adaptive early warning system prototype, which was subsequently evaluated through six interviews and eight cognitive walkthroughs to validate their relevance and applicability. The findings demonstrate that human-centric requirements, when addressed early, enhance the usability and accessibility of systems for all users. The paper concludes by positioning human-centricity not as an ethical add-on but as a defining quality of safe and equitable critical systems."}
{"id": "2511.12884", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12884", "abs": "https://arxiv.org/abs/2511.12884", "authors": ["Worawalan Chatlatanagulchai", "Hao Li", "Yutaro Kashiwa", "Brittany Reid", "Kundjanasith Thonglek", "Pattara Leelaprute", "Arnon Rungsawang", "Bundit Manaskasemsak", "Bram Adams", "Ahmed E. Hassan", "Hajimu Iida"], "title": "Agent READMEs: An Empirical Study of Context Files for Agentic Coding", "comment": null, "summary": "Agentic coding tools receive goals written in natural language as input, break them down into specific tasks, and write or execute the actual code with minimal human intervention. Central to this process are agent context files (\"READMEs for agents\") that provide persistent, project-level instructions. In this paper, we conduct the first large-scale empirical study of 2,303 agent context files from 1,925 repositories to characterize their structure, maintenance, and content. We find that these files are not static documentation but complex, difficult-to-read artifacts that evolve like configuration code, maintained through frequent, small additions. Our content analysis of 16 instruction types shows that developers prioritize functional context, such as build and run commands (62.3%), implementation details (69.9%), and architecture (67.7%). We also identify a significant gap: non-functional requirements like security (14.5%) and performance (14.5%) are rarely specified. These findings indicate that while developers use context files to make agents functional, they provide few guardrails to ensure that agent-written code is secure or performant, highlighting the need for improved tooling and practices."}
{"id": "2511.12950", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.12950", "abs": "https://arxiv.org/abs/2511.12950", "authors": ["Zirui Chen", "Zhipeng Xue", "Jiayuan Zhou", "Xing Hu", "Xin Xia", "Xiaohu Yang"], "title": "Diffploit: Facilitating Cross-Version Exploit Migration for Open Source Library Vulnerabilities", "comment": null, "summary": "Exploits are commonly used to demonstrate the presence of library vulnerabilities and validate their impact across different versions. However, their direct application to alternative versions often fails due to breaking changes introduced during evolution. These failures stem from both changes in triggering conditions (e.g., API refactorings) and broken dynamic environments (e.g., build or runtime errors), which are challenging to interpret and adapt manually. Existing techniques primarily focus on code-level trace alignment through fuzzing, which is both time-consuming and insufficient for handling environment-level failures. Moreover, they often fall short when dealing with complicated triggering condition changes across versions. To overcome this, we propose Diffploit, an iterative, diff-driven exploit migration method structured around two key modules: the Context Module and the Migration Module. The Context Module dynamically constructs contexts derived from analyzing behavioral discrepancies between the target and reference versions, which capture the failure symptom and its related diff hunks. Leveraging these contexts, the Migration Module guides an LLM-based adaptation through an iterative feedback loop, balancing exploration of diff candidates and gradual refinement to resolve reproduction failures effectively. We evaluate Diffploit on a large-scale dataset containing 102 Java CVEs and 689 version-migration tasks across 79 libraries. Diffploit successfully migrates 84.2% exploits, outperforming the change-aware test repair tool TARGET by 52.0% and the rule-based tool in IDEA by 61.6%. Beyond technical effectiveness, Diffploit identifies 5 CVE reports with incorrect affected version ranges, three of which have been confirmed. It also discovers 111 unreported vulnerable versions in the GitHub Advisory Database."}
{"id": "2511.12993", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12993", "abs": "https://arxiv.org/abs/2511.12993", "authors": ["Longfei Chen", "Ruibin Yan", "Taiyu Wong", "Yiyang Chen", "Chao Zhang"], "title": "SmartPoC: Generating Executable and Validated PoCs for Smart Contract Bug Reports", "comment": null, "summary": "Smart contracts are prone to vulnerabilities and are analyzed by experts as well as automated systems, such as static analysis and AI-assisted solutions. However, audit artifacts are heterogeneous and often lack reproducible, executable PoC tests suitable for automated validation, leading to costly, ad hoc manual verification. Large language models (LLMs) can be leveraged to turn audit reports into PoC test cases, but have three major challenges: noisy inputs, hallucinations, and missing runtime oracles. In this paper, we present SmartPoC, an automated framework that converts textual audit reports into executable, validated test cases. First, the input audit report is processed to reduce noise, and only bug-related functions are extracted and fed to LLMs as context. To curb hallucinations and ensure compile-and-run readiness, we leverage LLMs to synthesize PoC test cases with specially-designed pre-/post-execution repair. We further utilize differential verification as oracles to confirm exploitability of the PoC test cases. On the SmartBugs-Vul and FORGE-Vul benchmarks, SmartPoC generates executable, validated Foundry test cases for 85.61% and 86.45% of targets, respectively. Applied to the latest Etherscan verified-source corpus, SmartPoC confirms 236 real bugs out of 545 audit findings at a cost of only $0.03 per finding."}
{"id": "2511.13069", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13069", "abs": "https://arxiv.org/abs/2511.13069", "authors": ["Zhenyu Mao", "Jacky Keung", "Yicheng Sun", "Yifei Wang", "Shuo Liu", "Jialong Li"], "title": "Towards Requirements Engineering for GenAI-Enabled Software: Bridging Responsibility Gaps through Human Oversight Requirements", "comment": null, "summary": "Context: Responsibility gaps, long-recognized challenges in socio-technical systems where accountability becomes diffuse or ambiguous, have become increasingly pronounced in GenAI-enabled software. The generative and adaptive nature complicates how human oversight and responsibility are specified, delegated, and traced. Existing requirements engineering (RE) approaches remain limited in addressing these phenomena, revealing conceptual, methodological, and artifact-level research gaps.. Objective: This study aims to analyze these research gaps in the context of GenAI-enabled software systems. It seeks to establish a coherent perspective for a systematic analysis of responsibility gaps from a human oversight requirements standpoint, encompassing how these responsibility gaps should be conceptualized, identified, and represented throughout the RE process. Methods: The proposed design methodology is structured across three analytical layers. At the conceptualization layer, it establishes a conceptual framing that defines the key elements of responsibility across the human and system dimensions and explains how potential responsibility gaps emerge from their interactions. At the methodological layer, it introduces a deductive pipeline for identifying responsibility gaps by analyzing interactions between these dimensions and deriving corresponding oversight requirements within established RE frameworks. At the artifact layer, it formalizes the results in a Deductive Backbone Table, a reusable representation that traces the reasoning path from responsibility gaps identification to human oversight requirements derivation. Results: A user study compared the proposed methodology with a baseline goal-oriented RE across two scenarios. Evaluation across six dimensions indicated clear improvements of the proposed methodology, confirming its effectiveness in addressing three research gaps."}
{"id": "2511.13271", "categories": ["cs.SE", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13271", "abs": "https://arxiv.org/abs/2511.13271", "authors": ["Rufeng Chen", "Shuaishuai Jiang", "Jiyun Shen", "AJung Moon", "Lili Wei"], "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming", "comment": "9 pages, 4 figures, accepted at AIWARE 2025", "summary": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding."}
{"id": "2511.13305", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13305", "abs": "https://arxiv.org/abs/2511.13305", "authors": ["Rangeet Pan", "Raju Pavuluri", "Ruikai Huang", "Rahul Krishna", "Tyler Stennett", "Alessandro Orso", "Saurabh SInha"], "title": "SAINT: Service-level Integration Test Generation with Program Analysis and LLM-based Agents", "comment": "Accepted at ICSE'26", "summary": "Enterprise applications are typically tested at multiple levels, with service-level testing playing an important role in validating application functionality. Existing service-level testing tools, especially for RESTful APIs, often employ fuzzing and/or depend on OpenAPI specifications which are not readily available in real-world enterprise codebases. Moreover, these tools are limited in their ability to generate functional tests that effectively exercise meaningful scenarios. In this work, we present SAINT, a novel white-box testing approach for service-level testing of enterprise Java applications. SAINT combines static analysis, large language models (LLMs), and LLM-based agents to automatically generate endpoint and scenario-based tests. The approach builds two key models: an endpoint model, capturing syntactic and semantic information about service endpoints, and an operation dependency graph, capturing inter-endpoint ordering constraints. SAINT then employs LLM-based agents to generate tests. Endpoint-focused tests aim to maximize code and database interaction coverage. Scenario-based tests are synthesized by extracting application use cases from code and refining them into executable tests via planning, action, and reflection phases of the agentic loop. We evaluated SAINT on eight Java applications, including a proprietary enterprise application. Our results illustrate the effectiveness of SAINT in coverage, fault detection, and scenario generation. Moreover, a developer survey provides strong endorsement of the scenario-based tests generated by SAINT. Overall, our work shows that combining static analysis with agentic LLM workflows enables more effective, functional, and developer-aligned service-level test generation."}
{"id": "2511.13318", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13318", "abs": "https://arxiv.org/abs/2511.13318", "authors": ["Peihao Li"], "title": "LinkXplore: A Framework for Affordable High-Quality Blockchain Data", "comment": null, "summary": "Blockchain technologies are rapidly transforming both academia and industry. However, large-scale blockchain data collection remains prohibitively expensive, as many RPC providers only offer enhanced APIs with high pricing tiers that are unsuitable for budget-constrained research or industrial-scale applications, which has significantly slowed down academic studies and product development. Moreover, there is a clear lack of a systematic framework that allows flexible integration of new modules for analyzing on-chain data.\n  To address these challenges, we introduce LinkXplore, the first open framework for collecting and managing on-chain data. LinkXplore enables users to bypass costly blockchain data providers by directly analyzing raw data from RPC queries or streams, thereby offering high-quality blockchain data at a fraction of the cost. Through a simple API and backend processing logic, any type of chain data can be integrated into the framework. This makes it a practical alternative for both researchers and developers with limited budgets. Code and dataset used in this project are publicly available at https://github.com/Linkis-Project/LinkXplore"}
{"id": "2511.13341", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13341", "abs": "https://arxiv.org/abs/2511.13341", "authors": ["Zihe Yan", "Kai Luo", "Haoyu Yang", "Yang Yu", "Zhuosheng Zhang", "Guancheng Li"], "title": "An LLM-based Quantitative Framework for Evaluating High-Stealthy Backdoor Risks in OSS Supply Chains", "comment": "7 figures, 4 tables, conference", "summary": "In modern software development workflows, the open-source software supply chain contributes significantly to efficient and convenient engineering practices. With increasing system complexity, using open-source software as third-party dependencies has become a common practice. However, the lack of maintenance for underlying dependencies and insufficient community auditing create challenges in ensuring source code security and the legitimacy of repository maintainers, especially under high-stealthy backdoor attacks exemplified by the XZ-Util incident. To address these problems, we propose a fine-grained project evaluation framework for backdoor risk assessment in open-source software. The framework models stealthy backdoor attacks from the viewpoint of the attacker and defines targeted metrics for each attack stage. In addition, to overcome the limitations of static analysis in assessing the reliability of repository maintenance activities such as irregular committer privilege escalation and limited participation in reviews, the framework uses large language models (LLMs) to conduct semantic evaluation of code repositories without relying on manually crafted patterns. The framework is evaluated on sixty six high-priority packages in the Debian ecosystem. The experimental results indicate that the current open-source software supply chain is exposed to various security risks."}
{"id": "2511.13357", "categories": ["cs.SE", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.13357", "abs": "https://arxiv.org/abs/2511.13357", "authors": ["Dmitry Moskalev"], "title": "FLOWER: Flow-Oriented Entity-Relationship Tool", "comment": "12 pages, 8 figures", "summary": "Exploring relationships across data sources is a crucial optimization for entities recognition. Since databases can store big amount of information with synthetic and organic data, serving all quantity of objects correctly is an important task to deal with. However, the decision of how to construct entity relationship model is associated with human factor. In this paper, we present flow-oriented entity-relationship tool. This is first and unique end-to-end solution that eliminates routine and resource-intensive problems of processing, creating and visualizing both of explicit and implicit dependencies for prominent SQL dialects on-the-fly. Once launched, FLOWER automatically detects built-in constraints and starting to create own correct and necessary one using dynamic sampling and robust data analysis techniques. This approach applies to improve entity-relationship model and data storytelling to better understand the foundation of data and get unseen insights from DB sources using SQL or natural language. Evaluated on state-of-the-art STATS benchmark, experiments show that FLOWER is superior to reservoir sampling by 2.4x for distribution representation and 2.6x for constraint learning with 2.15x acceleration. For data storytelling, our tool archives 1.19x for accuracy enhance with 1.86x context decrease compare to LLM. Presented tool is also support 23 languages and compatible with both of CPU and GPU. Those results show that FLOWER can manage with real-world data a way better to ensure with quality, scalability and applicability for different use-cases."}
{"id": "2511.13611", "categories": ["cs.SE", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.13611", "abs": "https://arxiv.org/abs/2511.13611", "authors": ["Torec T. Luik", "Joost de Folter", "Rodrigo Rosas-Bertolini", "Eric A. J. Reits", "Ron A. Hoebe", "Przemek M. Krawczyk"], "title": "BIOMERO 2.0: end-to-end FAIR infrastructure for bioimaging data import, analysis, and provenance", "comment": "16 pages, 2 figures, 25 pages supplemental information; for software, see https://github.com/Cellular-Imaging-Amsterdam-UMC/NL-BIOMERO", "summary": "We present BIOMERO 2.0, a major evolution of the BIOMERO framework that transforms OMERO into a FAIR-compliant (findable, accessible, interoperable, and reusable), provenance-aware bioimaging platform. BIOMERO 2.0 integrates data import, preprocessing, analysis, and workflow monitoring through an OMERO.web plugin and containerized components. The importer subsystem facilitates in-place import using containerized preprocessing and metadata enrichment via forms, while the analyzer subsystem coordinates and tracks containerized analyses on high-performance computing systems via the BIOMERO Python library. All imports and analyses are recorded with parameters, versions, and results, ensuring real-time provenance accessible through integrated dashboards. This dual approach places OMERO at the heart of the bioimaging analysis process: the importer ensures provenance from image acquisition through preprocessing and import into OMERO, while the analyzer records it for downstream processing. These integrated layers enhance OMEROs FAIRification, supporting traceable, reusable workflows for image analysis that bridge the gap between data import, analysis, and sharing."}
{"id": "2511.13646", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13646", "abs": "https://arxiv.org/abs/2511.13646", "authors": ["Chunqiu Steven Xia", "Zhe Wang", "Yan Yang", "Yuxiang Wei", "Lingming Zhang"], "title": "Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?", "comment": null, "summary": "Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that Live-SWE-agent can achieve an impressive solve rate of 75.4% without test-time scaling, outperforming all existing open-source software agents and approaching the performance of the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%."}
{"id": "2511.13656", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.13656", "abs": "https://arxiv.org/abs/2511.13656", "authors": ["Marvin Wyrich", "Lloyd Montgomery"], "title": "What's in a Software Engineering Job Posting?", "comment": "Accepted to the 48th International Conference on Software Engineering (ICSE 2026) Research Track", "summary": "A well-rounded software engineer is often defined by technical prowess and the ability to deliver on complex projects. However, the narrative around the ideal Software Engineering (SE) candidate is evolving, suggesting that there is more to the story. This article explores the non-technical aspects emphasized in SE job postings, revealing the sociotechnical and organizational expectations of employers. Our Thematic Analysis of 100 job postings shows that employers seek candidates who align with their sense of purpose, fit within company culture, pursue personal and career growth, and excel in interpersonal interactions. This study contributes to ongoing discussions in the SE community about the evolving role and workplace context of software engineers beyond technical skills. By highlighting these expectations, we provide relevant insights for researchers, educators, practitioners, and recruiters. Additionally, our analysis offers a valuable snapshot of SE job postings in 2023, providing a scientific record of prevailing trends and expectations."}
{"id": "2511.13661", "categories": ["cs.SE", "cs.FL"], "pdf": "https://arxiv.org/pdf/2511.13661", "abs": "https://arxiv.org/abs/2511.13661", "authors": ["Francisco Abreu", "Luís Cruz", "Sérgio Guerreiro"], "title": "Ontology-Driven Model-to-Model Transformation of Workflow Specifications", "comment": null, "summary": "Proprietary workflow modeling languages such as Smart Forms & Smart Flow hamper interoperability and reuse because they lock process knowledge into closed formats. To address this vendor lock-in and ease migration to open standards, we introduce an ontology-driven model-to-model pipeline that systematically translates domain-specific workflow definitions to Business Process Model and Notation (BPMN) 2.0. The pipeline comprises three phases: RML-based semantic lifting of JSON to RDF/OWL, ontology alignment and reasoning, and BPMN generation via the Camunda Model API. By externalizing mapping knowledge into ontologies and declarative rules rather than code, the approach supports reusability across vendor-specific formats and preserves semantic traceability between source definitions and target BPMN models. We instantiated the pipeline for Instituto Superior Técnico (IST)'s Smart Forms & Smart Flow and implemented a converter that produces standard-compliant BPMN diagrams. Evaluation on a corpus of 69 real-world workflows produced 92 BPMN diagrams with a 94.2% success rate. Failures (5.81%) stemmed from dynamic behaviors and time-based transitions not explicit in the static JSON. Interviews with support and development teams indicated that the resulting diagrams provide a top-down view that improves comprehension, diagnosis and onboarding by exposing implicit control flow and linking tasks and forms back to their sources. The pipeline is generalizable to other proprietary workflow languages by adapting the ontology and mappings, enabling interoperability and reducing vendor dependency while supporting continuous integration and long-term maintainability. The presented case study demonstrates that ontology-driven M2M transformation can systematically bridge domain-specific workflows and standard notations, offering quantifiable performance and qualitative benefits for stakeholders."}
