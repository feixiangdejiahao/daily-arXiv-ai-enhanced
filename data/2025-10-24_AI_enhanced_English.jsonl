{"id": "2510.19860", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19860", "abs": "https://arxiv.org/abs/2510.19860", "authors": ["Ketai Qiu", "Luca Di Grazia", "Leonardo Mariani", "Mauro Pezz\u00e8"], "title": "E-Test: E'er-Improving Test Suites", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "Test suites are inherently imperfect, and testers can always enrich a suite\nwith new test cases that improve its quality and, consequently, the reliability\nof the target software system. However, finding test cases that explore\nexecution scenarios beyond the scope of an existing suite can be extremely\nchallenging and labor-intensive, particularly when managing large test suites\nover extended periods.\n  In this paper, we propose E-Test, an approach that reduces the gap between\nthe execution space explored with a test suite and the executions experienced\nafter testing by augmenting the test suite with test cases that explore\nexecution scenarios that emerge in production. E-Test (i) identifies executions\nthat have not yet been tested from large sets of scenarios, such as those\nmonitored during intensive production usage, and (ii) generates new test cases\nthat enhance the test suite. E-Test leverages Large Language Models (LLMs) to\npinpoint scenarios that the current test suite does not adequately cover, and\naugments the suite with test cases that execute these scenarios.\n  Our evaluation on a dataset of 1,975 scenarios, collected from highly-starred\nopen-source Java projects already in production and Defects4J, demonstrates\nthat E-Test retrieves not-yet-tested execution scenarios significantly better\nthan state-of-the-art approaches. While existing regression testing and field\ntesting approaches for this task achieve a maximum F1-score of 0.34, and\nvanilla LLMs achieve a maximum F1-score of 0.39, E-Test reaches 0.55. These\nresults highlight the impact of E-Test in enhancing test suites by effectively\ntargeting not-yet-tested execution scenarios and reducing manual effort\nrequired for maintaining test suites.", "AI": {"tldr": "E-Test leverages LLMs to discover and generate test cases for production scenarios not covered by existing test suites. It achieves superior results over current methods, enhancing software reliability and reducing testers' manual workload.", "motivation": "Test suites often fail to fully cover all possible execution scenarios, especially as software evolves and new scenarios emerge in production. Identifying and creating new test cases to cover these undiscovered scenarios is highly labor-intensive, particularly for large and long-lived projects.", "method": "The authors propose E-Test, an approach that uses Large Language Models (LLMs) to identify execution scenarios not yet covered by the current test suite, by analyzing scenarios gathered from production usage. E-Test then generates new test cases specifically targeting these uncovered scenarios to augment the test suite.", "result": "E-Test was evaluated on 1,975 scenarios from popular open-source Java projects and the Defects4J dataset. It significantly outperformed previous state-of-the-art methods and vanilla LLMs, achieving an F1-score of 0.55 compared to 0.34 (state-of-the-art) and 0.39 (vanilla LLMs) in retrieving not-yet-tested scenarios.", "conclusion": "E-Test efficiently augments test suites by automatically targeting and testing execution scenarios not covered by existing tests, outperforming current approaches and reducing manual effort required for comprehensive testing."}}
{"id": "2510.19864", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19864", "abs": "https://arxiv.org/abs/2510.19864", "authors": ["Amila Indika", "Igor Molybog"], "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "comment": "14 pages, 5 figures, 4 tables", "summary": "Numerous knowledge workers utilize spreadsheets in business, accounting, and\nfinance. However, a lack of systematic documentation methods for spreadsheets\nhinders automation, collaboration, and knowledge transfer, which risks the loss\nof crucial institutional knowledge. This paper introduces Spreadsheet\nOperations Documentation (SOD), an AI task that involves generating\nhuman-readable explanations from spreadsheet operations. Many previous studies\nhave utilized Large Language Models (LLMs) for generating spreadsheet\nmanipulation code; however, translating that code into natural language for SOD\nis a less-explored area. To address this, we present a benchmark of 111\nspreadsheet manipulation code snippets, each paired with a corresponding\nnatural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini,\nLLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and\nMETEOR metrics. Our findings suggest that LLMs can generate accurate\nspreadsheet documentation, making SOD a feasible prerequisite step toward\nenhancing reproducibility, maintainability, and collaborative workflows in\nspreadsheets, although there are challenges that need to be addressed.", "AI": {"tldr": "The paper introduces an AI task for generating natural language documentation from spreadsheet operations, evaluates five LLMs on a new benchmark, and finds that they can accurately explain spreadsheet code, paving the way for better collaboration and knowledge management, albeit with some remaining challenges.", "motivation": "Spreadsheets are widely used by knowledge workers, but their lack of systematic documentation impedes automation, knowledge transfer, and collaboration. This creates a risk of losing institutional knowledge, motivating the need for automated and comprehensible spreadsheet documentation methods.", "method": "The paper defines Spreadsheet Operations Documentation (SOD) as an AI task that generates human-readable explanations for spreadsheet operations. It introduces a new benchmark dataset of 111 spreadsheet code snippets paired with natural language summaries. The study evaluates five large language models (LLMs)\u2014GPT-4o, GPT-4o-mini, LLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B\u2014using BLEU, GLEU, ROUGE-L, and METEOR for performance assessment.", "result": "The results indicate that LLMs can effectively generate accurate and useful documentation for spreadsheet operations. However, the study also highlights certain challenges that need further attention for widespread adoption and robust performance.", "conclusion": "AI-driven natural language documentation for spreadsheets is feasible and has potential to improve reproducibility, maintainability, and collaborative workflows, although additional work is needed to tackle existing challenges."}}
{"id": "2510.19868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19868", "abs": "https://arxiv.org/abs/2510.19868", "authors": ["Qian Xiong", "Bo Yang", "Weisong Sun", "Yiran Zhang", "Tianlin Li", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "comment": null, "summary": "Automated code generation driven by Large Lan- guage Models (LLMs) has\nenhanced development efficiency, yet generating complex application-level\nsoftware code remains challenging. Multi-agent frameworks show potential, but\nexisting methods perform inadequately in large-scale application-level software\ncode generation, failing to ensure reasonable orga- nizational structures of\nproject code and making it difficult to maintain the code generation process.\nTo address this, this paper envisions a Knowledge-Guided Application-Level Code\nGeneration framework named KGACG, which aims to trans- form software\nrequirements specification and architectural design document into executable\ncode through a collaborative closed- loop of the Code Organization & Planning\nAgent (COPA), Coding Agent (CA), and Testing Agent (TA), combined with a\nfeedback mechanism. We demonstrate the collaborative process of the agents in\nKGACG in a Java Tank Battle game case study while facing challenges. KGACG is\ndedicated to advancing the automation of application-level software\ndevelopment.", "AI": {"tldr": "KGACG is a new multi-agent framework designed to automate the generation of complex, large-scale application-level software. It uses cooperative agents for planning, coding, and testing, demonstrating its effectiveness with a Java game, and aims to resolve the organizational and process maintenance issues seen in previous LLM-driven code generation.", "motivation": "Although Large Language Models have improved code generation, creating large, complex application-level software still faces major hurdles, such as maintaining organizational code structure and managing the generation process.", "method": "The authors propose KGACG, a Knowledge-Guided Application-Level Code Generation framework, involving three agents (Code Organization & Planning Agent, Coding Agent, Testing Agent) working collaboratively with a feedback mechanism to transform software requirements and architecture into executable code.", "result": "They showcase the framework\u2019s collaborative process using a Java Tank Battle game as a case study, highlighting how agents interact and address development challenges.", "conclusion": "KGACG represents progress toward fully automated application-level code generation, especially for large projects, by improving code organization, planning, and maintainability through agent collaboration and knowledge guidance."}}
{"id": "2510.19898", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19898", "abs": "https://arxiv.org/abs/2510.19898", "authors": ["Atharv Sonwane", "Isadora White", "Hyunji Lee", "Matheus Pereira", "Lucas Caccia", "Minseon Kim", "Zhengyan Shi", "Chinmay Singh", "Alessandro Sordoni", "Marc-Alexandre C\u00f4t\u00e9", "Xingdi Yuan"], "title": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "comment": null, "summary": "High quality bugs are key to training the next generation of language model\nbased software engineering (SWE) agents. We introduce a novel method for\nsynthetic generation of difficult and diverse bugs. Our method instructs SWE\nAgents to introduce a feature into the codebase whereby they may\nunintentionally break tests, resulting in bugs. Prior approaches often induce\nan out-of-distribution effect by generating bugs intentionally (e.g. by\nintroducing local perturbation to existing code), which does not reflect\nrealistic development processes. We perform qualitative analysis to demonstrate\nthat our approach for generating bugs more closely reflects the patterns found\nin human-authored edits. Through extensive experiments, we demonstrate that our\nbugs provide more efficient training data for supervised fine-tuning,\noutperforming other bug datasets by 2% with half the training data (1.2k vs. 3k\nbugs). We train on our newly generated bugs in addition to existing bug\ndatasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench\nVerified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on\nSWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over\nthree seeds.", "AI": {"tldr": "A novel synthetic bug generation method produces more realistic bugs by instructing agents to add features that accidentally break tests. This yields better SWE agent models with less training data, setting new performance benchmarks.", "motivation": "Training large language models as software engineering agents requires high-quality, realistic bugs in datasets, but previous synthetic bug generation methods often fail to accurately simulate real-world development mistakes.", "method": "The authors propose a new synthetic bug generation method where SWE Agents are instructed to add new features that may unintentionally break tests, resulting in more realistic, diverse, and challenging bugs that mirror human editing patterns.", "result": "Qualitative analysis confirms that generated bugs align more closely with human-authored errors. Experiments show that these bugs yield superior training efficiency, enabling better model performance with fewer training samples. Training with this dataset helped produce state-of-the-art results on SWE-bench Verified benchmarks for both FrogBoss (32B model) with a pass@1 of 54.6% and FrogMini (14B model) with pass@1 of 45.3%.", "conclusion": "The proposed bug generation approach creates more realistic and challenging bugs, leading to more efficient language model training and state-of-the-art results on SWE-bench Verified."}}
{"id": "2510.19850", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.19850", "abs": "https://arxiv.org/abs/2510.19850", "authors": ["Mostapha Kalami Heris"], "title": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs", "comment": null, "summary": "Large Language Models (LLMs) are central to reasoning, writing, and\ndecision-support workflows, yet users lack consistent control over how they\nreason and express outputs. Conventional prompt engineering relies on verbose\nnatural-language instructions, limiting reproducibility, modularity, and\ninterpretability. This paper introduces Prompt Decorators, a declarative,\ncomposable syntax that governs LLM behavior through compact control tokens such\nas +++Reasoning, +++Tone(style=formal), and +++Import(topic=\"Systems\nThinking\"). Each decorator modifies a behavioral dimension, such as reasoning\nstyle, structure, or tone, without changing task content. The framework\nformalizes twenty core decorators organized into two functional families\n(Cognitive & Generative and Expressive & Systemic), each further decomposed\ninto subcategories that govern reasoning, interaction, expression, and\nsession-control. It defines a unified syntax, scoping model, and deterministic\nprocessing pipeline enabling predictable and auditable behavior composition. By\ndecoupling task intent from execution behavior, Prompt Decorators create a\nreusable and interpretable interface for prompt design. Illustrative use cases\ndemonstrate improved reasoning transparency, reduced prompt complexity, and\nstandardized model behavior across domains. The paper concludes with\nimplications for interoperability, behavioral consistency, and the development\nof declarative interfaces for scalable AI systems.", "AI": {"tldr": "This paper proposes Prompt Decorators\u2014a concise, modular way to control LLM reasoning and expression using structured tokens\u2014demonstrating improved transparency, reproducibility, and standardized outputs compared to traditional prompt engineering.", "motivation": "Users of Large Language Models (LLMs) currently lack consistent, interpretable means to control model reasoning and output style. Conventional prompt engineering is verbose and limits reproducibility, modularity, and interpretability.", "method": "The paper introduces Prompt Decorators: a declarative, composable syntax using control tokens to govern LLM behavior (such as reasoning style, tone, and structure). The framework formalizes 20 decorators across two functional families, defines a unified syntax, scoping, and processing pipeline for predictable behavior composition.", "result": "Prompt Decorators enable auditable, interpretable, and reusable prompt designs. Use cases illustrate improved reasoning transparency, reduced prompt complexity, and standardized behavior across various domains.", "conclusion": "Prompt Decorators allow decoupling of task intent from execution behavior, promoting reproducibility, transparency, and standardized control over LLM outputs. They provide a scalable, declarative interface for designing AI interactions, with implications for interoperability and consistency."}}
{"id": "2510.19984", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19984", "abs": "https://arxiv.org/abs/2510.19984", "authors": ["Konstantinos Kitsios", "Marcel B\u00f6hme", "Alberto Bacchelli"], "title": "On Interaction Effects in Greybox Fuzzing", "comment": "12 pages, 2 figures, Accepted for presentation at the 48th\n  International Conference on Software Engineering (ICSE '26)", "summary": "A greybox fuzzer is an automated software testing tool that generates new\ntest inputs by applying randomly chosen mutators (e.g., flipping a bit or\ndeleting a block of bytes) to a seed input in random order and adds all\ncoverage-increasing inputs to the corpus of seeds. We hypothesize that the\norder in which mutators are applied to a seed input has an impact on the\neffectiveness of greybox fuzzers. In our experiments, we fit a linear model to\na dataset that contains the effectiveness of all possible mutator pairs and\nindeed observe the conjectured interaction effect. This points us to more\nefficient fuzzing by choosing the most promising mutator sequence with a higher\nlikelihood. We propose MuoFuzz, a greybox fuzzer that learns and chooses the\nmost promising mutator sequences. MuoFuzz learns the conditional probability\nthat the next mutator will yield an interesting input, given the previously\nselected mutator. Then, it samples from the learned probability using a random\nwalk to generate mutator sequences. We compare the performance of MuoFuzz to\nAFL++, which uses a fixed selection probability, and MOPT, which optimizes the\nselection probability of each mutator in isolation. Experimental results on the\nFuzzBench and MAGMA benchmarks show that MuoFuzz achieves the highest code\ncoverage and finds four bugs missed by AFL++ and one missed by both AFL++ and\nMOPT.", "AI": {"tldr": "This paper shows that the order of mutator application in greybox fuzzers matters. Introducing MuoFuzz, a fuzzer that learns effective mutator sequences, the authors demonstrate superior bug finding and code coverage compared to existing tools.", "motivation": "Greybox fuzzers typically apply random mutators in random order, but the order may affect fuzzing effectiveness. The paper seeks to investigate whether choosing mutator sequences more intelligently improves results.", "method": "Fit a linear model to analyze interaction effects between mutator pairs; develop MuoFuzz, a greybox fuzzer that learns optimal mutator sequences via conditional probability and random walk sampling.", "result": "MuoFuzz achieves the highest code coverage on FuzzBench and MAGMA benchmarks, discovering four bugs missed by AFL++ and one missed by both AFL++ and MOPT.", "conclusion": "Strategic selection and learning of mutator sequences can greatly enhance the performance of greybox fuzzers over conventional random or isolated mutator selection approaches."}}
{"id": "2510.19853", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.19853", "abs": "https://arxiv.org/abs/2510.19853", "authors": ["Assaf Marron", "David Harel"], "title": "A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification", "comment": null, "summary": "An algorithm specification in natural language or pseudocode is expected to\nbe clear and explicit enough to enable mechanical execution. In this position\npaper we contribute an initial characterization of the knowledge that an\nexecuting agent, human or machine, should possess in order to be able to carry\nout the instructions of a given algorithm specification as a stand-alone\nentity, independent of any system implementation. We argue that, for that\nalgorithm specification, such prerequisite knowledge, whether unique or shared\nwith other specifications, can be summarized in a document of practical size.\nWe term this document the realm of the algorithm specification. The generation\nof such a realm is itself a systematic analytical process, significant parts of\nwhich can be automated with the help of large language models and the reuse of\nexisting documents. The algorithm-specification's realm would consist of\nspecification language syntax and semantics, domain knowledge restricted to the\nreferenced entities, inter-entity relationships, relevant underlying\ncause-and-effect rules, and detailed instructions and means for carrying out\ncertain operations. Such characterization of the realm can contribute to\nmethodological implementation of the algorithm specification in diverse systems\nand to its formalization for mechanical verification. The paper also touches\nupon the question of assessing execution faithfulness, which is distinct from\ncorrectness: in the absence of a reference interpretation of natural language\nor pseudocode specification with a given vocabulary, how can we determine if an\nobserved agent's execution indeed complies with the input specification.", "AI": {"tldr": "This paper introduces the concept of an \"algorithm realm\": a document cataloging all background knowledge necessary for executing algorithms written in natural language or pseudocode. It discusses how the realm can be systematically created (partly automated by AI), aiding implementation, verification, and the assessment of faithful execution by agents.", "motivation": "The motivation is to clarify what knowledge an executing agent needs to possess in order to reliably and independently execute algorithm specifications written in natural language or pseudocode.", "method": "The paper presents a conceptual framework, introducing the idea of the \"realm\" of an algorithm specification. This involves cataloging necessary knowledge, such as language syntax, semantics, domain entities, relationships, and operational instructions. It further discusses how generating this realm can be partially automated using large language models and reuse of existing documentation.", "result": "The paper proposes that the realm concept helps systematically characterize and document the background knowledge needed for correct execution of algorithm specifications. This approach facilitates algorithm implementation in various systems and shapes the process for mechanical verification. It also distinguishes execution faithfulness from correctness, raising methods for their assessment.", "conclusion": "The realm concept provides a practical means to document, formalize, and verify the knowledge required for executing algorithm specifications, supporting both methodological implementations and faithfulness assessment independent of specific system implementations."}}
{"id": "2510.19997", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19997", "abs": "https://arxiv.org/abs/2510.19997", "authors": ["Abraham Itzhak Weinberg"], "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) presents transformative\nopportunities for organizations, yet both midsize organizations and larger\nenterprises face distinctive adoption challenges. Midsize organizations\nencounter resource constraints and limited AI expertise, while enterprises\nstruggle with organizational complexity and coordination challenges. Existing\ntechnology adoption frameworks, including TAM (Technology Acceptance Model),\nTOE (Technology Organization Environment), and DOI (Diffusion of Innovations)\ntheory, lack the specificity required for GenAI implementation across these\ndiverse contexts, creating a critical gap in adoption literature. This paper\nintroduces FAIGMOE (Framework for the Adoption and Integration of Generative AI\nin Midsize Organizations and Enterprises), a conceptual framework addressing\nthe unique needs of both organizational types. FAIGMOE synthesizes technology\nadoption theory, organizational change management, and innovation diffusion\nperspectives into four interconnected phases: Strategic Assessment, Planning\nand Use Case Development, Implementation and Integration, and\nOperationalization and Optimization. Each phase provides scalable guidance on\nreadiness assessment, strategic alignment, risk governance, technical\narchitecture, and change management adaptable to organizational scale and\ncomplexity. The framework incorporates GenAI specific considerations including\nprompt engineering, model orchestration, and hallucination management that\ndistinguish it from generic technology adoption frameworks. As a perspective\ncontribution, FAIGMOE provides the first comprehensive conceptual framework\nexplicitly addressing GenAI adoption across midsize and enterprise\norganizations, offering actionable implementation protocols, assessment\ninstruments, and governance templates requiring empirical validation through\nfuture research.", "AI": {"tldr": "This paper introduces FAIGMOE, a four-phase framework to guide midsize and enterprise organizations in adopting Generative AI. FAIGMOE addresses unique challenges and GenAI-specific requirements, offering practical protocols and templates, but its effectiveness awaits empirical validation.", "motivation": "Existing technology adoption frameworks lack specificity for successful GenAI implementation in midsize and enterprise organizations. Distinct challenges\u2014such as resource constraints for midsize organizations and organizational complexity for enterprises\u2014necessitate a tailored approach to GenAI adoption.", "method": "The paper introduces FAIGMOE, a new conceptual framework specifically designed for the adoption and integration of GenAI in midsize and enterprise organizations. FAIGMOE synthesizes technology adoption theories, change management, and innovation diffusion into four implementation phases. It also integrates GenAI-specific concerns like prompt engineering and hallucination management.", "result": "The FAIGMOE framework offers scalable, actionable protocols for GenAI adoption, including readiness assessment, strategic alignment, risk governance, technical architecture, and change management. It provides detailed implementation guidance, assessment instruments, and governance templates, but requires empirical validation in future research.", "conclusion": "FAIGMOE represents the first comprehensive conceptual framework tailored for GenAI adoption in midsize and enterprise organizations. It addresses previously unmet needs, filling a critical gap in existing literature and offering practitioners structured support for GenAI integration."}}
{"id": "2510.20018", "categories": ["cs.PL", "68N18 (Primary), 03B70 (Secondary)", "F.3.3; D.3.1"], "pdf": "https://arxiv.org/pdf/2510.20018", "abs": "https://arxiv.org/abs/2510.20018", "authors": ["Ryan Kavanagh", "Chuta Sano", "Brigitte Pientka"], "title": "Deconstructed Proto-Quipper: A Rational Reconstruction", "comment": "Submitted to the 35th European Symposium on Programming (ESOP 2026)", "summary": "The Proto-Quipper family of programming languages aims to provide a formal\nfoundation for the Quipper quantum programming language. Unfortunately,\nProto-Quipper languages have complex operational semantics: they are inherently\neffectful, and they rely on set-theoretic operations and fresh name generation\nto manipulate quantum circuits. This makes them difficult to reason about using\nstandard programming language techniques and, ultimately, to mechanize. We\nintroduce Proto-Quipper-A, a rational reconstruction of Proto-Quipper languages\nfor static circuit generation. It uses a linear $\\lambda$-calculus to describe\nquantum circuits with normal forms that closely correspond to box-and-wire\ncircuit diagrams. Adjoint-logical foundations integrate this circuit language\nwith a linear/non-linear functional language and let us reconstruct\nProto-Quipper's circuit programming abstractions using more primitive\nadjoint-logical operations. Proto-Quipper-A enjoys a simple call-by-value\nreduction semantics, and to illustrate its tractability as a foundation for\nProto-Quipper languages, we show that it is normalizing. We show how to use\nstandard logical relations to prove normalization of linear and substructural\nsystems, thereby avoiding the inherent complexity of existing linear logical\nrelations.", "AI": {"tldr": "Proto-Quipper-A simplifies the semantics of Proto-Quipper quantum languages, making them easier to reason about and formalize by introducing a normalizing, call-by-value language grounded in linear lambda calculus and standard logical relations.", "motivation": "The motivation is to address the complexity and mechanization challenges in the operational semantics of Proto-Quipper quantum programming languages, which are made difficult by their effectful nature and reliance on set-theoretic operations and name generation when handling quantum circuits.", "method": "The paper introduces Proto-Quipper-A, a reconstructed language based on linear lambda calculus. It incorporates adjoint-logical foundations to integrate circuit languages with functional languages, aiming for a simpler and more tractable semantics. The paper also employs standard logical relations for proving normalization, as opposed to more complex existing methods.", "result": "Proto-Quipper-A achieves a simple call-by-value reduction semantics and is proven to be normalizing using standard logical relations. This simplicity and the normalizing property demonstrate Proto-Quipper-A's tractability as a foundational language for the Proto-Quipper family.", "conclusion": "Proto-Quipper-A provides a more accessible and formally manageable semantic foundation for Proto-Quipper languages, enabling easier reasoning and mechanization for quantum circuit programming via normalization and simpler semantic structures."}}
{"id": "2510.20041", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20041", "abs": "https://arxiv.org/abs/2510.20041", "authors": ["Gareema Ranjan", "Mahmoud Alfadel", "Gengyi Sun", "Shane McIntosh"], "title": "The Cost of Downgrading Build Systems: A Case Study of Kubernetes", "comment": null, "summary": "Since developers invoke the build system frequently, its performance can\nimpact productivity. Modern artifact-based build tools accelerate builds, yet\nprior work shows that teams may abandon them for alternatives that are easier\nto maintain. While prior work shows why downgrades are performed, the\nimplications of downgrades remain largely unexplored. In this paper, we\ndescribe a case study of the Kubernetes project, focusing on its downgrade from\nan artifact-based build tool (Bazel) to a language-specific solution (Go\nBuild). We reproduce and analyze the full and incremental builds of change sets\nduring the downgrade period. On the one hand, we find that Bazel builds are\nfaster than Go Build, completing full builds in 23.06-38.66 up to 75.19 impose\na larger memory footprint than Go Build of 81.42-351.07 respectively. Bazel\nbuilds also impose a greater CPU load at parallelism settings above eight for\nfull builds and above one for incremental builds. We estimate that downgrading\nfrom Bazel can increase CI resource costs by up to 76 explore whether our\nobservations generalize by replicating our Kubernetes study on four other\nprojects that also downgraded from Bazel to older build tools. We observe that\nwhile build time penalties decrease, Bazel consistently consumes more memory.\nWe conclude that abandoning artifact-based build tools, despite perceived\nmaintainability benefits, tends to incur considerable performance costs for\nlarge projects. Our observations may help stakeholders to balance trade-offs in\nbuild tool adoption", "AI": {"tldr": "Switching from Bazel (fast, high-resource artifact-based build tool) to Go Build (slower, simpler) in Kubernetes and other projects leads to longer builds and higher resource costs, despite improved maintainability. The study warns that abandoning artifact-based tools can bring notable performance penalties.", "motivation": "Developers frequently use build systems, so their performance is critical. Although modern artifact-based build tools speed up builds, teams sometimes revert to simpler, more maintainable alternatives, but the consequences of these downgrades are not well understood.", "method": "The paper presents a case study of the Kubernetes project, specifically focusing on its downgrade from Bazel (artifact-based) to Go Build (language-specific). The authors analyzed full and incremental build times, memory usage, and CPU load during the transition period. They also replicated the study on four other projects that downgraded from Bazel, to check if findings generalize.", "result": "Bazel provides faster build times compared to Go Build, but it requires significantly more memory and higher CPU loads, especially under certain parallelism settings. Downgrading to Go Build leads to increased build times and potentially higher CI resource costs. Replication in other projects confirms Bazel's higher memory consumption but suggests reduced build time penalties over time.", "conclusion": "While downgrading from artifact-based build tools like Bazel may improve maintainability, it often results in significant performance costs for large projects, particularly in terms of build time, memory usage, and CI resource expenses. Stakeholders should carefully consider these trade-offs when choosing build systems."}}
{"id": "2510.20532", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.20532", "abs": "https://arxiv.org/abs/2510.20532", "authors": ["Patrycja Balik", "Szymon J\u0119dras", "Piotr Polesiuk"], "title": "Deciding not to Decide: Sound and Complete Effect Inference in the Presence of Higher-Rank Polymorphism", "comment": null, "summary": "Type-and-effect systems help the programmer to organize data and\ncomputational effects in a program. While for traditional type systems\nexpressive variants with sophisticated inference algorithms have been developed\nand widely used in programming languages, type-and-effect systems did not yet\ngain widespread adoption. One reason for this is that type-and-effect systems\nare more complex and the existing inference algorithms make compromises between\nexpressiveness, intuitiveness, and decidability. In this work, we present an\neffect inference algorithm for a type-and-effect system with subtyping,\nexpressive higher-rank polymorphism, and intuitive set-like semantics of\neffects. In order to deal with scoping issues of higher-rank polymorphism, we\ndelay solving of effect constraints by transforming them into formulae of\npropositional logic. We prove soundness and completeness of our algorithm with\nrespect to a declarative type-and-effect system. All the presented results have\nbeen formalized in the Rocq proof assistant, and the algorithm has been\nsuccessfully implemented in a realistic programming language.", "AI": {"tldr": "The paper introduces a sound and complete effect inference algorithm for advanced type-and-effect systems with subtyping and higher-rank polymorphism. By transforming effect constraints to logical formulae, the approach resolves scoping challenges and is both formally verified and practically implemented.", "motivation": "Type-and-effect systems manage data and computational effects, but unlike traditional type systems, they lack widespread use due to complexity and limited inference algorithms. The challenge is to balance expressiveness, intuitiveness, and decidability in inference algorithms.", "method": "The authors present a novel effect inference algorithm for a type-and-effect system featuring subtyping, higher-rank polymorphism, and intuitive set-like semantics for effects. They address the scoping issues of higher-rank polymorphism by delaying the solving of effect constraints and converting these constraints into propositional logic formulae.", "result": "The algorithm is proven sound and complete relative to a declarative type-and-effect system. The results are fully formalized using the Rocq proof assistant and the algorithm is implemented in a realistic programming language.", "conclusion": "The proposed algorithm effectively enables expressive, intuitive, and decidable effect inference for advanced type-and-effect systems, demonstrating practical feasibility and formal correctness."}}
{"id": "2510.20121", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20121", "abs": "https://arxiv.org/abs/2510.20121", "authors": ["Carlos J. Fernandez-Candel", "Jesus Garcia-Molina", "Francisco Javier Bermudez Ruiz", "Jose Ramon Hoyos Barcelo", "Diego Sevilla Ruiz", "Benito Jose Cuesta Viera"], "title": "Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience", "comment": "31 pages, 22 figures", "summary": "Model-driven software engineering (MDE) techniques are not only useful in\nforward engineering scenarios, but can also be successfully applied to evolve\nexisting systems. RAD (Rapid Application Development) platforms emerged in the\nnineties, but the success of modern software technologies motivated that a\nlarge number of enterprises tackled the migration of their RAD applications,\nsuch as Oracle Forms. Our research group has collaborated with a software\ncompany in developing a solution to migrate PL/SQL monolithic code on Forms\ntriggers and program units to Java code separated in several tiers.\n  Our research focused on the model-driven reengineering process applied to\ndevelop the migration tool for the conversion of PL/SQL code to Java. Legacy\ncode is represented in form of KDM (Knowledge-Discovery Metamodel) models. In\nthis paper, we propose a software process to implement a model-driven\nre-engineering. This process integrates a TDD-like approach to incrementally\ndevelop model transformations with three kinds of validations for the generated\ncode. The implementation and validation of the re-engineering approach are\nexplained in detail, as well as the evaluation of some issues related with the\napplication of MDE.", "AI": {"tldr": "The paper describes a model-driven process to migrate legacy PL/SQL code in Oracle Forms to multi-tier Java applications. Using KDM models and a TDD-like transformation approach with multiple validations, the process is demonstrated to be effective and well-structured for legacy system modernization.", "motivation": "Many enterprises use legacy RAD applications like Oracle Forms, and there is a strong need to migrate their monolithic PL/SQL code to modern, multi-tier Java architectures to leverage recent technologies and practices.", "method": "The paper proposes a model-driven re-engineering process for migrating legacy PL/SQL code to Java, using KDM (Knowledge-Discovery Metamodel) models for code representation. It also integrates a TDD-like method to incrementally develop model transformations and employs three types of validations to ensure the quality of the converted code.", "result": "The paper presents a detailed implementation and validation of the proposed migration process, demonstrating its effectiveness for converting legacy code and discussing challenges encountered during the application of model-driven engineering techniques.", "conclusion": "Model-driven re-engineering, supported by incremental transformation development and thorough code validation, is a feasible and effective approach for migrating legacy RAD applications. The described process offers a structured way to transition from PL/SQL to Java, facilitating modernization efforts."}}
{"id": "2510.20547", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.20547", "abs": "https://arxiv.org/abs/2510.20547", "authors": ["Nikolaus Huber", "Susanne Graf", "Philipp R\u00fcmmer", "Wang Yi"], "title": "Compiling the Mimosa programming language to RTOS tasks", "comment": null, "summary": "This paper introduces a compilation scheme for programs written in the Mimosa\nprogramming language, which builds upon the MIMOS model of computation. Mimosa\ndescribes embedded systems software as a collection of time-triggered processes\nwhich communicate through FIFO queues. We formally describe an adaptation of\nthe Lustre compilation scheme to the semantics of Mimosa and show how the\ncoordination layer can be mapped to real-time operating system primitives.", "AI": {"tldr": "This paper adapts a known compilation method (from Lustre) for the Mimosa language, which targets time-triggered embedded software, and demonstrates how such programs can run on real-time operating systems.", "motivation": "To provide a reliable compilation strategy for Mimosa, a language for describing time-triggered embedded systems, making it suitable for practical implementation on real-time operating systems.", "method": "Formal description of adapting the Lustre compilation scheme to Mimosa's semantics; mapping the coordination layer to RTOS primitives.", "result": "The authors show that Mimosa programs can be compiled using the adapted Lustre scheme, allowing their execution on platforms supporting real-time operating system primitives.", "conclusion": "The paper successfully adapts the Lustre compilation scheme for Mimosa, enabling its semantics to be implemented on real-time operating systems."}}
{"id": "2510.20211", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20211", "abs": "https://arxiv.org/abs/2510.20211", "authors": ["Zhenning Yang", "Hui Guan", "Victor Nicolet", "Brandon Paulsen", "Joey Dodds", "Daniel Kroening", "Ang Chen"], "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "comment": null, "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally,\ncloud consoles, command-line interfaces (CLI), and SDKs are the tools of\nchoice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have\nquickly gained popularity. Unlike conventional tools, IaC~frameworks encode the\ninfrastructure in a \"source-of-truth\" configuration. They are capable of\nautomatically carrying out modifications to the cloud -- deploying, updating,\nor destroying resources -- to bring the actual infrastructure into alignment\nwith the IaC configuration. However, when IaC is used alongside consoles, CLIs,\nor SDKs, it loses visibility into external changes, causing infrastructure\ndrift, where the configuration becomes outdated, and later IaC operations may\nundo valid updates or trigger errors.\n  We present NSync, an automated system for IaC reconciliation that propagates\nout-of-band changes back into the IaC program. Our key insight is that\ninfrastructure changes eventually all occur via cloud API invocations -- the\nlowest layer for cloud management operations. NSync gleans insights from API\ntraces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update\nthe IaC configuration to capture the changes). It employs an agentic\narchitecture that leverages LLMs to infer high-level intents from noisy API\nsequences, synthesize targeted IaC updates using specialized tools, and\ncontinually improve through a self-evolving knowledge base of past\nreconciliations. We further introduce a novel evaluation pipeline for injecting\nrealistic drifts into cloud infrastructure and assessing reconciliation\nperformance. Experiments across five real-world Terraform projects and 372\ndrift scenarios show that NSync outperforms the baseline both in terms of\naccuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$\nimprovement).", "AI": {"tldr": "IaC frameworks often lose track of manual or external infrastructure changes, leading to errors and drift. NSync is an automated system that monitors cloud APIs to detect these changes and updates the IaC config accordingly, using LLMs and specialized tools. Experiments show NSync is more accurate and efficient than previous solutions.", "motivation": "The motivation is to address the problem of infrastructure drift when Infrastructure-as-Code (IaC) frameworks are used alongside traditional cloud management interfaces like consoles, CLIs, or SDKs. Standard tools can't keep track of changes made outside the IaC configuration, leading to inconsistencies, errors, and outdated configurations.", "method": "The paper introduces NSync, an automated system that monitors cloud API calls to detect out-of-band changes that cause drift. It uses LLMs to infer intent from API logs and synthesizes targeted updates to the IaC configuration, using a self-improving knowledge base and a pipeline for realistic drift injection and evaluation.", "result": "NSync was tested on five real-world Terraform projects and 372 drift scenarios. It significantly improved reconciliation accuracy (pass@3 metric rose from 0.71 to 0.97) and was 1.47 times more token efficient compared to the baseline.", "conclusion": "NSync effectively reconciles IaC configurations with real-world infrastructure by tracking API-level changes and using automated reasoning for IaC updates, mitigating infrastructure drift and outperforming existing methods in both accuracy and efficiency."}}
{"id": "2510.20688", "categories": ["cs.PL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20688", "abs": "https://arxiv.org/abs/2510.20688", "authors": ["Oliver Braunsdorf", "Tim Lange", "Konrad Hohentanner", "Julian Horsch", "Johannes Kinder"], "title": "SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe Code in Rust and Mixed-Language Applications", "comment": null, "summary": "Unsafe Rust code is necessary for interoperability with C/C++ libraries and\nimplementing low-level data structures, but it can cause memory safety\nviolations in otherwise memory-safe Rust programs. Sanitizers can catch such\nmemory errors at runtime, but introduce many unnecessary checks even for memory\naccesses guaranteed safe by the Rust type system. We introduce SafeFFI, a\nsystem for optimizing memory safety instrumentation in Rust binaries such that\nchecks occur at the boundary between unsafe and safe code, handing over the\nenforcement of memory safety from the sanitizer to the Rust type system. Unlike\nprevious approaches, our design avoids expensive whole-program analysis and\nadds much less compile-time overhead (2.64x compared to over 8.83x). On a\ncollection of popular Rust crates and known vulnerable Rust code, SafeFFI\nachieves superior performance compared to state-of-the-art systems, reducing\nsanitizer checks by up to 98%, while maintaining correctness and flagging all\nspatial and temporal memory safety violations.", "AI": {"tldr": "SafeFFI optimizes memory safety in Rust programs using FFI by reducing unnecessary checks and overhead, performing as well as or better than state-of-the-art systems while reliably catching memory errors.", "motivation": "Modern Rust programs require 'unsafe' code to interface with C/C++ and for low-level implementations, but such code can compromise memory safety in primarily safe Rust applications. Existing sanitization methods for detecting memory errors apply checks even where the Rust type system guarantees safety, leading to unnecessary overhead.", "method": "SafeFFI strategically places memory safety checks only at the interface between unsafe and safe code, leveraging Rust's type system for enforcement within safe code regions. This approach bypasses whole-program analysis and focuses instrumentation at FFI boundaries.", "result": "SafeFFI significantly reduces the number of runtime sanitizer checks (by up to 98%), and imposes far less compile-time overhead (2.64x versus over 8.83x in previous systems), while still detecting all types of memory safety violations in Rust binaries.", "conclusion": "SafeFFI presents a more efficient mechanism for ensuring memory safety in Rust, especially in applications using FFI, maintaining error detection capabilities with lower performance impact than existing solutions."}}
{"id": "2510.20340", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20340", "abs": "https://arxiv.org/abs/2510.20340", "authors": ["Serena Cofano", "Daniel Williams", "Aman Sharma", "Martin Monperrus"], "title": "Classport: Designing Runtime Dependency Introspection for Java", "comment": null, "summary": "Runtime introspection of dependencies, i.e., the ability to observe which\ndependencies are currently used during program execution, is fundamental for\nSoftware Supply Chain security. Yet, Java has no support for it. We solve this\nproblem with Classport, a system that embeds dependency information into Java\nclass files, enabling the retrieval of dependency information at runtime. We\nevaluate Classport on six real-world projects, demonstrating the feasibility in\nidentifying dependencies at runtime. Runtime dependency introspection with\nClassport opens important avenues for runtime integrity checking.", "AI": {"tldr": "Java lacks runtime support for tracking dependencies, which is crucial for software security. The authors introduce Classport, a system that embeds dependency data in Java class files for runtime access, and show its effectiveness across real-world projects. This innovation could improve runtime integrity and supply chain security.", "motivation": "The motivation of the paper is to address the lack of support in Java for runtime introspection of dependencies, which is essential for Software Supply Chain security. Being able to observe dependencies during program execution can help detect integrity issues and mitigate security risks.", "method": "The proposed solution is Classport, a system that embeds dependency information directly into Java class files, allowing programs to retrieve and observe their dependencies at runtime.", "result": "Classport was evaluated on six real-world projects, demonstrating its capability to successfully identify dependencies during program execution.", "conclusion": "Classport enables runtime dependency introspection in Java, facilitating new approaches for runtime integrity checking and enhancing Software Supply Chain security."}}
{"id": "2510.20389", "categories": ["cs.SE", "cs.DC", "D.m"], "pdf": "https://arxiv.org/pdf/2510.20389", "abs": "https://arxiv.org/abs/2510.20389", "authors": ["Bjorn Remseth"], "title": "Symmetry in Software Platforms as an Architectural Principle", "comment": "Working paper, 11 pages", "summary": "Software platforms often act as structure preserving systems. They provide\nconsistent interfaces and behaviors that remain stable under specific\ntransformations that we denote as symmetries. This paper explores the idea that\narchitectural robustness emerges from enforcing such structural regularities", "AI": {"tldr": "Robustness in software platform architectures results from enforcing regular structures that remain stable under certain transformations, referred to as symmetries.", "motivation": "Software platforms need architectural robustness to maintain consistent behavior despite changes or transformations. The paper is motivated by the desire to understand how such robustness can be systematically achieved.", "method": "The paper investigates software platforms by framing their stable behaviors as invariance under certain transformations, defined as symmetries. The approach is conceptual and draws on structural regularity principles.", "result": "It finds that architectural robustness in software platforms can emerge when structural regularities, preserved by symmetries, are enforced.", "conclusion": "Imposing structure-preserving symmetries is key to achieving robust architectures in software platforms, making their interfaces and behaviors stable."}}
{"id": "2510.20403", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20403", "abs": "https://arxiv.org/abs/2510.20403", "authors": ["Santiago Gil", "Ecem E. Ba\u015f", "Christian D. Jensen", "Sebastian Engelsgaard", "Giuseppe Abbiati", "Cl\u00e1udio Gomes"], "title": "FMI-Based Distributed Co-Simulation with Enhanced Security and Intellectual Property Safeguards", "comment": "6 pages, Proceedings of the 2025 Annual Modeling and Simulation\n  Conference (ANNSIM)", "summary": "Distributed co-simulation plays a key role in enabling collaborative modeling\nand simulation by different stakeholders while protecting their Intellectual\nProperty (IP). Although IP protection is provided implicitly by co-simulation,\nthere is no consensus in the guidelines to conduct distributed co-simulation of\ncontinuous-time or hybrid systems with no exposure to potential hacking\nattacks. We propose an approach for distributed co-simulation on top of UniFMU\nwith enhanced cybersecurity and IP protection mechanisms, ensuring that the\nconnection is initiated by the client and the models and binaries live on\ntrusted platforms. We showcase the functionality of this approach using two\nco-simulation demos in four different network settings and analyze the\ntrade-off between IP-protected distribution and performance efficiency in these\nsettings.", "AI": {"tldr": "The paper presents a secure, IP-protected distributed co-simulation method based on UniFMU. By client-initiated connections and hosting models on trusted platforms, it increases cybersecurity. Tested in various network settings, it demonstrates good protection and performance trade-offs.", "motivation": "Ensuring intellectual property (IP) protection in distributed co-simulation is crucial, but current systems lack secure guidelines, especially against hacking attacks.", "method": "An approach is proposed for distributed co-simulation utilizing UniFMU with enhanced cybersecurity and IP protection. The connection is client-initiated, and models/binaries reside on trusted platforms. Functionality is demonstrated via two co-simulation demos across four network settings.", "result": "The paper analyzes the trade-offs between IP-protected distribution and performance in different network settings, showing the effectiveness of their approach in maintaining security and efficiency.", "conclusion": "The approach successfully strengthens IP and cybersecurity for distributed co-simulation, balancing security concerns without substantially sacrificing performance."}}
{"id": "2510.20514", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20514", "abs": "https://arxiv.org/abs/2510.20514", "authors": ["Lea Salome Brugger", "Xavier Denis", "Peter M\u00fcller"], "title": "Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia", "comment": null, "summary": "Deductive verification is an effective method to ensure that a given system\nexposes the intended behavior. In spite of its proven usefulness and\nfeasibility in selected projects, deductive verification is still not a\nmainstream technique. To pave the way to widespread use, we present a study\ninvestigating the factors enabling successful applications of deductive\nverification and the underlying issues preventing broader adoption. We\nconducted semi-structured interviews with 30 practitioners of verification from\nboth industry and academia and systematically analyzed the collected data\nemploying a thematic analysis approach. Beside empirically confirming familiar\nchallenges, e.g., the high level of expertise needed for conducting formal\nproofs, our data reveal several underexplored obstacles, such as proof\nmaintenance, insufficient control over automation, and usability concerns. We\nfurther use the results from our data analysis to extract enablers and barriers\nfor deductive verification and formulate concrete recommendations for\npractitioners, tool builders, and researchers, including principles for\nusability, automation, and integration with existing workflows.", "AI": {"tldr": "Deductive verification is powerful but not widely used. Through interviews and thematic analysis, the authors confirmed established challenges and discovered new ones, such as difficulty in proof maintenance and usability. They offer key recommendations to make deductive verification more accessible and practical for a broader audience.", "motivation": "Deductive verification ensures systems behave as intended, but despite its effectiveness, it is not widely adopted in practice. The authors seek to understand what enables or blocks broader use of this technique.", "method": "The authors conducted semi-structured interviews with 30 deductive verification practitioners from both industry and academia. They applied thematic analysis to systematically assess the challenges and opportunities revealed in these interviews.", "result": "The study confirmed known challenges, such as the high expertise required for formal proofs. It also uncovered less-discussed obstacles, including issues with proof maintenance, limited control over automation, and usability problems. The analysis identified both enablers and barriers to adoption and led to recommendations for improving usability, automation, and integration.", "conclusion": "To encourage wider adoption of deductive verification, stakeholders should address not only familiar difficulties but also underexplored barriers like maintenance and usability. The paper provides actionable recommendations for practitioners, tool developers, and researchers."}}
{"id": "2510.20521", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20521", "abs": "https://arxiv.org/abs/2510.20521", "authors": ["YingJian Xiao", "RongQun Hu", "WeiWei Gong", "HongWei Li", "AnQuan Jie"], "title": "Large Language Models for Fault Localization: An Empirical Study", "comment": "in Chinese language", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, particularly in automated program repair. However, the\neffectiveness of such repairs is highly dependent on the performance of\nupstream fault localization, for which comprehensive evaluations are currently\nlacking. This paper presents a systematic empirical study on LLMs in the\nstatement-level code fault localization task. We evaluate representative\nopen-source models (Qwen2.5-coder-32b-instruct, DeepSeek-V3) and closed-source\nmodels (GPT-4.1 mini, Gemini-2.5-flash) to assess their fault localization\ncapabilities on the HumanEval-Java and Defects4J datasets. The study\ninvestigates the impact of different prompting strategies--including standard\nprompts, few-shot examples, and chain-of-reasoning--on model performance, with\na focus on analysis across accuracy, time efficiency, and economic cost\ndimensions. Our experimental results show that incorporating bug report context\nsignificantly enhances model performance. Few-shot learning shows potential for\nimprovement but exhibits noticeable diminishing marginal returns, while\nchain-of-thought reasoning's effectiveness is highly contingent on the model's\ninherent reasoning capabilities. This study not only highlights the performance\ncharacteristics and trade-offs of different models in fault localization tasks,\nbut also offers valuable insights into the strengths of current LLMs and\nstrategies for improving fault localization effectiveness.", "AI": {"tldr": "LLMs' ability to localize code faults hinges on context and prompt strategy\u2014bug reports help most, few-shot learning yields limited gains, and reasoning-heavy prompts only work with strong models. These findings inform practical ways to improve automated code debugging with LLMs.", "motivation": "Although LLMs are highly effective at automated program repair, their success largely depends on the quality of upstream fault localization, which has not been comprehensively evaluated.", "method": "The authors conduct a systematic empirical study of various LLMs (including both open-source and closed-source) on the task of statement-level code fault localization, using HumanEval-Java and Defects4J datasets. They test different prompting strategies, such as standard prompting, few-shot learning, and chain-of-reasoning, evaluating models based on accuracy, time efficiency, and economic cost.", "result": "Including bug report context leads to significant performance improvements. Few-shot learning can help but shows diminishing returns, and the effectiveness of chain-of-thought reasoning depends on the model's reasoning abilities.", "conclusion": "The study reveals key performance characteristics and trade-offs of different LLMs for fault localization, providing actionable insights for leveraging LLMs and optimizing prompting strategies to improve automated software debugging."}}
{"id": "2510.20679", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20679", "abs": "https://arxiv.org/abs/2510.20679", "authors": ["Jonas Klauke", "Tom Ohlmer", "Stefan Schott", "Serena Elisa Ponta", "Wolfram Fischer", "Eric Bodden"], "title": "A Soundness and Precision Benchmark for Java Debloating Tools", "comment": "Preprint - accepted at the ACM Workshop on Software Supply Chain\n  Offensive Research and Ecosystem Defenses (SCORED '25)", "summary": "Modern software development reuses code by importing libraries as\ndependencies. Software projects typically include an average of 36\ndependencies, with 80% being transitive, meaning they are dependencies of\ndependencies. Recent research indicates that only 24.9% of these dependencies\nare required at runtime, and even within those, many program constructs remain\nunused, adding unnecessary code to the project. This has led to the development\nof debloating tools that remove unnecessary dependencies and program constructs\nwhile balancing precision by eliminating unused constructs and soundness by\npreserving all required constructs. To systematically evaluate this trade-off,\nwe developed Deblometer, a micro-benchmark consisting of 59 test cases designed\nto assess support for various Java language features in debloating tools. Each\ntest case includes a manually curated ground truth specifying necessary and\nbloated classes, methods, and fields, enabling precise measurement of soundness\nand precision. Using Deblometer, we evaluated three popular Java debloating\ntools: Deptrim, JShrink, and ProGuard. Our evaluation reveals that all tools\nremove required program constructs, which results in changed semantics or\nexecution crashes. In particular, the dynamic class loading feature introduces\nunsoundness in all evaluated tools. Our comparison shows that Deptrim retains\nmore bloated constructs, while ProGuard removes more required constructs.\nJShrink's soundness is significantly affected by limited support for\nannotations, which leads to corrupted debloated artifacts. These soundness\nissues highlight the need to improve debloating tools to ensure stable and\nreliable debloated software.", "AI": {"tldr": "Deblometer, a Java micro-benchmark, reveals that popular debloating tools often remove necessary code elements, causing crashes or altered program behavior. Dynamic class loading and annotations are notably problematic. These tools require enhancement to achieve safer and more effective debloating.", "motivation": "Modern software development heavily relies on third-party libraries, resulting in a large number of dependencies\u2014many of which are unused and contribute to software bloat. Addressing this inefficiency is critical for improving performance, maintainability, and security.", "method": "The authors developed Deblometer, a micro-benchmark composed of 59 carefully curated test cases that cover various Java language features. Each case specifies ground truth for necessary and bloated code elements (classes, methods, fields). Deblometer is used to systematically evaluate the soundness (preserving necessary code) and precision (removing unnecessary code) of debloating tools.", "result": "All evaluated Java debloating tools (Deptrim, JShrink, ProGuard) removed some required program constructs, leading to semantic changes or execution failures. Dynamic class loading proved especially challenging. Deptrim was more conservative, retaining more bloated code, while ProGuard was more aggressive, risking removal of necessary constructs. JShrink exhibited poor soundness due to insufficient annotation handling, resulting in corrupted outputs.", "conclusion": "Current debloating tools for Java fail to fully balance precision and soundness, often removing required constructs and causing instability. Significant improvements are needed to support stable and reliable debloated software."}}
{"id": "2510.20692", "categories": ["cs.SE", "cs.AI", "cs.FL", "D.4.6; D.2.4; I.2.2; I.2.7; F.3.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2510.20692", "abs": "https://arxiv.org/abs/2510.20692", "authors": ["Adarsh Vatsa", "Bethel Hall", "William Eiers"], "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "comment": "20 pages, 7 figures", "summary": "Cloud computing is ubiquitous, with a growing number of services being hosted\non the cloud every day. Typical cloud compute systems allow administrators to\nwrite policies implementing access control rules which specify how access to\nprivate data is governed. These policies must be manually written, and due to\ntheir complexity can often be error prone. Moreover, existing policies often\nimplement complex access control specifications and thus can be difficult to\nprecisely analyze in determining their behavior works exactly as intended.\nRecently, Large Language Models (LLMs) have shown great success in automated\ncode synthesis and summarization. Given this success, they could potentially be\nused for automatically generating access control policies or aid in\nunderstanding existing policies. In this paper, we explore the effectiveness of\nLLMs for access control policy synthesis and summarization. Specifically, we\nfirst investigate diverse LLMs for access control policy synthesis, finding\nthat: although LLMs can effectively generate syntactically correct policies,\nthey have permissiveness issues, generating policies equivalent to the given\nspecification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time\nfor reasoning LLMs. We then investigate how LLMs can be used to analyze\npolicies by introducing a novel semantic-based request summarization approach\nwhich leverages LLMs to generate a precise characterization of the requests\nallowed by a policy. Our results show that while there are significant hurdles\nin leveraging LLMs for automated policy generation, LLMs show promising results\nwhen combined with symbolic approaches in analyzing existing policies.", "AI": {"tldr": "This paper shows that while LLMs struggle to generate correct access control policies on their own, especially non-reasoning models, they perform much better with reasoning tasks and in combination with symbolic methods for analyzing and summarizing existing policies.", "motivation": "Access control policies in cloud systems are complex and error-prone, requiring manual writing and analysis. There is a growing need for automation and better tools to synthesize and understand these policies.", "method": "The paper investigates the use of various Large Language Models (LLMs) for both access control policy synthesis and summarization. It evaluates LLM effectiveness in generating correct policies and introduces a novel semantic-based request summarization approach using LLMs.", "result": "LLMs can generate syntactically correct policies, but suffer from permissiveness issues: only 45.8% equivalence for non-reasoning LLMs and 93.7% for reasoning LLMs. For policy analysis, LLMs combined with symbolic methods provide promising results in summarizing policy behavior.", "conclusion": "LLMs are not fully reliable for automated policy generation due to permissiveness errors, but are useful when paired with symbolic techniques for policy analysis and summarization."}}
