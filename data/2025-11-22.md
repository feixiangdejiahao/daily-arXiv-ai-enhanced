<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.PL](#cs.PL) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: This paper introduces a framework using LLM generation, reverse generation, and rubric-guided refinement to systematically validate quality engineering artefacts, demonstrating improved reliability and scalability across multiple projects.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of ensuring the quality of artefacts (requirements, test cases, BDD scenarios) generated by Large Language Models in Quality Engineering applications.

Method: The method combines initial LLM-driven artefact generation with reverse generation and iterative refinement. The refinement is guided by rubric-based evaluation for metrics such as clarity, completeness, consistency, and testability.

Result: Experimental results over 12 projects demonstrate that reverse-generated artefacts can surpass low-quality inputs and maintain high standards with quality initial inputs, proving the framework's effectiveness.

Conclusion: The proposed framework enables systematic, scalable, and reliable validation of LLM-generated QE artefacts, ensuring accountability and bridging the gap between automation and quality assurance.

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [2] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: RGym is a new, lightweight framework that enables practical automated program repair for Linux kernel bugs on local hardware. Using specialized bug localization and feedback-based retries, it achieves 43.36% success at low cost, outperforming prior approaches and identifying key factors for APR improvement.


<details>
  <summary>Details</summary>
Motivation: Automated program repair (APR) using Large Language Models has advanced, but there is a lack of effective benchmarks and frameworks for kernel-space, which is more complex due to concurrency and hardware interactions. Existing solutions are either ineffective or expensive.

Method: The authors developed RGym, a lightweight, platform-agnostic evaluation framework for Linux kernel APR. Their APR pipeline uses specialized localization (call stacks, blamed commits) to identify bug locations. The system works on local hardware, avoiding expensive infrastructure. They conducted empirical evaluation on 143 filtered, verified Linux kernel bugs, and performed an ablation study to assess different pipeline components.

Result: Their approach achieved up to 43.36% pass rate with GPT-5 Thinking at a cost below $0.20 per bug. Ablation showed prompt structure, model choice, and feedback-based retries improved APR success rates.

Conclusion: RGym provides an accessible, efficient way to benchmark and improve kernel-space APR, showing promising results that lower cost and outperform past methods. The framework helps reveal which strategies enhance repair success, especially using LLMs.

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [3] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: This paper introduces and validates the Propensity Smelly Score (PSC) for assessing and mitigating code smells in LLM-generated code, finding that prompt design and model architecture are key factors. PSC helps developers judge code quality, supporting safer LLM deployment.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) are widely used in software engineering but often generate code with poor structure and code smells, which undermines readability, maintainability, and design quality. The community lacks understanding of when and why these issues emerge in LLM-generated code.

Method: The paper introduces the Propensity Smelly Score (PSC), a probabilistic metric to estimate the likelihood of code smell occurrence. It uses PSC to conduct causal analyses on how generation strategy, model size, architecture, and prompt formulation affect code quality. A user study evaluates PSC's utility for developers.

Result: Prompt design and model architecture significantly influence the likelihood of code smells in generated code. Mitigation methods based on these insights are effective. Developers benefit from using PSC to interpret LLM behavior and assess code quality.

Conclusion: The PSC metric can guide both developers and researchers to assess and mitigate code smell propensity in LLM-generated code, and integrating such quality-aware methods can improve the evaluation and deployment of LLMs in software engineering.

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [4] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: The study introduces an AI-powered orchestration framework for Workday ERP in healthcare, automating and optimizing workflows through event-driven logic. Demonstrated across multiple organizations, the approach improves efficiency, cost control, and decision-making, offering a robust model for future intelligent ERP automation.


<details>
  <summary>Details</summary>
Motivation: Traditional ERP workflow logic does not provide the necessary adaptability for today's event-driven and data-intensive healthcare environments, creating challenges in effectively managing integrated financial, supply-chain, and workforce processes.

Method: The paper proposes an AI-enabled, event-driven orchestration framework built within Workday ERP. This framework leverages machine-learning triggers, anomaly detection, and process mining analytics to automate and synchronize workflows. The authors validate their approach through a case analysis involving multiple healthcare organizations.

Result: The framework led to measurable improvements in process efficiency, cost visibility, and decision accuracy during the case analysis.

Conclusion: Integrating AI-driven event-based orchestration significantly enhances the operational resilience, governance, and scalability of Workday ERP in healthcare settings. This framework serves as a model for intelligent ERP integration and next-generation automation in the industry.

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [5] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: High-quality annotation of data is vital for safe autonomous driving AI, but how requirements are set and managed is underexplored. Interviews revealed five main challenges and best practices for improving annotation reliability and compliance, helping bridge software requirements with AI development.


<details>
  <summary>Details</summary>
Motivation: High-quality data annotation is essential for safe and reliable AI-enabled perception systems in autonomous vehicles, but how annotation requirements are defined and managed has not been well-studied. This gap leads to potential inconsistencies, safety risks, and regulatory concerns.

Method: The study used 19 semi-structured interviews with professionals from six international companies and four research organizations. The researchers employed thematic analysis to identify challenges, best practices, and the impact of annotation requirements on AI systems.

Result: Five main challenges were identified: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints. Three categories of best practices emerged: compliance with ethical standards, improved annotation requirements guidelines, and embedded quality assurance. Interconnections between requirements, practices, data quality, and system performance were clarified. The findings show how flaws can propagate through the AI development pipeline.

Conclusion: This is the first empirically grounded study to provide actionable guidance for improving annotation requirements in AI-enabled perception systems. The insights support higher annotation quality, regulatory compliance, and system reliability, bridging gaps between software engineering, requirements engineering, and AI.

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [6] [InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution](https://arxiv.org/abs/2511.16004)
*KeFan Li,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: InfCode introduces a multi-agent, adversarial framework for fixing software repository issues, outperforming prior methods and establishing new benchmarks for reliability and effectiveness.


<details>
  <summary>Details</summary>
Motivation: Resolving real-world software issues in repositories is challenging due to the need for deep reasoning, accurate diagnostics, and robust verification. Existing automation approaches often produce patches that pass weak tests but do not truly fix bugs.

Method: InfCode is an adversarial multi-agent framework for repository-level issue resolution. It uses a Test Patch Generator and a Code Patch Generator that iteratively improve tests and code patches by interacting adversarially, with a Selector agent picking the most reliable fix. The process operates in a containerized environment for realistic validation.

Result: InfCode consistently outperforms strong baselines on benchmark datasets. It achieves 79.4% accuracy on SWE-bench Verified, setting a new state-of-the-art.

Conclusion: InfCode effectively improves automated software issue resolution at the repository level by robustly generating and verifying patches. Its open-source release enables further research and application.

Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.

</details>


### [7] [InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution](https://arxiv.org/abs/2511.16005)
*Qingao Dong,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: Most LLM agents work well for Python but struggle with C++ code issues. INFCODE-C++ introduces a language-aware system that uses both semantic intent and AST-based querying, achieving much better results on C++ benchmarks and showing that deeper, language-specific methods are essential for effective automated issue resolution in complex codebases.


<details>
  <summary>Details</summary>
Motivation: Current LLM-based agents for automated code issue resolution are mainly focused on Python, which transfers poorly to C++ due to the language's complexity (e.g., overloaded identifiers, deep control flow, templates). As a result, existing agents perform poorly on C++ projects.

Method: The authors develop INFCODE-C++, an autonomous system that integrates two retrieval mechanisms: semantic code-intent retrieval and deterministic AST-structured querying, tailored for accurate context retrieval and repair in C++ repositories.

Result: INFCODE-C++ achieves a 25.58% issue resolution rate on the MultiSWE-bench-CPP benchmark, outperforming the leading previous agent by 10.85 percentage points and more than doubling MSWE-agent’s performance. Further analyses confirm the importance of semantic and structural methods for C++ issue resolution.

Conclusion: INFCODE-C++ establishes the importance of language-aware approaches in LLM-based software repair systems, providing a new benchmark and raising the standard for C++ and other statically-typed languages.

Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.

</details>


### [8] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: This report summarizes expert discussions at Shonan Meeting 222, focusing on the impacts, challenges, and opportunities of integrating Generative AI into software development environments.


<details>
  <summary>Details</summary>
Motivation: Generative AI is increasingly capable in software engineering tasks, potentially transforming Human-AI interactions within IDEs. The paper aims to analyze these changes, recognizing the importance of understanding their implications.

Method: A workshop-style discussion was conducted among 33 experts from software engineering, AI, and HCI fields at Shonan Meeting 222, focusing on GenAI's effects on IDEs.

Result: The paper offers a report of the discussions, highlighting identified challenges and opportunities for GenAI integration in IDEs, informed by cross-disciplinary expert insights.

Conclusion: The meeting emphasized that GenAI will fundamentally influence how developers interact with code and IDEs, and highlighted areas where further research and innovation are needed for effective integration.

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [9] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: This paper presents a novel framework leveraging LLMs to unify and enhance textual vulnerability descriptions from multiple sources, resulting in higher accuracy, informativeness, and usability for security analysis.


<details>
  <summary>Details</summary>
Motivation: Textual Vulnerability Descriptions (TVDs) are often inconsistent across different repositories, which complicates the task of security analysts trying to understand and respond to software vulnerabilities. Existing alignment methods either lose valuable information or do not create comprehensive vulnerability representations.

Method: The paper proposes a domain-constrained LLM-based synthesis framework to unify the key aspects of TVDs. The framework includes three stages: 1) Extraction using rule-based templates, 2) Self-evaluation with anchor words to gauge semantic variability, and 3) Fusion using information entropy to reconcile inconsistencies and prioritize details. Additionally, 'Digest Labels' are developed for practical visualization of synthesized TVDs.

Result: The framework improves the F1 score for key aspect augmentation from 0.82 to 0.87. Comprehension and efficiency of TVDs are increased by over 30%. Human evaluations demonstrate that 'Digest Labels' significantly enhance usability.

Conclusion: A three-stage, domain-constrained LLM-based synthesis framework effectively reconciles inconsistencies in TVDs, augmenting the completeness and clarity of vulnerability information. The approach significantly improves analytic effectiveness and user experience.

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [10] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: LLMs can write Solidity code that looks similar to real smart contracts, but are often functionally incorrect and oversimplified. Adding retrieval methods helps, but expert review is still crucial for production quality.


<details>
  <summary>Details</summary>
Motivation: Despite the popularity of LLMs for code generation and the dominance of Solidity in blockchain smart contracts, there is insufficient understanding of how well these models address smart contracts' unique requirements: gas consumption, security, and determinism.

Method: Benchmarking four state-of-the-art large language models under zero-shot and retrieval-augmented generation settings using 500 real-world smart contract functions. Multi-faceted evaluation includes code similarity metrics, semantic embeddings, automated testing, gas profiling, and cognitive and cyclomatic complexity analyses.

Result: LLMs generate code with high semantic similarity but low functional correctness (only 20%-26% behave identically to ground-truth contracts). Code is simpler and uses less gas, often omitting critical validation logic. Retrieval-Augmented Generation boosts functional correctness up to 45% and results in more concise, efficient code.

Conclusion: RAG is effective at improving code generation for smart contracts, but existing LLMs still fall short of reliably delivering robust, production-ready code. Expert validation remains essential due to persistent gaps between semantic similarity and true functional performance.

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [11] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: Annotation errors in autonomous vehicle AI depend on multi-step processes across organisations. This paper creates a taxonomy of 18 error types, validated by industry, to help diagnose, standardise, and improve data annotation quality, boosting AI trustworthiness and reliability.


<details>
  <summary>Details</summary>
Motivation: Despite the importance of data annotation quality in AI-enabled perception systems for automated driving, there is a lack of empirical understanding of how annotation errors arise and propagate throughout the automotive supply chain.

Method: The study used a multi-organisation case study approach, conducting 19 semi-structured interviews with 20 experts from six companies and four research institutes. The analysis involved six-phase thematic analysis of 50 hours of transcripts.

Result: The study developed a taxonomy of 18 recurring annotation error types grouped into three data-quality dimensions: completeness, accuracy, and consistency. This taxonomy was validated by industry practitioners, who found it beneficial for various quality assurance processes.

Conclusion: This research provides a shared vocabulary, diagnostic tools, and actionable guidance for improving annotation quality in AI-enabled perception systems, addressing annotation as a supply-chain lifecycle issue and supporting root-cause analysis and industry best practices.

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


### [12] [Green Resilience of Cyber-Physical Systems: Doctoral Dissertation](https://arxiv.org/abs/2511.16593)
*Diaeddin Rimawi*

Main category: cs.SE

TL;DR: The paper proposes models and policies to balance resilience (consistent performance) and greenness (energy/environmental impact) in online collaborative AI systems disrupted during operation. They introduce the GResilience framework with various agent-based recovery strategies, showing its effectiveness in faster, more stable, and less human-dependent recovery—especially with RL-based policies, though with slight environmental cost. Containerization greatly reduces system emissions. The research equips practitioners to enhance both robustness and sustainability in collaborative AI systems.


<details>
  <summary>Details</summary>
Motivation: Online Collaborative AI Systems (OL-CAIS), as a form of cyber-physical systems, are increasingly prevalent and must learn in real time alongside humans. Their close integration with real-world processes makes them susceptible to disruptive events that can degrade their performance. Maintaining high system performance (resilience) is often at odds with minimizing energy use and environmental impact (greenness). Thus, there is a critical need to effectively balance these two properties in OL-CAIS during disruptions.

Method: The researchers model OL-CAIS behavior using three operational states: steady, disruptive, and final. They develop the GResilience framework, which integrates multiple policy types to support system recovery during disruptions: multi-objective optimization for single-agent cases, game-theoretic decision-making for two agents, and reinforcement learning (RL) for RL-agent policies. Additionally, a measurement framework is designed to quantify resilience and greenness. Experiments include both real-world and simulated tests with collaborative robots learning object classification from humans.

Result: The resilience model successfully captures the system's performance transitions during disruptive events. Policies developed in the GResilience framework notably enhance 'green recovery'—shorter recovery times, more stable performance, and less human intervention. RL-based policies deliver the best performance benefits, albeit with a slight increase in CO2 emissions. Catastrophic forgetting is observed after repeated disruptions, but the proposed policies largely maintain stable performance. Furthermore, running the system in a containerized environment halves CO2 emissions.

Conclusion: This research delivers new conceptual models, metrics, and practical agent-based policies that address the trade-off between resilience and greenness in OL-CAIS. By leveraging advanced optimization methods and robust experimentation, they demonstrate significant improvements in eco-friendly recovery and stable performance, contributing tools and insights for practitioners to manage online collaborative AI systems more sustainably and reliably.

Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [13] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: This paper presents a symmetric type system and unification algorithm for Polarity, a language designed to equally support extending types by new operations (inductively) and new constructors (coinductively). The solution also handles implicit arguments and is backed by a concrete implementation, offering guidelines for other languages that aspire to similar extensibility.


<details>
  <summary>Details</summary>
Motivation: Dependently typed languages traditionally favor extending types with new operations (e.g., via pattern matching on inductive types) but handle extension with new constructors (via coinductive types) poorly. The motivation is to address the lack of symmetry and practical features (such as implicit arguments) in languages like Polarity that aim to treat both kinds of types equally.

Method: The paper presents an algorithmic type system and an inference algorithm for implicit arguments that maintain the core symmetry between inductive and coinductive types. It details rules for reduction semantics, conversion checking, and a comprehensive unification algorithm for pattern matching. The approach is supported by a work-in-progress implementation available online.

Result: The paper delivers a complete algorithmic description of the type system for Polarity and a robust unification algorithm applicable to both inductive and coinductive types. These are implemented in ongoing work and documented with rules that enable practical type checking and inference.

Conclusion: The authors conclude that their comprehensive type system and unification algorithm for Polarity provide essential advances towards symmetric support for inductive and coinductive types in dependently typed languages. Their work sets a blueprint for similar languages seeking to address the expression problem and features like implicit arguments.

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [14] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex enables robust, fault-tolerant distributed applications in Elixir via choreographic programming and metaprogramming. It handles actor crashes by respawning and restoring state, tightly integrates with Elixir, and its methods may be extensible to other languages.


<details>
  <summary>Details</summary>
Motivation: To create a robust distributed application environment in Elixir by leveraging choreographic programming, specifically improving fault tolerance and integration with the host language.

Method: Developed Chorex, a choreographic programming language for Elixir, utilizing metaprogramming to tightly integrate with Elixir and manage actor failures through checkpoints and dynamic network reconfiguration. Demonstrated through multiple examples and measured performance overhead.

Result: Chorex successfully tolerates actor failures by respawning processes, restoring state, and reconfiguring networks. It also achieves tight static integration with Elixir, and provides useful reporting for implementation mismatches. Performance overhead due to checkpointing is analyzed.

Conclusion: Chorex proves choreographic programming with actor failure tolerance is feasible and useful in Elixir. Its metaprogramming-based projection strategy and restartable actor support could be adapted to other languages.

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [15] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: Offloading most VM components to a host machine allows microcontroller VMs to overcome memory limitations, providing richer features and faster execution. The BlueScript VM demonstrates superior speed and interactivity compared to existing solutions, proving this technique is practical for microcontroller development.


<details>
  <summary>Details</summary>
Motivation: Microcontroller-based virtual machines (VMs) often cannot provide interactive or fast environments due to limited memory. Existing solutions do not enable rich features or high responsiveness.

Method: The authors propose a disaggregated VM design that offloads most VM components to a host machine with abundant memory and processing capabilities. They implement this concept as BlueScript VM and introduce a 'shadow machine' on the host to mirror microcontroller execution state, aiming to minimize communication overhead.

Result: Experiments show that the proposed approach maintains expected benefits with minimal compromises. Specifically, the offloaded incremental compiler yields faster execution speeds than popular alternatives like MicroPython and Espruino, while maintaining comparable interactivity. Offloading the dynamic compiler also improves VM performance.

Conclusion: Offloading VM components to a host system is feasible and effective for memory-limited microcontroller development, enabling richer features and better performance without losing interactivity. The BlueScript VM exemplifies these benefits.

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [16] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon is a Rust workflow engine designed for ragged data (variable-length collections), providing significant improvements (15x lower overhead, scalable performance) over existing systems thanks to its dimension annotation language, parallel scheduling, and robust recovery mechanisms.


<details>
  <summary>Details</summary>
Motivation: Modern data workflows often deal with ragged data—data with variable-length elements—which is challenging to process efficiently, especially with existing workflow engines that do not natively track data shapes or dependencies.

Method: Operon, a new Rust-based workflow engine, uses named dimensions with explicit dependency relations. It includes a domain-specific language for declaring pipelines with statically verifiable dimension annotations, and a runtime that schedules tasks as data shapes are discovered. The authors formalize mathematical reasoning for partial shapes and prove deterministic, confluent parallel execution. Operon employs a per-task multi-queue architecture to optimize parallelism, and supports robust persistence and recovery through explicit state modeling.

Result: Operon provides efficient and robust processing for ragged data and demonstrates significant empirical improvements: it reduces baseline overhead by almost 15x and maintains near-linear output scaling as workloads increase, outperforming existing workflow engines.

Conclusion: Operon solves a key limitation in workflow engines by allowing expressive, verifiable, and efficient ragged data workflow definitions, making it well-suited to large-scale machine learning data pipelines, and ensuring robust scalability, persistence, and parallelism.

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>
