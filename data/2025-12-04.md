<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 5]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Is Vibe Coding Safe? Benchmarking Vulnerability of Agent-Generated Code in Real-World Tasks](https://arxiv.org/abs/2512.03262)
*Songwen Zhao,Danqing Wang,Kexun Zhang,Jiaxuan Luo,Zhuo Li,Lei Li*

Main category: cs.SE

TL;DR: The paper evaluates the security of vibe coding, a paradigm where engineers instruct LLM agents to code. It finds that popular agents often produce functionally correct but insecure code, raising concerns about deploying such outputs in practice.


<details>
  <summary>Details</summary>
Motivation: With vibe coding gaining adoption, the safety and security of code produced by LLM agents is largely unknown, motivating a systematic evaluation to determine if current solutions can be safely deployed.

Method: The authors introduce the SU S VI B E S benchmark, consisting of 200 real-world feature requests known to have led to vulnerabilities, and assess the performance and security of code generated by several LLM coding agents using this benchmark.

Result: Agents like SWE-Agent with Claude 4 Sonnet generated functionally correct code 61% of the time but only 10.5% were secure. Attempts to improve security by adding vulnerability hints were ineffective, highlighting severe shortcomings in existing agent outputs.

Conclusion: Vibe coding with LLM agents often results in insecure implementations even when the code is functionally correct, indicating significant risks for real-world and security-sensitive applications.

Abstract: Vibe coding is a new programming paradigm in which human engineers instruct large language model (LLM) agents to complete complex coding tasks with little supervision. Although it is increasingly adopted, are vibe coding outputs really safe to deploy in production? To answer this question, we propose SU S VI B E S, a benchmark consisting of 200 feature-request software engineering tasks from real-world open-source projects, which, when given to human programmers, led to vulnerable implementations. We evaluate multiple widely used coding agents with frontier models on this benchmark. Disturbingly, all agents perform poorly in terms of software security. Although 61% of the solutions from SWE-Agent with Claude 4 Sonnet are functionally correct, only 10.5% are secure. Further experiments demonstrate that preliminary security strategies, such as augmenting the feature request with vulnerability hints, cannot mitigate these security issues. Our findings raise serious concerns about the widespread adoption of vibe-coding, particularly in security-sensitive applications.

</details>


### [2] [Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization](https://arxiv.org/abs/2512.03421)
*Hexiang Xu,Hengyuan Liu,Yonghao Wu,Xiaolan Kang,Xiang Chen,Yong Liu*

Main category: cs.SE

TL;DR: LLMs show strong potential in helping novices debug code by providing more accurate and understandable fault localization than traditional methods, but require improvements in reasoning and computational efficiency for real-world use.


<details>
  <summary>Details</summary>
Motivation: Novice programmers struggle with fault localization due to limited experience and insufficient understanding of code. Traditional fault localization methods often lack contextual understanding, making them less effective for beginners.

Method: The study compares six closed-source and seven open-source LLMs on multiple datasets (Codeflaws, Condefects, and BugT), assessing fault localization accuracy and reasoning quality. BugT, a new dataset, helps address data leakage. User ratings from novice programmers (one year experience) evaluate explanation quality.

Result: Advanced LLMs with reasoning capabilities outperform traditional methods in fault localization, achieving higher accuracy with minimal prompt engineering. Novice programmers rate LLM-generated explanations highly. However, performance drops for complex problems, and some models suffer from over-reasoning. Computational cost is also a challenge.

Conclusion: LLMs significantly enhance debugging for novice programmers, but practical deployment needs improvements in reasoning clarity and computational resource demands. Further research and refinement are needed for widespread adoption.

Abstract: Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.

</details>


### [3] [Runnable Directories: The Solution to the Monorepo vs. Multi-repo Debate](https://arxiv.org/abs/2512.03815)
*Shayan Ghasemnezhad,Samarth KaPatel,Sofia Nikiforova,Giacinto Paolo Saggese,Paul Smith,Heanh Sok*

Main category: cs.SE

TL;DR: Causify Dev introduces 'runnable directories,' combining strengths of monorepos (consistency) and multi-repos (modularity), supported by Docker workflows for scalable and maintainable development.


<details>
  <summary>Details</summary>
Motivation: Traditional monorepo and multi-repo structures each have major limitations—monorepos struggle with scalability, multi-repos with coordination. Developers need a system that combines the benefits of both for complex, growing projects.

Method: The method centers on creating self-contained runnable directories, operating within a thin, unified environment supported by containerized Docker workflows and shared helper utilities.

Result: The Causify Dev system is introduced as a hybrid codebase management approach. It defines 'runnable directories'—self-contained, executable units with independent development lifecycles—supported by shared utilities and Docker-based workflows. The paper claims this model delivers the scaling and reliability benefits of monorepos while retaining the modularity and isolation of multi-repos, particularly for CI/CD and dependency management.

Conclusion: Causify Dev provides a practical, scalable compromise between monorepo and multi-repo strategies, improving reliability and maintainability for large, complex software codebases.

Abstract: Modern software systems increasingly strain traditional codebase organization strategies. Monorepos offer consistency but often suffer from scalability issues and tooling complexity, while multi-repos provide modularity at the cost of coordination and dependency management challenges. As an answer to this trade-off, we present the Causify Dev system, a hybrid approach that integrates key benefits of both. Its central concept is the runnable directory -- a self-contained, independently executable unit with its own development, testing, and deployment lifecycles. Backed by a unified thin environment, shared helper utilities, and containerized Docker-based workflows, runnable directories enable consistent setups, isolated dependencies, and efficient CI/CD processes. The Causify Dev approach provides a practical middle ground between monorepo and multi-repo strategies, improving reliability and maintainability for growing, complex codebases.

</details>


### [4] [A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software](https://arxiv.org/abs/2512.03868)
*Shree Hari Bittugondanahalli Indra Kumar,Lilia Rodrigues Sampaio,André Martin,Andrey Brito,Christof Fetzer*

Main category: cs.SE

TL;DR: Analyzed a large, multi-language dataset of open-source projects with VODA to examine dependency vulnerabilities. Found most vulnerabilities are transitive and persist for over a year, suggesting the need for better vulnerability management in open-source ecosystems.


<details>
  <summary>Details</summary>
Motivation: Open-source libraries expedite software development but can introduce security vulnerabilities. Recent incidents like Log4Shell highlight the urgent need to better understand and mitigate these risks. Evaluating how widespread vulnerabilities are, how long they persist, and how quickly they are fixed in real-world projects is important for improving software supply chain security.

Method: The study analyzed over 1,000 open-source software projects (with ~50,000 releases) across several languages using the VODA Software Composition Analysis tool. The researchers collected version histories, mapped dependencies, and tracked known vulnerabilities from 2013 to 2023. Project metrics such as team size, contributor count, activity, and release cycles were correlated with vulnerability persistence and severity.

Result: Most vulnerable dependencies found are transitive in nature. Across most programming languages studied, critical vulnerabilities persist for an average of over a year before being addressed. The study's dataset is larger and more diverse than prior works, providing improved insights and generalizability regarding dependency risks.

Conclusion: The findings highlight persistent risks in open-source software dependencies, especially transitive vulnerabilities and their long lifespans. The research underscores the need for more proactive vulnerability tracking and mitigation measures in the software development lifecycle and provides a more generalizable data source for future studies.

Abstract: Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.

</details>


### [5] [Tunable Automation in Automated Program Verification](https://arxiv.org/abs/2512.03926)
*Alexander Y. Bai,Chris Hawblitzel,Andrea Lattuada*

Main category: cs.SE

TL;DR: They introduce a mechanism for customizable quantifier instantiation in SMT-based verification (in Verus), showing developers can flexibly balance automation and performance based on context.


<details>
  <summary>Details</summary>
Motivation: SMT-based verifiers struggle with quantifier instantiation, which causes a tradeoff between automation and performance: aggressive instantiation provides automation but can slow down verification, while conservative instantiation is faster but demands manual effort. The goal is to address this limitation and allow developers to better manage this tradeoff.

Method: They propose a mechanism for fine-grained control of quantified facts in verification contexts, enabling both library authors and end-users to adjust automation levels at module, function, or proof context granularity. The mechanism is implemented in Verus, a Rust-based verification tool.

Result: Empirical analysis on multiple open codebases shows that their approach exposes the automation-performance tradeoff and enables effective context-dependent tuning of quantifier management.

Conclusion: Selective control over quantifier availability improves developer flexibility, allowing more practical use of SMT-based verification tools by tuning automation as needed for different scenarios.

Abstract: Automated verification tools based on SMT solvers have made significant progress in verifying complex software systems. However, these tools face a fundamental tension between automation and performance when dealing with quantifier instantiation -- the primary source of incompleteness and verification slowdown in SMT-based verifiers. Tools choose between aggressive quantifier instantiation that provides more automation but longer verification times, or conservative instantiation that responds quickly but may require more manual proof hints.
  We present a mechanism that enables fine-grained control over the availability of quantified facts in verification contexts, allowing developers to selectively tune the level of automation. Our approach lets library authors provide different pre-defined automation levels while giving end-users the ability to further customize quantifier availability at the module, function, or proof context level.
  We implement our techniques in Verus, a Rust-based verification tool, and evaluate them on multiple openly available codebases. Our empirical analysis demonstrates the automation-performance tradeoff and that selective quantifier management enables developers to select the appropriate level of automation in different contexts.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Evaluate the Stack Management in Effect Handlers using the libseff C Library](https://arxiv.org/abs/2512.03083)
*ZeHao Yu*

Main category: cs.PL

TL;DR: This paper introduces and evaluates a user-level overcommitting stack management approach for effect handlers, comparing it to traditional and kernel-based methods.


<details>
  <summary>Details</summary>
Motivation: Managing stacks efficiently for effect handlers is complex due to dynamic control flows; existing stack strategies have limitations in memory usage and performance.

Method: They implement user-level overcommitting in the libseff C library using virtual memory and signal-driven commitment, benchmarking it against other stack management strategies with various performance metrics.

Result: User-level overcommitting improves memory utilization and stack resizing, but kernel-based overcommitting is more performant overall; areas for optimizing user-level approaches are identified.

Conclusion: While kernel-based overcommitting balances performance and flexibility well, the user-level approach adds flexibility but suffers some overheads; recommendations are provided for different use cases and future improvements are suggested.

Abstract: Effect handlers are increasingly prominent in modern programming for managing complex computational effects, including concurrency, asynchronous operations, and exception handling, in a modular and flexible manner. Efficient stack management remains a significant challenge for effect handlers due to the dynamic control flow changes they introduce. This paper explores a novel stack management approach using user-level overcommitting within the libseff C library, which leverages virtual memory mechanisms and protection-based lazy allocation combined with signal-driven memory commitment. Our user-level overcommitting implementation dynamically resizes stacks on-demand, improving memory utilization and reducing waste compared to traditional methods. We rigorously benchmark and evaluate this novel strategy against conventional fixed- size stacks, segmented stacks, and kernel-based overcommitting, using metrics such as context-switch latency, stack expansion efficiency, multi-threaded performance, and robustness under rapid stack growth conditions. Experimental results demonstrate that kernel-based overcommitting achieves an effective balance between performance and flexibility, whereas our user-level implementation, while flexible, incurs additional overheads, highlighting areas for optimization. This study provides a detailed comparative analysis of various stack management strate- gies, offering practical recommendations tailored to specific application requirements and operational constraints. Future work will focus on refining user-level overcommit- ting mechanisms, mitigating non-deterministic behaviors, and expanding benchmark frameworks to include real-world scenarios.

</details>


### [7] [Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation](https://arxiv.org/abs/2512.03086)
*Le Chen,Nuo Xu,Winson Chen,Bin Lei,Pei-Hung Lin,Dunzhi Zhou,Rajeev Thakur,Caiwen Ding,Ali Jannesari,Chunhua Liao*

Main category: cs.PL

TL;DR: The paper introduces a pipeline that creates high-quality code translation datasets (including multi-turn dialogues and verified outputs) for low-resource domains, leading to huge performance gains when fine-tuning LLMs for tasks like C++ to CUDA translation.


<details>
  <summary>Details</summary>
Motivation: Large language models perform well in code translation tasks for popular languages but struggle with low-resource domains (e.g., Fortran, CUDA) due to a lack of quality parallel data.

Method: The authors developed an automated dual-LLM (Questioner-Solver) pipeline that uses external knowledge (compiler/runtime feedback) to generate datasets comprising code translations, unit tests, and multi-turn dialogue reasoning. This was applied to create datasets for Fortran-to-C++ and C++-to-CUDA, which were then used to fine-tune language models.

Result: The proposed pipeline generated thousands of dialogue-based datasets for Fortran-to-C++ and C++-to-CUDA translation tasks. Fine-tuning on this dataset improved functional correctness drastically, with unit test pass rates increasing by over 56% for C++ to CUDA. A 7B parameter open-weight model trained on this data exceeded the performance of larger proprietary models in compilation success and related metrics.

Conclusion: Automated, dialogue-enhanced dataset generation greatly improves LLM code translation in low-resource scenarios such as Fortran and CUDA. The resulting data enables even smaller open models to outperform larger closed models on functional tasks.

Abstract: Large language models (LLMs) have shown remarkable capabilities in code translation, yet their performance deteriorates in low-resource programming domains such as Fortran and emerging frameworks like CUDA, where high-quality parallel data are scarce. We present an automated dataset generation pipeline featuring a dual-LLM Questioner-Solver design that incorporates external knowledge from compilers and runtime feedback. Beyond traditional source-target code pair datasets, our approach additionally generates (1) verified translations with unit tests for assessing functional consistency, and (2) multi-turn dialogues that capture the reasoning process behind translation refinement. Applied to Fortran -> C++ and C++ -> CUDA, the pipeline yields 3.64k and 3.93k dialogues, respectively. Fine-tuning on this data yields dramatic improvements in functional correctness, boosting unit test success rates by over 56% on the challenging C++-to-CUDA task. We show this data enables a 7B open-weight model to significantly outperform larger proprietary systems on key metrics like compilation success.

</details>


### [8] [OOPredictor: Predicting Object-Oriented Accesses using Static Analysis](https://arxiv.org/abs/2512.03972)
*Hassan Arafat,David Bremner,Kenneth B. Kent,Julian Wang*

Main category: cs.PL

TL;DR: Pointer chasing in object-oriented code degrades cache performance and is hard for hardware prefetchers to optimize. This work uses static analysis at compile time to predict common access patterns with Markov chains in the JVM. The predictions are accurate and help guide memory optimizations, providing a low-overhead alternative to runtime profiling.


<details>
  <summary>Details</summary>
Motivation: Object-oriented programming (OOP) has widespread adoption due to its adaptability and ability to separate concerns. However, excessive pointer chasing in OOP harms cache performance because it reduces memory locality. Existing software solutions mostly rely on expensive runtime profiling to address this problem.

Method: This paper proposes a novel approach using compile-time static analysis to anticipate the most common memory access patterns in programs. The implementation leverages the OpenJ9 JVM with the OMR optimizer to produce Markov chain models predicting object access behavior.

Result: The predicted Markov chains were compared to actual program execution traces using an instrumented interpreter. Experimental results show the predictor achieves good accuracy and can guide optimization strategies, such as improving garbage collector copying order for better locality.

Conclusion: Compile-time static analysis can effectively predict access patterns in Java OOP programs, enabling targeted optimizations with minimal runtime overhead. This approach provides a practical alternative to costly runtime profiling.

Abstract: Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders

</details>
