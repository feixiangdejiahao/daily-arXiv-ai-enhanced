{"id": "2510.19850", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.19850", "abs": "https://arxiv.org/abs/2510.19850", "authors": ["Mostapha Kalami Heris"], "title": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs", "comment": null, "summary": "Large Language Models (LLMs) are central to reasoning, writing, and\ndecision-support workflows, yet users lack consistent control over how they\nreason and express outputs. Conventional prompt engineering relies on verbose\nnatural-language instructions, limiting reproducibility, modularity, and\ninterpretability. This paper introduces Prompt Decorators, a declarative,\ncomposable syntax that governs LLM behavior through compact control tokens such\nas +++Reasoning, +++Tone(style=formal), and +++Import(topic=\"Systems\nThinking\"). Each decorator modifies a behavioral dimension, such as reasoning\nstyle, structure, or tone, without changing task content. The framework\nformalizes twenty core decorators organized into two functional families\n(Cognitive & Generative and Expressive & Systemic), each further decomposed\ninto subcategories that govern reasoning, interaction, expression, and\nsession-control. It defines a unified syntax, scoping model, and deterministic\nprocessing pipeline enabling predictable and auditable behavior composition. By\ndecoupling task intent from execution behavior, Prompt Decorators create a\nreusable and interpretable interface for prompt design. Illustrative use cases\ndemonstrate improved reasoning transparency, reduced prompt complexity, and\nstandardized model behavior across domains. The paper concludes with\nimplications for interoperability, behavioral consistency, and the development\nof declarative interfaces for scalable AI systems.", "AI": {"tldr": "Prompt Decorators provide a new syntax for controlling LLMs' behavior, enhancing reproducibility and making prompts more modular and interpretable. This results in clearer, more consistent, and auditable LLM outputs.", "motivation": "Traditional prompt engineering for Large Language Models (LLMs) depends on lengthy natural-language instructions, leading to challenges in reproducibility, modularity, and interpretability. Users currently lack robust mechanisms to control how LLMs reason or express their outputs.", "method": "The paper introduces \"Prompt Decorators,\" a declarative and composable syntax that uses compact control tokens to adjust LLM behaviors such as reasoning, tone, and structure. The framework establishes twenty core decorators, organized into functional families, and defines unified syntax, scoping, and processing methods for reliable compositional control.", "result": "Prompt Decorators enable users to control LLM reasoning and output style in a reusable, interpretable, and predictable manner. Use cases in the paper show improved reasoning transparency, reduced complexity, and standardized model behavior across varied domains.", "conclusion": "The study demonstrates that Prompt Decorators allow for greater control and consistency in LLM outputs, promote behavioral standardization, and have positive implications for scalable and interoperable AI interfaces."}}
{"id": "2510.19853", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.19853", "abs": "https://arxiv.org/abs/2510.19853", "authors": ["Assaf Marron", "David Harel"], "title": "A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification", "comment": null, "summary": "An algorithm specification in natural language or pseudocode is expected to\nbe clear and explicit enough to enable mechanical execution. In this position\npaper we contribute an initial characterization of the knowledge that an\nexecuting agent, human or machine, should possess in order to be able to carry\nout the instructions of a given algorithm specification as a stand-alone\nentity, independent of any system implementation. We argue that, for that\nalgorithm specification, such prerequisite knowledge, whether unique or shared\nwith other specifications, can be summarized in a document of practical size.\nWe term this document the realm of the algorithm specification. The generation\nof such a realm is itself a systematic analytical process, significant parts of\nwhich can be automated with the help of large language models and the reuse of\nexisting documents. The algorithm-specification's realm would consist of\nspecification language syntax and semantics, domain knowledge restricted to the\nreferenced entities, inter-entity relationships, relevant underlying\ncause-and-effect rules, and detailed instructions and means for carrying out\ncertain operations. Such characterization of the realm can contribute to\nmethodological implementation of the algorithm specification in diverse systems\nand to its formalization for mechanical verification. The paper also touches\nupon the question of assessing execution faithfulness, which is distinct from\ncorrectness: in the absence of a reference interpretation of natural language\nor pseudocode specification with a given vocabulary, how can we determine if an\nobserved agent's execution indeed complies with the input specification.", "AI": {"tldr": "This paper introduces the concept of an algorithm's 'realm'\u2014a document systematically capturing all prerequisite knowledge for mechanical execution of algorithms. It outlines what this realm should include, describes the analytical and partially automatable process to create it, and argues that this structured approach aids implementation, verification, and assessing execution faithfulness beyond correctness.", "motivation": "The motivation for this paper is to clarify what specific knowledge an executing agent (human or machine) needs to possess to faithfully carry out algorithm specifications written in natural language or pseudocode, independently of any system implementation. There is a need to systematically define and document this prerequisite knowledge to ensure clarity and facilitate mechanical execution, implementation, and verification.", "method": "The authors propose creating a document called the 'realm' of the algorithm specification, which enumerates all the knowledge needed to execute a given algorithm. They discuss the types of information the realm should contain, the process for generating it, and suggest that this process can be partially automated using large language models and document reuse. The paper also introduces a distinction between execution faithfulness and correctness, and highlights the methodological significance of characterizing the realm.", "result": "The result is an initial framework and conceptual analysis of the 'realm' concept, specifying its constituents (language syntax/semantics, domain knowledge, relationships, rules, and instructions) and outlining practical steps toward its generation. The paper identifies opportunities for automation in the creation and reuse of realms, and lays the groundwork for further research in formalizing and verifying algorithm specification execution.", "conclusion": "The paper concludes that defining and documenting the 'realm' of algorithm specifications is feasible and valuable. This approach enhances implementation methodology and provides a basis for formalization, mechanical verification, and assessing execution faithfulness. It also enables partial automation of the realm-creation process using large language models."}}
{"id": "2510.20018", "categories": ["cs.PL", "68N18 (Primary), 03B70 (Secondary)", "F.3.3; D.3.1"], "pdf": "https://arxiv.org/pdf/2510.20018", "abs": "https://arxiv.org/abs/2510.20018", "authors": ["Ryan Kavanagh", "Chuta Sano", "Brigitte Pientka"], "title": "Deconstructed Proto-Quipper: A Rational Reconstruction", "comment": "Submitted to the 35th European Symposium on Programming (ESOP 2026)", "summary": "The Proto-Quipper family of programming languages aims to provide a formal\nfoundation for the Quipper quantum programming language. Unfortunately,\nProto-Quipper languages have complex operational semantics: they are inherently\neffectful, and they rely on set-theoretic operations and fresh name generation\nto manipulate quantum circuits. This makes them difficult to reason about using\nstandard programming language techniques and, ultimately, to mechanize. We\nintroduce Proto-Quipper-A, a rational reconstruction of Proto-Quipper languages\nfor static circuit generation. It uses a linear $\\lambda$-calculus to describe\nquantum circuits with normal forms that closely correspond to box-and-wire\ncircuit diagrams. Adjoint-logical foundations integrate this circuit language\nwith a linear/non-linear functional language and let us reconstruct\nProto-Quipper's circuit programming abstractions using more primitive\nadjoint-logical operations. Proto-Quipper-A enjoys a simple call-by-value\nreduction semantics, and to illustrate its tractability as a foundation for\nProto-Quipper languages, we show that it is normalizing. We show how to use\nstandard logical relations to prove normalization of linear and substructural\nsystems, thereby avoiding the inherent complexity of existing linear logical\nrelations.", "AI": {"tldr": "Proto-Quipper-A simplifies and formalizes quantum circuit programming semantics, improves mechanization, and proves normalization using logical relations.", "motivation": "Existing Proto-Quipper languages have complex operational semantics, making them hard to reason about and mechanize. A more tractable and formal foundation is needed.", "method": "The paper introduces Proto-Quipper-A, a linear lambda calculus-based programming language for quantum circuits, with adjoint-logical foundations. It employs standard logical relations to prove normalization, avoiding complex set-theoretic or name-generation techniques.", "result": "Proto-Quipper-A achieves a simple call-by-value reduction semantics, and the authors demonstrate its normalization property using logical relations, specifically for linear and substructural systems.", "conclusion": "Proto-Quipper-A provides a simpler, formal, and mechanizable foundation for Proto-Quipper quantum circuit programming, supporting normalization and better reasoning through standard logical relations."}}
{"id": "2510.20532", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.20532", "abs": "https://arxiv.org/abs/2510.20532", "authors": ["Patrycja Balik", "Szymon J\u0119dras", "Piotr Polesiuk"], "title": "Deciding not to Decide: Sound and Complete Effect Inference in the Presence of Higher-Rank Polymorphism", "comment": null, "summary": "Type-and-effect systems help the programmer to organize data and\ncomputational effects in a program. While for traditional type systems\nexpressive variants with sophisticated inference algorithms have been developed\nand widely used in programming languages, type-and-effect systems did not yet\ngain widespread adoption. One reason for this is that type-and-effect systems\nare more complex and the existing inference algorithms make compromises between\nexpressiveness, intuitiveness, and decidability. In this work, we present an\neffect inference algorithm for a type-and-effect system with subtyping,\nexpressive higher-rank polymorphism, and intuitive set-like semantics of\neffects. In order to deal with scoping issues of higher-rank polymorphism, we\ndelay solving of effect constraints by transforming them into formulae of\npropositional logic. We prove soundness and completeness of our algorithm with\nrespect to a declarative type-and-effect system. All the presented results have\nbeen formalized in the Rocq proof assistant, and the algorithm has been\nsuccessfully implemented in a realistic programming language.", "AI": {"tldr": "The paper introduces a robust effect inference algorithm for expressive type-and-effect systems with higher-rank polymorphism, subtyping, and intuitive effects semantics, offering formal guarantees and real-world implementation.", "motivation": "Type-and-effect systems are not widely used in practice due to their complexity and less mature inference algorithms compared to standard type systems, leading to challenges in balancing expressiveness, intuitiveness, and decidability.", "method": "The authors propose an effect inference algorithm for a type-and-effect system featuring subtyping, higher-rank polymorphism, and set-like semantics of effects. They address higher-rank scoping issues by delaying effect constraint solving, representing them as propositional logic formulae. They formally prove the soundness and completeness of the algorithm with respect to a declarative system, and implement it in a real programming language.", "result": "The soundness and completeness of the new effect inference algorithm were proven formally (in the Rocq proof assistant), and the algorithm was successfully implemented in a realistic programming language.", "conclusion": "A practical and theoretically sound effect inference algorithm for advanced type-and-effect systems is feasible, addressing previous limitations in expressiveness, intuitiveness, and decidability."}}
{"id": "2510.19860", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19860", "abs": "https://arxiv.org/abs/2510.19860", "authors": ["Ketai Qiu", "Luca Di Grazia", "Leonardo Mariani", "Mauro Pezz\u00e8"], "title": "E-Test: E'er-Improving Test Suites", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "Test suites are inherently imperfect, and testers can always enrich a suite\nwith new test cases that improve its quality and, consequently, the reliability\nof the target software system. However, finding test cases that explore\nexecution scenarios beyond the scope of an existing suite can be extremely\nchallenging and labor-intensive, particularly when managing large test suites\nover extended periods.\n  In this paper, we propose E-Test, an approach that reduces the gap between\nthe execution space explored with a test suite and the executions experienced\nafter testing by augmenting the test suite with test cases that explore\nexecution scenarios that emerge in production. E-Test (i) identifies executions\nthat have not yet been tested from large sets of scenarios, such as those\nmonitored during intensive production usage, and (ii) generates new test cases\nthat enhance the test suite. E-Test leverages Large Language Models (LLMs) to\npinpoint scenarios that the current test suite does not adequately cover, and\naugments the suite with test cases that execute these scenarios.\n  Our evaluation on a dataset of 1,975 scenarios, collected from highly-starred\nopen-source Java projects already in production and Defects4J, demonstrates\nthat E-Test retrieves not-yet-tested execution scenarios significantly better\nthan state-of-the-art approaches. While existing regression testing and field\ntesting approaches for this task achieve a maximum F1-score of 0.34, and\nvanilla LLMs achieve a maximum F1-score of 0.39, E-Test reaches 0.55. These\nresults highlight the impact of E-Test in enhancing test suites by effectively\ntargeting not-yet-tested execution scenarios and reducing manual effort\nrequired for maintaining test suites.", "AI": {"tldr": "E-Test uses LLMs to automatically find and generate test cases for real production scenarios missing from current test suites, achieving better coverage and higher F1-scores than state-of-the-art methods, which saves manual effort and improves software reliability.", "motivation": "Test suites often fail to cover all possible execution scenarios in large or long-lived software systems. Identifying and covering untested scenarios from production is difficult and time-consuming. The motivation is to automate enriching test suites with cases that represent untested execution paths seen in production, thus improving software reliability and reducing manual labor.", "method": "The authors propose E-Test, an approach that uses Large Language Models (LLMs) to identify execution scenarios from production that are not yet covered by the current test suite. E-Test then generates new test cases for these scenarios, augmenting the existing suite. The method was evaluated on over 1,900 scenarios from open-source Java projects and the Defects4J dataset.", "result": "E-Test outperforms existing regression and field testing approaches, retrieving not-yet-tested scenarios with a maximum F1-score of 0.55, compared to baseline methods (0.34 for state-of-the-art, 0.39 for vanilla LLMs).", "conclusion": "E-Test is more effective than previous approaches at identifying and covering execution scenarios not yet tested by a suite. This results in enhanced test suites and reduces the manual effort needed for test maintenance."}}
{"id": "2510.20547", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.20547", "abs": "https://arxiv.org/abs/2510.20547", "authors": ["Nikolaus Huber", "Susanne Graf", "Philipp R\u00fcmmer", "Wang Yi"], "title": "Compiling the Mimosa programming language to RTOS tasks", "comment": null, "summary": "This paper introduces a compilation scheme for programs written in the Mimosa\nprogramming language, which builds upon the MIMOS model of computation. Mimosa\ndescribes embedded systems software as a collection of time-triggered processes\nwhich communicate through FIFO queues. We formally describe an adaptation of\nthe Lustre compilation scheme to the semantics of Mimosa and show how the\ncoordination layer can be mapped to real-time operating system primitives.", "AI": {"tldr": "A new compilation scheme for the Mimosa programming language is proposed, adapting Lustre's approach and integrating it with real-time OS features for embedded systems.", "motivation": "The paper is motivated by the need for effective compilation schemes for the Mimosa programming language, which is designed for embedded systems using the MIMOS computational model.", "method": "The authors formally adapt the Lustre compilation scheme to fit the unique semantics of the Mimosa language and show how its coordination layer can be implemented using real-time operating system primitives.", "result": "The paper presents a working scheme that allows Mimosa programs\u2014described as collections of time-triggered, FIFO-communicating processes\u2014to be effectively compiled and mapped onto real-time operating system features.", "conclusion": "Their adaptation makes it practical to develop and deploy Mimosa-based embedded software using robust compilation and OS mapping techniques."}}
{"id": "2510.19864", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19864", "abs": "https://arxiv.org/abs/2510.19864", "authors": ["Amila Indika", "Igor Molybog"], "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "comment": "14 pages, 5 figures, 4 tables", "summary": "Numerous knowledge workers utilize spreadsheets in business, accounting, and\nfinance. However, a lack of systematic documentation methods for spreadsheets\nhinders automation, collaboration, and knowledge transfer, which risks the loss\nof crucial institutional knowledge. This paper introduces Spreadsheet\nOperations Documentation (SOD), an AI task that involves generating\nhuman-readable explanations from spreadsheet operations. Many previous studies\nhave utilized Large Language Models (LLMs) for generating spreadsheet\nmanipulation code; however, translating that code into natural language for SOD\nis a less-explored area. To address this, we present a benchmark of 111\nspreadsheet manipulation code snippets, each paired with a corresponding\nnatural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini,\nLLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and\nMETEOR metrics. Our findings suggest that LLMs can generate accurate\nspreadsheet documentation, making SOD a feasible prerequisite step toward\nenhancing reproducibility, maintainability, and collaborative workflows in\nspreadsheets, although there are challenges that need to be addressed.", "AI": {"tldr": "This paper proposes and benchmarks an AI task to convert spreadsheet code into human-readable documentation. Five LLMs are tested, showing promising results for automating documentation, thus supporting better collaboration and knowledge sharing in spreadsheet-heavy workflows.", "motivation": "Knowledge workers widely use spreadsheets, but lack of systematic documentation hampers automation, collaboration, and knowledge retention. This risk leads to potential loss of critical institutional knowledge.", "method": "The paper introduces Spreadsheet Operations Documentation (SOD), formulating it as an AI task to automatically generate human-readable explanations from spreadsheet operations. They create a benchmark of 111 spreadsheet code snippets paired with natural language summaries and evaluate five LLMs (GPT-4o, GPT-4o-mini, LLaMA-3.3-70B, Mixtral-8x7B, Gemma2-9B) using BLEU, GLEU, ROUGE-L, and METEOR metrics.", "result": "LLMs can generate accurate documentation for spreadsheet operations. SOD is feasible and can improve reproducibility, maintainability, and collaboration for spreadsheets, though some challenges remain.", "conclusion": "Spreadsheet documentation generation using LLMs is viable and beneficial for knowledge transfer and collaboration in professional environments, but further work is needed to overcome the identified challenges."}}
{"id": "2510.20688", "categories": ["cs.PL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20688", "abs": "https://arxiv.org/abs/2510.20688", "authors": ["Oliver Braunsdorf", "Tim Lange", "Konrad Hohentanner", "Julian Horsch", "Johannes Kinder"], "title": "SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe Code in Rust and Mixed-Language Applications", "comment": null, "summary": "Unsafe Rust code is necessary for interoperability with C/C++ libraries and\nimplementing low-level data structures, but it can cause memory safety\nviolations in otherwise memory-safe Rust programs. Sanitizers can catch such\nmemory errors at runtime, but introduce many unnecessary checks even for memory\naccesses guaranteed safe by the Rust type system. We introduce SafeFFI, a\nsystem for optimizing memory safety instrumentation in Rust binaries such that\nchecks occur at the boundary between unsafe and safe code, handing over the\nenforcement of memory safety from the sanitizer to the Rust type system. Unlike\nprevious approaches, our design avoids expensive whole-program analysis and\nadds much less compile-time overhead (2.64x compared to over 8.83x). On a\ncollection of popular Rust crates and known vulnerable Rust code, SafeFFI\nachieves superior performance compared to state-of-the-art systems, reducing\nsanitizer checks by up to 98%, while maintaining correctness and flagging all\nspatial and temporal memory safety violations.", "AI": {"tldr": "SafeFFI optimizes memory safety checks in Rust, reducing runtime and compile-time overhead by enforcing checks only at the boundary of safe and unsafe code, achieving superior performance while maintaining full protection.", "motivation": "Rust ensures memory safety in safe code, but interoperability with C/C++ and certain low-level programming require unsafe Rust code, which can introduce memory safety vulnerabilities. Existing sanitizers for detecting such issues incur unnecessary overhead in memory-safe regions, motivating the need for a more efficient system.", "method": "The authors introduce SafeFFI, a system that strategically places memory safety instrumentation at the boundary of safe and unsafe code. By delegating safety guarantees inside safe Rust to the compiler/type system and focusing runtime checks only on unsafe regions, SafeFFI minimizes unnecessary instrumentation. Notably, this approach avoids costly whole-program analysis and limits compile-time performance impact.", "result": "SafeFFI significantly reduces the amount of runtime checks (by up to 98%) compared to existing systems. It maintains correctness, catching all spatial and temporal memory safety violations, and decreases compile-time overhead to 2.64x versus 8.83x for previous solutions. These results are demonstrated on both popular Rust crates and intentionally vulnerable code.", "conclusion": "SafeFFI represents a practical and performant solution for memory safety in Rust programs that incorporate unsafe code, optimizing sanitizer overhead while preserving detection accuracy."}}
{"id": "2510.19868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19868", "abs": "https://arxiv.org/abs/2510.19868", "authors": ["Qian Xiong", "Bo Yang", "Weisong Sun", "Yiran Zhang", "Tianlin Li", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "comment": null, "summary": "Automated code generation driven by Large Lan- guage Models (LLMs) has\nenhanced development efficiency, yet generating complex application-level\nsoftware code remains challenging. Multi-agent frameworks show potential, but\nexisting methods perform inadequately in large-scale application-level software\ncode generation, failing to ensure reasonable orga- nizational structures of\nproject code and making it difficult to maintain the code generation process.\nTo address this, this paper envisions a Knowledge-Guided Application-Level Code\nGeneration framework named KGACG, which aims to trans- form software\nrequirements specification and architectural design document into executable\ncode through a collaborative closed- loop of the Code Organization & Planning\nAgent (COPA), Coding Agent (CA), and Testing Agent (TA), combined with a\nfeedback mechanism. We demonstrate the collaborative process of the agents in\nKGACG in a Java Tank Battle game case study while facing challenges. KGACG is\ndedicated to advancing the automation of application-level software\ndevelopment.", "AI": {"tldr": "The paper presents KGACG, a multi-agent framework using LLMs to automate application-level software code generation more effectively by improving organization and maintenance, as demonstrated through a Java game example.", "motivation": "Automated code generation by LLMs has improved development efficiency, but there are still difficulties in generating complex, application-level code, primarily due to poor organization and maintenance in current multi-agent approaches.", "method": "The paper proposes KGACG, a framework that converts software requirements and architectural documents into executable code by employing multiple specialized agents: Code Organization & Planning Agent (COPA), Coding Agent (CA), and Testing Agent (TA), working collaboratively in a closed loop with feedback mechanisms.", "result": "The process and effectiveness of the KGACG framework are demonstrated through a Java Tank Battle game case study, showing how the agents collaborate and address current challenges in code generation.", "conclusion": "KGACG provides a step forward in automating application-level software development and addresses shortcomings in code organization and maintenance seen in existing multi-agent LLM-driven systems."}}
{"id": "2510.19898", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19898", "abs": "https://arxiv.org/abs/2510.19898", "authors": ["Atharv Sonwane", "Isadora White", "Hyunji Lee", "Matheus Pereira", "Lucas Caccia", "Minseon Kim", "Zhengyan Shi", "Chinmay Singh", "Alessandro Sordoni", "Marc-Alexandre C\u00f4t\u00e9", "Xingdi Yuan"], "title": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "comment": null, "summary": "High quality bugs are key to training the next generation of language model\nbased software engineering (SWE) agents. We introduce a novel method for\nsynthetic generation of difficult and diverse bugs. Our method instructs SWE\nAgents to introduce a feature into the codebase whereby they may\nunintentionally break tests, resulting in bugs. Prior approaches often induce\nan out-of-distribution effect by generating bugs intentionally (e.g. by\nintroducing local perturbation to existing code), which does not reflect\nrealistic development processes. We perform qualitative analysis to demonstrate\nthat our approach for generating bugs more closely reflects the patterns found\nin human-authored edits. Through extensive experiments, we demonstrate that our\nbugs provide more efficient training data for supervised fine-tuning,\noutperforming other bug datasets by 2% with half the training data (1.2k vs. 3k\nbugs). We train on our newly generated bugs in addition to existing bug\ndatasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench\nVerified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on\nSWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over\nthree seeds.", "AI": {"tldr": "This paper proposes a new way to generate training bugs for AI coding agents by simulating real development errors, leading to more effective training and state-of-the-art model performance compared to previous synthetic bug datasets.", "motivation": "High-quality bugs are crucial for training language model-based software engineering agents, but current synthetic bug generation methods do not accurately reflect how bugs are introduced during real development processes.", "method": "The authors introduce a method that instructs software engineering agents to add new features to codebases, potentially and unintentionally breaking tests and generating bugs. This contrasts with existing methods that introduce deliberate, often unrealistic code perturbations.", "result": "The approach produces bugs that better mimic human-edit patterns. Experimental results show the generated bugs are more efficient for training language models, achieving superior performance (2% higher with half the data compared to other datasets). Models trained with these bugs achieve state-of-the-art results on SWE-bench Verified: FrogBoss (32B) at 54.6% pass@1, FrogMini (14B) at 45.3% pass@1.", "conclusion": "Generating bugs by simulating realistic development processes (i.e., feature introduction) produces higher-quality and more efficient bug datasets for training, resulting in better-performing software engineering agents than alternative synthetic bug approaches."}}
{"id": "2510.19984", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19984", "abs": "https://arxiv.org/abs/2510.19984", "authors": ["Konstantinos Kitsios", "Marcel B\u00f6hme", "Alberto Bacchelli"], "title": "On Interaction Effects in Greybox Fuzzing", "comment": "12 pages, 2 figures, Accepted for presentation at the 48th\n  International Conference on Software Engineering (ICSE '26)", "summary": "A greybox fuzzer is an automated software testing tool that generates new\ntest inputs by applying randomly chosen mutators (e.g., flipping a bit or\ndeleting a block of bytes) to a seed input in random order and adds all\ncoverage-increasing inputs to the corpus of seeds. We hypothesize that the\norder in which mutators are applied to a seed input has an impact on the\neffectiveness of greybox fuzzers. In our experiments, we fit a linear model to\na dataset that contains the effectiveness of all possible mutator pairs and\nindeed observe the conjectured interaction effect. This points us to more\nefficient fuzzing by choosing the most promising mutator sequence with a higher\nlikelihood. We propose MuoFuzz, a greybox fuzzer that learns and chooses the\nmost promising mutator sequences. MuoFuzz learns the conditional probability\nthat the next mutator will yield an interesting input, given the previously\nselected mutator. Then, it samples from the learned probability using a random\nwalk to generate mutator sequences. We compare the performance of MuoFuzz to\nAFL++, which uses a fixed selection probability, and MOPT, which optimizes the\nselection probability of each mutator in isolation. Experimental results on the\nFuzzBench and MAGMA benchmarks show that MuoFuzz achieves the highest code\ncoverage and finds four bugs missed by AFL++ and one missed by both AFL++ and\nMOPT.", "AI": {"tldr": "MuoFuzz is a new greybox fuzzer that learns the most effective mutator sequences, proving superior to existing tools by covering more code and finding more bugs in benchmark tests.", "motivation": "Greybox fuzzers are widely used for automated software testing, but their effectiveness can be limited by the random application order of mutators. This paper aims to investigate whether the order of applying mutators affects the efficiency of fuzzing and to find ways to improve fuzzing effectiveness.", "method": "The researchers fit a linear model to a dataset containing the effectiveness of all possible mutator pairs in fuzzing, identifying interaction effects. They then propose MuoFuzz, a greybox fuzzer that learns the conditional probability of successful input generation given the sequence of mutators chosen so far, and samples promising sequences through a random walk. The performance of MuoFuzz is compared against AFL++ and MOPT on the FuzzBench and MAGMA benchmarks.", "result": "MuoFuzz achieves the highest code coverage among the tested fuzzers and discovers four bugs missed by AFL++ and one bug missed by both AFL++ and MOPT, demonstrating improved effectiveness in fuzzing.", "conclusion": "The order in which mutators are applied significantly affects greybox fuzzer effectiveness. By learning and exploiting promising mutator sequences, MuoFuzz can outperform established fuzzers, achieving higher code coverage and discovering unique bugs."}}
{"id": "2510.19997", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19997", "abs": "https://arxiv.org/abs/2510.19997", "authors": ["Abraham Itzhak Weinberg"], "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) presents transformative\nopportunities for organizations, yet both midsize organizations and larger\nenterprises face distinctive adoption challenges. Midsize organizations\nencounter resource constraints and limited AI expertise, while enterprises\nstruggle with organizational complexity and coordination challenges. Existing\ntechnology adoption frameworks, including TAM (Technology Acceptance Model),\nTOE (Technology Organization Environment), and DOI (Diffusion of Innovations)\ntheory, lack the specificity required for GenAI implementation across these\ndiverse contexts, creating a critical gap in adoption literature. This paper\nintroduces FAIGMOE (Framework for the Adoption and Integration of Generative AI\nin Midsize Organizations and Enterprises), a conceptual framework addressing\nthe unique needs of both organizational types. FAIGMOE synthesizes technology\nadoption theory, organizational change management, and innovation diffusion\nperspectives into four interconnected phases: Strategic Assessment, Planning\nand Use Case Development, Implementation and Integration, and\nOperationalization and Optimization. Each phase provides scalable guidance on\nreadiness assessment, strategic alignment, risk governance, technical\narchitecture, and change management adaptable to organizational scale and\ncomplexity. The framework incorporates GenAI specific considerations including\nprompt engineering, model orchestration, and hallucination management that\ndistinguish it from generic technology adoption frameworks. As a perspective\ncontribution, FAIGMOE provides the first comprehensive conceptual framework\nexplicitly addressing GenAI adoption across midsize and enterprise\norganizations, offering actionable implementation protocols, assessment\ninstruments, and governance templates requiring empirical validation through\nfuture research.", "AI": {"tldr": "This paper proposes FAIGMOE, a new framework tailored to help midsize and enterprise organizations adopt Generative AI. Unlike existing models, FAIGMOE tackles both resource and complexity barriers, integrates GenAI-specific requirements, and supports organizations with practical tools\u2014though it needs real-world validation.", "motivation": "Generative AI offers major opportunities but faces unique challenges in adoption. Midsize organizations lack resources and AI expertise; large enterprises struggle with complexity and coordination. Current frameworks (TAM, TOE, DOI) do not specifically address GenAI adoption in these organizational types, leaving a research gap.", "method": "The paper introduces FAIGMOE, a conceptual framework for GenAI adoption and integration in midsize and enterprise organizations. FAIGMOE combines concepts from technology adoption theory, organizational change management, and innovation diffusion, structured into four phases\u2014Strategic Assessment, Planning and Use Case Development, Implementation and Integration, Operationalization and Optimization.", "result": "FAIGMOE provides scalable, actionable guidance for readiness assessment, strategic alignment, risk governance, technical architecture, and change management adapted to both midsize and enterprise organizations. It also incorporates GenAI-specific elements such as prompt engineering, model orchestration, and hallucination management, setting it apart from generic technology frameworks.", "conclusion": "FAIGMOE is the first comprehensive conceptual framework to specifically address GenAI adoption in organizations of varying size and complexity. It offers practical protocols, assessment tools, and governance templates, but further empirical validation is required."}}
{"id": "2510.20041", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20041", "abs": "https://arxiv.org/abs/2510.20041", "authors": ["Gareema Ranjan", "Mahmoud Alfadel", "Gengyi Sun", "Shane McIntosh"], "title": "The Cost of Downgrading Build Systems: A Case Study of Kubernetes", "comment": null, "summary": "Since developers invoke the build system frequently, its performance can\nimpact productivity. Modern artifact-based build tools accelerate builds, yet\nprior work shows that teams may abandon them for alternatives that are easier\nto maintain. While prior work shows why downgrades are performed, the\nimplications of downgrades remain largely unexplored. In this paper, we\ndescribe a case study of the Kubernetes project, focusing on its downgrade from\nan artifact-based build tool (Bazel) to a language-specific solution (Go\nBuild). We reproduce and analyze the full and incremental builds of change sets\nduring the downgrade period. On the one hand, we find that Bazel builds are\nfaster than Go Build, completing full builds in 23.06-38.66 up to 75.19 impose\na larger memory footprint than Go Build of 81.42-351.07 respectively. Bazel\nbuilds also impose a greater CPU load at parallelism settings above eight for\nfull builds and above one for incremental builds. We estimate that downgrading\nfrom Bazel can increase CI resource costs by up to 76 explore whether our\nobservations generalize by replicating our Kubernetes study on four other\nprojects that also downgraded from Bazel to older build tools. We observe that\nwhile build time penalties decrease, Bazel consistently consumes more memory.\nWe conclude that abandoning artifact-based build tools, despite perceived\nmaintainability benefits, tends to incur considerable performance costs for\nlarge projects. Our observations may help stakeholders to balance trade-offs in\nbuild tool adoption", "AI": {"tldr": "Downgrading from fast, artifact-based build tools like Bazel to simpler alternatives makes build system maintenance easier, but introduces significant performance and resource costs, particularly for large-scale projects.", "motivation": "Developers frequently use build systems, impacting productivity. Although modern artifact-based build tools (like Bazel) can accelerate builds, teams sometimes revert to simpler tools for maintainability reasons. The impact of such downgrades is not well understood.", "method": "This paper presents a case study of the Kubernetes project, analyzing its downgrade from Bazel (artifact-based) to Go Build (language-specific). The study involves reproducing and analyzing full and incremental builds during the downgrade period, measuring performance, memory consumption, and CPU usage. The results are further generalized by examining four other projects that also downgraded from Bazel.", "result": "Bazel builds were faster than Go Build but used significantly more memory (81.42-351.07MB) and imposed a greater CPU load at higher parallelism settings. Downgrading from Bazel increased CI resource costs by up to 76%. In four additional projects, Bazel continued to use more memory but the build time penalties of alternatives decreased.", "conclusion": "Switching from artifact-based to simpler build tools may ease maintainability but often results in considerable performance costs, especially for large projects. Stakeholders need to carefully weigh these trade-offs when choosing build systems."}}
{"id": "2510.20121", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20121", "abs": "https://arxiv.org/abs/2510.20121", "authors": ["Carlos J. Fernandez-Candel", "Jesus Garcia-Molina", "Francisco Javier Bermudez Ruiz", "Jose Ramon Hoyos Barcelo", "Diego Sevilla Ruiz", "Benito Jose Cuesta Viera"], "title": "Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience", "comment": "31 pages, 22 figures", "summary": "Model-driven software engineering (MDE) techniques are not only useful in\nforward engineering scenarios, but can also be successfully applied to evolve\nexisting systems. RAD (Rapid Application Development) platforms emerged in the\nnineties, but the success of modern software technologies motivated that a\nlarge number of enterprises tackled the migration of their RAD applications,\nsuch as Oracle Forms. Our research group has collaborated with a software\ncompany in developing a solution to migrate PL/SQL monolithic code on Forms\ntriggers and program units to Java code separated in several tiers.\n  Our research focused on the model-driven reengineering process applied to\ndevelop the migration tool for the conversion of PL/SQL code to Java. Legacy\ncode is represented in form of KDM (Knowledge-Discovery Metamodel) models. In\nthis paper, we propose a software process to implement a model-driven\nre-engineering. This process integrates a TDD-like approach to incrementally\ndevelop model transformations with three kinds of validations for the generated\ncode. The implementation and validation of the re-engineering approach are\nexplained in detail, as well as the evaluation of some issues related with the\napplication of MDE.", "AI": {"tldr": "The paper presents a model-driven approach, using KDM and TDD-like validation, to migrate legacy PL/SQL Oracle Forms applications to multi-tier Java systems. It details the migration process, tool development, and validation strategies.", "motivation": "Many enterprises need to migrate legacy RAD applications (like Oracle Forms with PL/SQL code) to modern software platforms. Existing systems require effective approaches for migration, which can benefit from MDE techniques.", "method": "The paper proposes a model-driven re-engineering process for migrating legacy PL/SQL code to Java tiers. The process uses KDM models to represent legacy code and integrates a TDD-like approach for incrementally developing and validating model transformations before generating the final code.", "result": "The paper describes the implementation of this migration tool, detailing its validation methods (three types of validations for generated code) and evaluating challenges encountered during the application of MDE for legacy system migration.", "conclusion": "Model-driven re-engineering, supported by structured validation and incremental transformation development, can effectively facilitate the migration of legacy RAD applications (e.g., Oracle Forms) to modern Java-based, multi-tier systems."}}
{"id": "2510.20211", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20211", "abs": "https://arxiv.org/abs/2510.20211", "authors": ["Zhenning Yang", "Hui Guan", "Victor Nicolet", "Brandon Paulsen", "Joey Dodds", "Daniel Kroening", "Ang Chen"], "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "comment": null, "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally,\ncloud consoles, command-line interfaces (CLI), and SDKs are the tools of\nchoice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have\nquickly gained popularity. Unlike conventional tools, IaC~frameworks encode the\ninfrastructure in a \"source-of-truth\" configuration. They are capable of\nautomatically carrying out modifications to the cloud -- deploying, updating,\nor destroying resources -- to bring the actual infrastructure into alignment\nwith the IaC configuration. However, when IaC is used alongside consoles, CLIs,\nor SDKs, it loses visibility into external changes, causing infrastructure\ndrift, where the configuration becomes outdated, and later IaC operations may\nundo valid updates or trigger errors.\n  We present NSync, an automated system for IaC reconciliation that propagates\nout-of-band changes back into the IaC program. Our key insight is that\ninfrastructure changes eventually all occur via cloud API invocations -- the\nlowest layer for cloud management operations. NSync gleans insights from API\ntraces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update\nthe IaC configuration to capture the changes). It employs an agentic\narchitecture that leverages LLMs to infer high-level intents from noisy API\nsequences, synthesize targeted IaC updates using specialized tools, and\ncontinually improve through a self-evolving knowledge base of past\nreconciliations. We further introduce a novel evaluation pipeline for injecting\nrealistic drifts into cloud infrastructure and assessing reconciliation\nperformance. Experiments across five real-world Terraform projects and 372\ndrift scenarios show that NSync outperforms the baseline both in terms of\naccuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$\nimprovement).", "AI": {"tldr": "NSync solves the long-standing problem of infrastructure drift in cloud management by automatically detecting and reconciling changes outside of IaC frameworks using cloud API traces and LLM inference, achieving high accuracy and efficiency in extensive real-world evaluations.", "motivation": "Infrastructure-as-Code (IaC) frameworks like Terraform have revolutionized cloud management but face a major issue: when used with other tools (consoles, CLI, SDKs), they can lose track of direct changes, leading to 'infrastructure drift' and erroneous operations. This paper aims to resolve the challenge of drift detection and reconciliation in mixed-management cloud environments.", "method": "The authors introduce NSync, an automated reconciliation system that monitors cloud API traces to detect changes made outside of IaC, uses large language models (LLMs) to infer intent and synthesize corrective IaC updates, and continually learns and adapts through an evolving knowledge base. They further develop an evaluation pipeline to realistically simulate drift scenarios.", "result": "NSync was tested on five real-world Terraform projects, handling 372 drift scenarios. The system demonstrated superior performance over baseline approaches, achieving a significant increase in accuracy (pass@3 improved from 0.71 to 0.97) and better token efficiency (1.47\u00d7 improvement).", "conclusion": "NSync provides an effective and automated solution to reconcile out-of-band cloud infrastructure changes with IaC configurations, utilizing API tracing, LLM-driven intent inference, and self-improving mechanisms to maintain infrastructure consistency. The results prove its practical value and reliability in real-world scenarios."}}
{"id": "2510.20340", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20340", "abs": "https://arxiv.org/abs/2510.20340", "authors": ["Serena Cofano", "Daniel Williams", "Aman Sharma", "Martin Monperrus"], "title": "Classport: Designing Runtime Dependency Introspection for Java", "comment": null, "summary": "Runtime introspection of dependencies, i.e., the ability to observe which\ndependencies are currently used during program execution, is fundamental for\nSoftware Supply Chain security. Yet, Java has no support for it. We solve this\nproblem with Classport, a system that embeds dependency information into Java\nclass files, enabling the retrieval of dependency information at runtime. We\nevaluate Classport on six real-world projects, demonstrating the feasibility in\nidentifying dependencies at runtime. Runtime dependency introspection with\nClassport opens important avenues for runtime integrity checking.", "AI": {"tldr": "Java applications traditionally lack runtime visibility into their dependencies, posing a security risk. Classport solves this by embedding dependency information into class files, enabling runtime introspection. Evaluation on six projects confirms that Classport can reliably identify dependencies during execution, opening the door to improved software supply chain integrity checks.", "motivation": "Java currently lacks the capability for runtime introspection of dependencies, which is crucial for enhancing Software Supply Chain security. This limitation motivates the development of a system that can provide real-time visibility into which dependencies are used during program execution.", "method": "The authors present Classport, a system that embeds dependency information directly into Java class files. This enables the retrieval and observation of dependency usage during program execution without altering the runtime environment.", "result": "Classport was evaluated on six real-world Java projects. The evaluation showed its feasibility, successfully identifying dependencies at runtime and demonstrating practical effectiveness.", "conclusion": "Classport enables runtime dependency introspection for Java applications, facilitating new possibilities for integrity checking during execution and enhancing supply chain security."}}
{"id": "2510.20389", "categories": ["cs.SE", "cs.DC", "D.m"], "pdf": "https://arxiv.org/pdf/2510.20389", "abs": "https://arxiv.org/abs/2510.20389", "authors": ["Bjorn Remseth"], "title": "Symmetry in Software Platforms as an Architectural Principle", "comment": "Working paper, 11 pages", "summary": "Software platforms often act as structure preserving systems. They provide\nconsistent interfaces and behaviors that remain stable under specific\ntransformations that we denote as symmetries. This paper explores the idea that\narchitectural robustness emerges from enforcing such structural regularities", "AI": {"tldr": "By maintaining structural regularities, software platforms achieve robustness and consistency, even when they undergo certain changes or transformations.", "motivation": "The motivation is to understand why software platforms are able to maintain stable and consistent interfaces and behaviors despite transformations.", "method": "The paper explores the role of symmetries and structural regularities in the architecture of software platforms. It analyzes how enforcing these regularities contributes to robustness.", "result": "The results demonstrate that enforcing structural regularities (symmetries) makes software platforms more robust and capable of preserving desired behaviors under changes or transformations.", "conclusion": "Architectural robustness in software platforms is achieved by enforcing structural regularities, which act as symmetries to preserve system consistency."}}
{"id": "2510.20403", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20403", "abs": "https://arxiv.org/abs/2510.20403", "authors": ["Santiago Gil", "Ecem E. Ba\u015f", "Christian D. Jensen", "Sebastian Engelsgaard", "Giuseppe Abbiati", "Cl\u00e1udio Gomes"], "title": "FMI-Based Distributed Co-Simulation with Enhanced Security and Intellectual Property Safeguards", "comment": "6 pages, Proceedings of the 2025 Annual Modeling and Simulation\n  Conference (ANNSIM)", "summary": "Distributed co-simulation plays a key role in enabling collaborative modeling\nand simulation by different stakeholders while protecting their Intellectual\nProperty (IP). Although IP protection is provided implicitly by co-simulation,\nthere is no consensus in the guidelines to conduct distributed co-simulation of\ncontinuous-time or hybrid systems with no exposure to potential hacking\nattacks. We propose an approach for distributed co-simulation on top of UniFMU\nwith enhanced cybersecurity and IP protection mechanisms, ensuring that the\nconnection is initiated by the client and the models and binaries live on\ntrusted platforms. We showcase the functionality of this approach using two\nco-simulation demos in four different network settings and analyze the\ntrade-off between IP-protected distribution and performance efficiency in these\nsettings.", "AI": {"tldr": "This paper introduces a UniFMU-based distributed co-simulation method that enhances cybersecurity and IP protection, validated through multiple demos and analyzed for efficiency and protection trade-offs.", "motivation": "There is a need for collaborative modeling and simulation among stakeholders while protecting intellectual property (IP). Existing distributed co-simulation lacks clear cybersecurity guidelines, especially against hacking attacks, for continuous-time and hybrid systems.", "method": "The authors propose an enhanced distributed co-simulation approach using UniFMU, incorporating improved cybersecurity and IP protection mechanisms. This method ensures client-initiated connections and ensures that models and binaries reside on trusted platforms. The approach is demonstrated through two co-simulation demos tested in four different network settings.", "result": "The authors successfully demonstrate the functionality of their approach with enhanced security and IP protection. They analyze the trade-offs between IP protection and performance efficiency across the tested settings.", "conclusion": "The proposed approach provides more secure and IP-protected distributed co-simulation using UniFMU, addressing gaps in cybersecurity while facilitating collaborative modeling and simulation. There is a balance between strong IP protection and the system's performance efficiency."}}
{"id": "2510.20514", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20514", "abs": "https://arxiv.org/abs/2510.20514", "authors": ["Lea Salome Brugger", "Xavier Denis", "Peter M\u00fcller"], "title": "Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia", "comment": null, "summary": "Deductive verification is an effective method to ensure that a given system\nexposes the intended behavior. In spite of its proven usefulness and\nfeasibility in selected projects, deductive verification is still not a\nmainstream technique. To pave the way to widespread use, we present a study\ninvestigating the factors enabling successful applications of deductive\nverification and the underlying issues preventing broader adoption. We\nconducted semi-structured interviews with 30 practitioners of verification from\nboth industry and academia and systematically analyzed the collected data\nemploying a thematic analysis approach. Beside empirically confirming familiar\nchallenges, e.g., the high level of expertise needed for conducting formal\nproofs, our data reveal several underexplored obstacles, such as proof\nmaintenance, insufficient control over automation, and usability concerns. We\nfurther use the results from our data analysis to extract enablers and barriers\nfor deductive verification and formulate concrete recommendations for\npractitioners, tool builders, and researchers, including principles for\nusability, automation, and integration with existing workflows.", "AI": {"tldr": "Deductive verification isn't widely adopted due to challenges like high expertise requirements, proof maintenance, limited automation control, and usability issues. Through interviews with practitioners, the study exposes these barriers and provides targeted recommendations to improve usability, automation, and integration, aiming to pave the way for broader adoption.", "motivation": "Deductive verification has proven its efficacy but remains infrequently used in mainstream practice. The study aims to understand why adoption is limited and what can be done to broaden its use.", "method": "The authors conducted semi-structured interviews with 30 verification practitioners from both industry and academia. They analyzed the qualitative data using thematic analysis.", "result": "The study confirmed known challenges such as the need for substantial expertise but also discovered less discussed issues like difficulties in proof maintenance, lack of control over automation, and usability problems. Based on these findings, the authors identified key enablers and barriers and provided specific recommendations to improve the adoption of deductive verification.", "conclusion": "Bringing deductive verification into mainstream use requires addressing both persistent and underexplored challenges. Usability, automation, and workflow integration must be improved through collaborative efforts among practitioners, tool builders, and researchers."}}
{"id": "2510.20521", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20521", "abs": "https://arxiv.org/abs/2510.20521", "authors": ["YingJian Xiao", "RongQun Hu", "WeiWei Gong", "HongWei Li", "AnQuan Jie"], "title": "Large Language Models for Fault Localization: An Empirical Study", "comment": "in Chinese language", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, particularly in automated program repair. However, the\neffectiveness of such repairs is highly dependent on the performance of\nupstream fault localization, for which comprehensive evaluations are currently\nlacking. This paper presents a systematic empirical study on LLMs in the\nstatement-level code fault localization task. We evaluate representative\nopen-source models (Qwen2.5-coder-32b-instruct, DeepSeek-V3) and closed-source\nmodels (GPT-4.1 mini, Gemini-2.5-flash) to assess their fault localization\ncapabilities on the HumanEval-Java and Defects4J datasets. The study\ninvestigates the impact of different prompting strategies--including standard\nprompts, few-shot examples, and chain-of-reasoning--on model performance, with\na focus on analysis across accuracy, time efficiency, and economic cost\ndimensions. Our experimental results show that incorporating bug report context\nsignificantly enhances model performance. Few-shot learning shows potential for\nimprovement but exhibits noticeable diminishing marginal returns, while\nchain-of-thought reasoning's effectiveness is highly contingent on the model's\ninherent reasoning capabilities. This study not only highlights the performance\ncharacteristics and trade-offs of different models in fault localization tasks,\nbut also offers valuable insights into the strengths of current LLMs and\nstrategies for improving fault localization effectiveness.", "AI": {"tldr": "This paper comprehensively studies several LLMs in code fault localization. It finds bug report context boosts accuracy, few-shot learning helps but less so with scale, and chain-of-thought depends on the model. Results guide effective use and improvement of LLM-based fault localization.", "motivation": "LLMs are increasingly used in automated program repair, but their effectiveness depends heavily on the upstream process of fault localization. There is a lack of comprehensive evaluations of how well LLMs perform in fault localization at the statement-level.", "method": "The authors conduct a systematic empirical study comparing open-source and closed-source LLMs (Qwen2.5-coder-32b-instruct, DeepSeek-V3, GPT-4.1 mini, Gemini-2.5-flash). The models are evaluated on HumanEval-Java and Defects4J datasets using various prompting strategies (standard, few-shot, chain-of-reasoning), with results analyzed in terms of accuracy, time efficiency, and cost.", "result": "Adding bug report context significantly improves model performance. Few-shot learning can further aid but has diminishing returns. The effectiveness of chain-of-thought reasoning depends on the model's reasoning abilities. This reveals performance differences and trade-offs among models and strategies in fault localization.", "conclusion": "LLMs show promise for fault localization, especially with bug report context. Strategic prompting can further improve results, but model and method selection are critical for best effectiveness. Insights are provided for future improvements and practical applications."}}
{"id": "2510.20679", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20679", "abs": "https://arxiv.org/abs/2510.20679", "authors": ["Jonas Klauke", "Tom Ohlmer", "Stefan Schott", "Serena Elisa Ponta", "Wolfram Fischer", "Eric Bodden"], "title": "A Soundness and Precision Benchmark for Java Debloating Tools", "comment": "Preprint - accepted at the ACM Workshop on Software Supply Chain\n  Offensive Research and Ecosystem Defenses (SCORED '25)", "summary": "Modern software development reuses code by importing libraries as\ndependencies. Software projects typically include an average of 36\ndependencies, with 80% being transitive, meaning they are dependencies of\ndependencies. Recent research indicates that only 24.9% of these dependencies\nare required at runtime, and even within those, many program constructs remain\nunused, adding unnecessary code to the project. This has led to the development\nof debloating tools that remove unnecessary dependencies and program constructs\nwhile balancing precision by eliminating unused constructs and soundness by\npreserving all required constructs. To systematically evaluate this trade-off,\nwe developed Deblometer, a micro-benchmark consisting of 59 test cases designed\nto assess support for various Java language features in debloating tools. Each\ntest case includes a manually curated ground truth specifying necessary and\nbloated classes, methods, and fields, enabling precise measurement of soundness\nand precision. Using Deblometer, we evaluated three popular Java debloating\ntools: Deptrim, JShrink, and ProGuard. Our evaluation reveals that all tools\nremove required program constructs, which results in changed semantics or\nexecution crashes. In particular, the dynamic class loading feature introduces\nunsoundness in all evaluated tools. Our comparison shows that Deptrim retains\nmore bloated constructs, while ProGuard removes more required constructs.\nJShrink's soundness is significantly affected by limited support for\nannotations, which leads to corrupted debloated artifacts. These soundness\nissues highlight the need to improve debloating tools to ensure stable and\nreliable debloated software.", "AI": {"tldr": "Most Java project dependencies are unused at runtime, yet existing debloating tools cannot reliably remove unnecessary code without breaking software. The Deblometer benchmark reveals pervasive unsoundness in popular tools, especially with features like dynamic class loading and annotations. Improved tools are needed for effective, stable debloating.", "motivation": "Modern software development heavily relies on code reuse through libraries, but most dependencies and included program constructs are not actually needed at runtime, leading to bloated software. There is an increasing need to debloat software projects by removing unnecessary dependencies without compromising functionality.", "method": "The authors built 'Deblometer', a micro-benchmark with 59 manually curated Java test cases, including ground truth for required and bloated classes, methods, and fields, to systematically measure the soundness and precision of debloating tools. They used Deblometer to evaluate three popular Java debloating tools: Deptrim, JShrink, and ProGuard.", "result": "All evaluated debloating tools failed to preserve all required program constructs, causing runtime crashes or changed program semantics. Dynamic class loading was a particular source of unsoundness. Deptrim left more bloated constructs, ProGuard removed more required constructs, and JShrink had significant soundness problems related to annotation support \u2014 resulting in corrupted artifacts.", "conclusion": "Current debloating tools are not able to guarantee both soundness and precision; they often remove constructs that are actually required, destabilizing software. There is a clear need for improved debloating tools that ensure stable and reliable software."}}
{"id": "2510.20692", "categories": ["cs.SE", "cs.AI", "cs.FL", "D.4.6; D.2.4; I.2.2; I.2.7; F.3.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2510.20692", "abs": "https://arxiv.org/abs/2510.20692", "authors": ["Adarsh Vatsa", "Bethel Hall", "William Eiers"], "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "comment": "20 pages, 7 figures", "summary": "Cloud computing is ubiquitous, with a growing number of services being hosted\non the cloud every day. Typical cloud compute systems allow administrators to\nwrite policies implementing access control rules which specify how access to\nprivate data is governed. These policies must be manually written, and due to\ntheir complexity can often be error prone. Moreover, existing policies often\nimplement complex access control specifications and thus can be difficult to\nprecisely analyze in determining their behavior works exactly as intended.\nRecently, Large Language Models (LLMs) have shown great success in automated\ncode synthesis and summarization. Given this success, they could potentially be\nused for automatically generating access control policies or aid in\nunderstanding existing policies. In this paper, we explore the effectiveness of\nLLMs for access control policy synthesis and summarization. Specifically, we\nfirst investigate diverse LLMs for access control policy synthesis, finding\nthat: although LLMs can effectively generate syntactically correct policies,\nthey have permissiveness issues, generating policies equivalent to the given\nspecification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time\nfor reasoning LLMs. We then investigate how LLMs can be used to analyze\npolicies by introducing a novel semantic-based request summarization approach\nwhich leverages LLMs to generate a precise characterization of the requests\nallowed by a policy. Our results show that while there are significant hurdles\nin leveraging LLMs for automated policy generation, LLMs show promising results\nwhen combined with symbolic approaches in analyzing existing policies.", "AI": {"tldr": "LLMs are effective at helping analyze and summarize cloud access control policies, especially with symbolic tools, but remain imperfect at generating fully accurate policies without errors.", "motivation": "Access control policies in cloud systems are critical for security but are manually written, complex, and prone to errors. Analyzing their true behavior is difficult, necessitating better automation and understanding tools.", "method": "The authors evaluate various Large Language Models (LLMs) on their capability to synthesize access control policies and introduce a novel semantic-based request summarization method using LLMs to characterize allowed requests.", "result": "LLMs can generate syntactically correct access control policies. Reasoning LLMs match given specifications 93.7% of the time, much better than non-reasoning LLMs at 45.8%. LLMs, when combined with symbolic approaches, are promising for analyzing existing policies, though policy generation still faces significant challenges.", "conclusion": "LLMs hold significant promise for analyzing and summarizing cloud access control policies, particularly when paired with symbolic methods, but their effectiveness in fully automated policy generation remains limited by permissiveness issues."}}
