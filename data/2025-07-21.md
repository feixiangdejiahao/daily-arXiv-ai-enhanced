<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 5]
- [cs.PL](#cs.PL) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence](https://arxiv.org/abs/2507.13481)
*Arthur Bueno,Bruno Cafeo,Maria Cagnin,Awdren Fontão*

Main category: cs.SE

TL;DR: The paper reviews literature to show that in open-source code samples, community-related issues frequently signal or cause technical problems. Early detection of such issues, along with better governance, is key to maintainability.


<details>
  <summary>Details</summary>
Motivation: Code samples are crucial for knowledge sharing in open-source ecosystems, yet governance over them is often informal, leading to concerns about their technical and community quality (socio-technical degradation). The study aims to explore the interplay between code smells and community smells in these samples over time.

Method: The authors applied a Multivocal Literature Review (MLR) protocol, analyzing 30 peer-reviewed and 17 practitioner-oriented sources from 2013-2024. They used thematic synthesis to identify patterns in how code and community smells co-occur and evolve within code samples in open-source ecosystems.

Result: Nine recurring socio-technical patterns were identified. The findings show that community smells often precede or reinforce the presence and persistence of technical anomalies ('code smells') in code samples. Symptoms like 'radio silence', centralized ownership, inadequate onboarding, lack of continuous refactoring, and informal collaboration were major contributors to smell accumulation.

Conclusion: Community-level dysfunctions in open-source code samples not only correlate with technical degradation but can also act as early indicators of it. Socio-technical quality indicators and lightweight governance mechanisms should be developed for instructional artifacts like code samples to maintain their value and reliability.

Abstract: Code samples play a pivotal role in open-source ecosystems (OSSECO), serving
as lightweight artifacts that support knowledge transfer, onboarding, and
framework adoption. Despite their instructional relevance, these samples are
often governed informally, with minimal review and unclear ownership, which
increases their exposure to socio-technical degradation. In this context, the
co-occurrence and longitudinal interplay of code smells (e.g., large classes,
poor modularity) and community smells (e.g., lone contributors, fragmented
communication) become particularly critical. While each type of smell has been
studied in isolation, little is known about how community-level dysfunctions
anticipate or exacerbate technical anomalies in code samples over time. This
study investigates how code and community smells emerge, co-occur, and evolve
within code samples maintained in OSSECOs. A Multivocal Literature Review
protocol was applied, encompassing 30 peer-reviewed papers and 17
practitioner-oriented sources (2013-2024). Thematic synthesis was conducted to
identify recurring socio-technical patterns related to smell dynamics. Nine
patterns were identified, showing that community smells often precede or
reinforce technical degradation in code samples. Symptoms such as "radio
silence" and centralized ownership were frequently associated with persistent
structural anomalies. Additionally, limited onboarding, the absence of
continuous refactoring, and informal collaboration emerged as recurring
conditions for smell accumulation. Conclusion: In OSSECOs, particularly within
code samples, community-level dysfunctions not only correlate with but often
signal maintainability decay. These findings underscore the need for
socio-technical quality indicators and lightweight governance mechanisms
tailored to shared instructional artifacts.

</details>


### [2] [AI-Assisted Fixes to Code Review Comments at Scale](https://arxiv.org/abs/2507.13499)
*Chandra Maddila,Negar Ghorbani,James Saindon,Parth Thakkar,Vijayaraghavan Murali,Rui Abreu,Jingyue Shen,Brian Zhou,Nachiappan Nagappan,Peter C. Rigby*

Main category: cs.SE

TL;DR: MetaMateCR, Meta's AI tool for fixing code review comments, outperforms GPT-4o in patch accuracy and actionable fixes. Safety trials revealed that exposing suggestions only to code authors avoids workflow slowdowns, demonstrating the value of careful rollout for scalable AI adoption in code review.


<details>
  <summary>Details</summary>
Motivation: Meta receives tens of thousands of code review comments weekly, making manual review and fixes time-consuming. The motivation is to automate and expedite the code review process with AI-generated fixes while maintaining review efficiency and quality.

Method: The authors developed 'MetaMate for Code Review' (MetaMateCR), using an internal dataset of 64,000 <review comment, patch> pairs to fine-tune Llama models. They benchmarked model performance against GPT-4o and deployed their models in production, running randomized controlled safety trials and full production experiments to monitor impact.

Result: The LargeLSFT Llama model produced exact match patches 68% of the time, outperforming GPT-4o by 9 percentage points, and generated more modern code. However, initial deployment slowed reviews by 5% until UX adjustments were made. In production, the AI patch suggestion system raised actionable patch application rates by 9.2 percentage points over GPT-4o.

Conclusion: AI-assisted code review using internally fine-tuned models can outperform leading general models like GPT-4o in both accuracy and adoption, but thoughtful deployment (especially via safety trials and UX tweaks) is necessary to prevent workflow slowdowns.

Abstract: Aim. There are 10s of thousands of code review comments each week at Meta. We
developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes
for reviewer comments in production at scale.
  Method. We developed an internal benchmark of 64k <review comment, patch>
data points to fine-tune Llama models. Once our models achieve reasonable
offline results, we roll them into production. To ensure that our AI-assisted
fixes do not negatively impact the time it takes to do code reviews, we conduct
randomized controlled safety trials as well as full production experiments.
  Offline Results. As a baseline, we compare GPT-4o to our small and large
Llama models. In offline results, our LargeLSFT model creates an exact match
patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The
internal models also use more modern Hack functions when compared to the PHP
functions suggested by GPT-4o.
  Safety Trial. When we roll MetaMateCR into production in a safety trial that
compares no AI patches with AI patch suggestions, we see a large regression
with reviewers taking over 5% longer to conduct reviews. After investigation,
we modify the UX to only show authors the AI patches, and see no regressions in
the time for reviews.
  Production. When we roll LargeLSFT into production, we see an
ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.
Our results illustrate the importance of safety trials in ensuring that AI does
not inadvertently slow down engineers, and a successful review comment to AI
patch product running at scale.

</details>


### [3] [Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software](https://arxiv.org/abs/2507.13553)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: Feature requests in OSS are often ambiguous or incomplete, but developers rarely clarify them directly, focusing more on aligning with project goals than on resolving unclear requests. This work highlights patterns in user-developer interactions that could improve handling of feature requests.


<details>
  <summary>Details</summary>
Motivation: In software development, user feature requests are often expressed in natural language, leading to ambiguity or incomplete information because of unclear communication or a lack of technical knowledge from the requester. This can cause misinterpretation and negatively impact software quality. The authors are motivated to better understand how developers handle the clarification of such requests, with the goal of improving software relevance and user satisfaction.

Method: The study investigates open-source software (OSS) projects to characterize how developers engage in the clarification process for ambiguous or incomplete feature requests. It examines how often ambiguities or incompleteness appear, the types of clarifications developers ask (when they do), and overall conversational dynamics in OSS issue trackers. The approach involves qualitative analysis of feature requests and developer responses to them.

Result: The findings reveal that feature requests in OSS frequently suffer from ambiguity and/or incompleteness. However, direct clarification to resolve such defects is relatively rare; developers tend to prioritize alignment with project goals over clarifying unclear requests. When clarification happens, it mostly targets user intent and feasibility, not technical details.

Conclusion: The study concludes that ambiguity and incompleteness are common in OSS feature requests, but explicit clarification is uncommon. Developers focus more on goal alignment than resolving unclear text. Understanding these patterns can help inform best practices to improve communication and collaboration between users and developers during the feature request process.

Abstract: As user demands evolve, effectively incorporating feature requests is crucial
for maintaining software relevance and user satisfaction. Feature requests,
typically expressed in natural language, often suffer from ambiguity or
incomplete information due to communication gaps or the requester's limited
technical expertise. These issues can lead to misinterpretation, faulty
implementation, and reduced software quality. While seeking clarification from
requesters is a common strategy to mitigate these risks, little is known about
how developers engage in this clarification process in practice-how they
formulate clarifying questions, seek technical or contextual details, align on
goals and use cases, or decide to close requests without attempting
clarification. This study investigates how feature requests are prone to NL
defects (i.e. ambiguous or incomplete) and the conversational dynamics of
clarification in open-source software (OSS) development, aiming to understand
how developers handle ambiguous or incomplete feature requests. Our findings
suggest that feature requests published on the OSS platforms do possess
ambiguity and incompleteness, and in some cases, both. We also find that
explicit clarification for the resolution of these defects is uncommon;
developers usually focus on aligning with project goals rather than resolving
unclear text. When clarification occurs, it emphasizes understanding user
intent/goal and feasibility, rather than technical details. By characterizing
the dynamics of clarification in open-source issue trackers, this work
identifies patterns that can improve user-developer collaboration and inform
best practices for handling feature requests effectively.

</details>


### [4] [Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software](https://arxiv.org/abs/2507.13555)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: The paper presents an LLM-based method to detect and clarify defects in natural language feature requests, proving effective compared to humans and valued by developers for improving software engineering processes in open-source environments.


<details>
  <summary>Details</summary>
Motivation: With the rapid evolution of software markets and the prevalence of apps, feature requests and enhancements—mostly written in natural language—are increasingly common. However, these texts often contain defects (ambiguity, incompleteness) that hinder software development, especially in decentralized settings like open-source projects, where traditional clarification techniques are impractical.

Method: The paper proposes an automated, novel approach using Large Language Models (LLMs) to detect and refine defects in natural language feature requests. The system identifies ambiguous or incomplete requests and generates clarification questions to improve them. The method was evaluated using real OSS feature requests, human annotation comparisons, and interviews with GitHub developers about defect handling and its impact.

Result: The approach effectively identified and refined ambiguous and incomplete feature requests. It generated helpful clarification questions, and performed comparably to human annotators on real OSS data. Interviews revealed developers' perspectives on managing NL defects and the significant effects these defects have on downstream software engineering.

Conclusion: LLMs can automate and improve the quality of natural language feature requests in OSS projects by identifying and resolving defects. This aids developers by making requests clearer and reduces the negative impact of ambiguous requirements, especially in decentralized, large-scale environments.

Abstract: The growing popularity and widespread use of software applications (apps)
across various domains have driven rapid industry growth. Along with this
growth, fast-paced market changes have led to constantly evolving software
requirements. Such requirements are often grounded in feature requests and
enhancement suggestions, typically provided by users in natural language (NL).
However, these requests often suffer from defects such as ambiguity and
incompleteness, making them challenging to interpret. Traditional validation
methods (e.g., interviews and workshops) help clarify such defects but are
impractical in decentralized environments like open-source software (OSS),
where change requests originate from diverse users on platforms like GitHub.
This paper proposes a novel approach leveraging Large Language Models (LLMs) to
detect and refine NL defects in feature requests. Our approach automates the
identification of ambiguous and incomplete requests and generates clarification
questions (CQs) to enhance their usefulness for developers. To evaluate its
effectiveness, we apply our method to real-world OSS feature requests and
compare its performance against human annotations. In addition, we conduct
interviews with GitHub developers to gain deeper insights into their
perceptions of NL defects, the strategies they use to address these defects,
and the impact of defects on downstream software engineering (SE) tasks.

</details>


### [5] [Testing Autonomous Driving Systems -- What Really Matters and What Doesn't](https://arxiv.org/abs/2507.13661)
*Changwen Li,Joseph Sifakis,Rongjie Yan,Jian Zhang*

Main category: cs.SE

TL;DR: The paper critically reviews test methods for autonomous driving systems, finding most are ineffective or invalid due to unrealistic scenarios and assumptions about autopilot behavior. It calls for new testing frameworks and urges development of autopilots that ensure rational and deterministic operation, as current practices do not provide reliable safety guarantees.


<details>
  <summary>Details</summary>
Motivation: Testing of autonomous driving systems (ADS) is fragmented, with no standard way to assess or compare testing methods. There is a lack of informative technical frameworks to evaluate the effectiveness and validity of current testing approaches for ADS. This undermines the reliability and safety assessment of autopilot systems.

Method: The paper proposes a framework for comparing test methods based on their intrinsic effectiveness (how well they detect failures) and validity (how accurately the tests represent real operational capabilities). It analyzes existing methods, identifies their limitations, and investigates how test outcomes depend on the design choices of autopilot systems (i.e., their rationality and determinacy). Empirical results are provided from tests on eight open-source autopilots.

Result: Many current test methods fall short by either failing to detect failures efficiently or by testing scenarios that are not actually representative or valid for the vehicles’ capabilities. Most autopilots tested do not uphold the principles of rationality (consistent, reasoned behavior) and determinacy (reproducibility), leading to diminished test validity and effectiveness.

Conclusion: Current testing methods for autonomous driving systems cannot guarantee essential autopilot properties. For stronger safety and performance assurances, both the design of autopilots and their test methods must be improved to ensure rationality and determinacy.

Abstract: Despite extensive research, the testing of autonomous driving systems (ADS)
landscape remains fragmented, and there is currently no basis for an informed
technical assessment of the importance and contribution of the current state of
the art. This paper attempts to address this problem by exploring two
complementary aspects.
  First, it proposes a framework for comparing existing test methods in terms
of their intrinsic effectiveness and validity. It shows that many methods do
not meet both of these requirements. Either because they are based on criteria
that do not allow for rapid, inexpensive, and comprehensive detection of
failures, or because the degree of validity of the properties tested cannot be
accurately estimated. In particular, it is shown that most critical test
methods do not take into account the nominal operational capabilities of
autopilots and generate scenarios that are impossible for the tested vehicles
to handle, resulting in unjustified rejections.
  Secondly, the paper shows that test effectiveness and validity are highly
dependent on how autopilots are designed: how they choose between different
control policies to perform maneuvers, as well as on the reproducibility of the
results. In fact, most test methods take for granted two principles underlying
traditional methods, but do not generally apply to ADS. We maintain that the
absence of rationality and determinacy significantly impairs the effectiveness
and validity of test methods, and provide test results on eight open
autopilots, in which most do not satisfy these properties, thereby illustrating
this fact.
  We conclude that under the current state of the art, it is impossible to
obtain strong enough guarantees for essential autopilot properties and
recommend that autopilots be developed with a view to both rationality and
determinacy.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Random Variate Generation with Formal Guarantees](https://arxiv.org/abs/2507.13494)
*Feras A. Saad,Wonyeol Lee*

Main category: cs.PL

TL;DR: The paper proposes a universal, efficient, and automated algorithm for generating random numbers from any finite-precision CDF, with strong accuracy and entropy guarantees. Their C library outperforms standard tools in efficiency and precision, making random variate generation easier and more reliable.


<details>
  <summary>Details</summary>
Motivation: Random variate generation is a fundamental problem in numerical computing, simulations, and probabilistic modeling. Existing methods often lack formal accuracy or entropy efficiency guarantees, require manual implementation for each distribution, or need expensive high-precision arithmetic. The authors are motivated to create a universal, formally guaranteed, and efficient solution for generating random variates from arbitrary distributions described by finite-precision CDFs.

Method: The authors propose a universal method that automatically synthesizes exact random variate generators from numerical cumulative distribution functions (CDFs) written in any binary number format (e.g., floating-point, fixed-point, posits). Their method achieves information-theoretically optimal entropy rates (matching the Knuth and Yao lower bound), operates at the same precision as the CDF, avoids overflows and arbitrary-precision arithmetic, and provides a consistent API. They implemented this method as a C library and benchmarked it against a standard library.

Result: The resulting library supports a wide range of continuous and discrete distributions, provides higher accuracy and better entropy efficiency than the GNU Scientific Library, operates at competitive runtimes, and offers a fully automated workflow.

Conclusion: The paper presents a practical yet theoretically sound framework for random variate generation from arbitrary numerical CDFs with formal guarantees on precision and entropy efficiency. The approach is universally applicable, efficient, and improves upon existing solutions in accuracy, automation, and resource usage.

Abstract: This article introduces a new approach to principled and practical random
variate generation with formal guarantees. The key idea is to first specify the
desired probability distribution in terms of a finite-precision numerical
program that defines its cumulative distribution function (CDF), and then
generate exact random variates according to this CDF. We present a universal
and fully automated method to synthesize exact random variate generators given
any numerical CDF implemented in any binary number format, such as
floating-point, fixed-point, and posits. The method is guaranteed to operate
with the same precision used to specify the CDF, does not overflow, avoids
expensive arbitrary-precision arithmetic, and exposes a consistent API. The
method rests on a novel space-time optimal implementation for the class of
generators that attain the information-theoretically optimal Knuth and Yao
entropy rate, consuming the least possible number of input random bits per
output variate. We develop a random variate generation library using our method
in C and evaluate it on a diverse set of ``continuous'' and ``discrete''
distributions, showing competitive runtime with the state-of-the-art GNU
Scientific Library while delivering higher accuracy, entropy efficiency, and
automation.

</details>


### [7] [Increasing the Expressiveness of a Gradual Verifier](https://arxiv.org/abs/2507.13533)
*Priyam Gupta*

Main category: cs.PL

TL;DR: This paper enhances Gradual C0 with unfolding expressions, enabling more intuitive and expressive specifications for recursive heap data structures, thus lowering the barriers to gradual verification.


<details>
  <summary>Details</summary>
Motivation: Static verification is reliable but too demanding due to complex specification requirements. Gradual verification aims to ease this process but is limited by the current lack of expressive specification languages, particularly for heap data structures.

Method: The authors design and implement an extension to the Gradual C0 gradual verification system to support unfolding expressions, enhancing the specification of recursive heap data structures.

Result: The extended Gradual C0 now supports unfolding expressions, making it possible to specify recursive heap data structures more intuitively.

Conclusion: The extension improves Gradual C0's expressiveness, thereby making gradual verification more practical for heap-manipulating programs by enabling better and easier specification of recursive data structures.

Abstract: Static verification provides strong correctness guarantees for code; however,
fully specifying programs for static verification is a complex, burdensome
process for users. Gradual verification was introduced to make this process
easier by supporting the verification of partially specified programs. The only
currently working gradual verifier, Gradual C0, successfully verifies heap
manipulating programs, but lacks expressiveness in its specification language.
This paper describes the design and implementation of an extension to Gradual
C0 that supports unfolding expressions, which allow more intuitive
specifications of recursive heap data structures.

</details>


### [8] [AdapTT: Functoriality for Dependent Type Casts](https://arxiv.org/abs/2507.13774)
*Arthur Adjedj,Meven Lennon-Bertrand,Thibaut Benjamin,Kenji Maillard*

Main category: cs.PL

TL;DR: AdapTT is a new type theory that formalizes the functorial structure underlying type casts in dependent type theories, enabling a precise understanding and derivation of their structural laws.


<details>
  <summary>Details</summary>
Motivation: There is a recurring need to cast values between related types in various dependent type theories, but a systematic and precise understanding of the structural properties underlying these casts is lacking.

Method: The authors design and conduct an extensive study of AdapTT, a new type theory, based on the idea of functorial type formers related by abstract adapters, and utilize descriptions for functorial inductive types to derive general structural laws.

Result: The study results in a robust framework (AdapTT) that formalizes and enables derivation of structural laws for type casts in general inductive type formers, clarifying the functorial properties involved.

Conclusion: The AdapTT type theory systematizes the common structural behavior of type casts by employing functorial type formers and abstract adapters, providing a general and precise framework for reasoning about type casting in dependent type theories.

Abstract: The ability to cast values between related types is a leitmotiv of many
flavors of dependent type theory, such as observational type theories,
subtyping, or cast calculi for gradual typing. These casts all exhibit a common
structural behavior that boils down to the pervasive functoriality of type
formers. We propose and extensively study a type theory, called AdapTT, which
makes systematic and precise this idea of functorial type formers, with respect
to an abstract notion of adapters relating types. Leveraging descriptions for
functorial inductive types in AdapTT, we derive structural laws for type casts
on general inductive type formers.

</details>


### [9] [Don't exhaust, don't waste](https://arxiv.org/abs/2507.13792)
*Riccardo Bianchini,Francesco Dagnino,Paola Giannini,Elena Zucca*

Main category: cs.PL

TL;DR: This paper proposes a resource-aware extension to the lambda calculus, using a parametric algebra and coinductive reasoning to ensure that well-typed programs do not waste or exhaust resources, all without modifying fundamental language elements.


<details>
  <summary>Details</summary>
Motivation: Traditional lambda calculus type systems do not account for resource usage, leading to the possibility of resource exhaustion or waste. The paper is motivated by the need for a calculus that guarantees resource-aware computations, preventing resource misuse in well-typed programs.

Method: The authors extend the semantics and type system of a lambda calculus by integrating resource awareness using a parametric grade algebra, and formalize the semantics in a big-step style. The type system and semantics are designed to avoid both exhaustion and wastage of resources, with soundness proved via coinductive reasoning techniques.

Result: The extended type system and semantics guarantee that well-typed lambda calculus programs have computations where resources are neither exhausted nor wasted. This is achieved in a manner parametric with respect to possible ways resources can be used, without making ad-hoc changes to the language structure.

Conclusion: The paper provides a general and robust resource-aware extension to lambda calculus type systems and semantics, ensuring sound, efficient resource usage for well-typed programs through a parametric approach and advanced proof techniques.

Abstract: We extend the semantics and type system of a lambda calculus equipped with
common constructs to be resource-aware. That is, the semantics keep tracks of
the usage of resources, and is stuck, besides in case of type errors, if either
a needed resource is exhausted, or a provided resource would be wasted. In such
way, the type system guarantees, besides standard soundness, that for
well-typed programs there is a computation where no resource gets either
exhausted or wasted.
  The no-waste extension is parametric on an arbitrary grade algebra, modeling
an arbitrary assortment of possible usages, and does not require ad-hoc changes
to the underlying language. To this end, the semantics needs to be formalized
in big-step style; as a consequence, expressing and proving (resource-aware)
soundness is challenging, and is achieved by applying recent techniques based
on coinductive reasoning.

</details>
