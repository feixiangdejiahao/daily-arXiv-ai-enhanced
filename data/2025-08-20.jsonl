{"id": "2508.13396", "categories": ["cs.SE", "68P20 (Primary), 68M14 (Secondary)"], "pdf": "https://arxiv.org/pdf/2508.13396", "abs": "https://arxiv.org/abs/2508.13396", "authors": ["Dinesh Eswararaj", "Ajay Babu Nellipudi", "Vandana Kollati"], "title": "A Comparative Study of Delta Parquet, Iceberg, and Hudi for Automotive Data Engineering Use Cases", "comment": "Published in SSRG International Journal of Computer Science and\n  Engineering (IJCSE), July 2025. This is the authors accepted manuscript. The\n  final published version is available", "summary": "The automotive industry generates vast amounts of data from sensors,\ntelemetry, diagnostics, and real-time operations. Efficient data engineering is\ncritical to handle challenges of latency, scalability, and consistency. Modern\ndata lakehouse formats Delta Parquet, Apache Iceberg, and Apache Hudi offer\nfeatures such as ACID transactions, schema enforcement, and real-time\ningestion, combining the strengths of data lakes and warehouses to support\ncomplex use cases. This study presents a comparative analysis of Delta Parquet,\nIceberg, and Hudi using real-world time-series automotive telemetry data with\nfields such as vehicle ID, timestamp, location, and event metrics. The\nevaluation considers modeling strategies, partitioning, CDC support, query\nperformance, scalability, data consistency, and ecosystem maturity. Key\nfindings show Delta Parquet provides strong ML readiness and governance,\nIceberg delivers high performance for batch analytics and cloud-native\nworkloads, while Hudi is optimized for real-time ingestion and incremental\nprocessing. Each format exhibits tradeoffs in query efficiency, time-travel,\nand update semantics. The study offers insights for selecting or combining\nformats to support fleet management, predictive maintenance, and route\noptimization. Using structured datasets and realistic queries, the results\nprovide practical guidance for scaling data pipelines and integrating machine\nlearning models in automotive applications."}
{"id": "2508.13666", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13666", "abs": "https://arxiv.org/abs/2508.13666", "authors": ["Dangfeng Pan", "Zhensu Sun", "Cenyuan Zhang", "David Lo", "Xiaoning Du"], "title": "The Hidden Cost of Readability: How Code Formatting Silently Consumes Your LLM Budget", "comment": "Accepted by ICSE'26 (First Cycle)", "summary": "Source code is usually formatted with elements like indentation and newlines\nto improve readability for human developers. However, these visual aids do not\nseem to be beneficial for large language models (LLMs) in the same way since\nthe code is processed as a linear sequence of tokens. Furthermore, these\nadditional tokens can lead to increased computational costs and longer response\ntimes for LLMs. If such formatting elements are non-essential to LLMs, we can\nreduce such costs by removing them from the code. To figure out the role played\nby formatting elements, we conduct a comprehensive empirical study to evaluate\nthe impact of code formatting on LLM performance and efficiency. Through\nlarge-scale experiments on Fill-in-the-Middle Code Completion tasks across four\nprogramming languages (Java, Python, C++, C\\#) and ten LLMs-including both\ncommercial and open-source models-we systematically analyze token count and\nperformance when formatting elements are removed. Key findings indicate that\nLLMs can maintain performance across formatted code and unformatted code,\nachieving an average input token reduction of 24.5\\% with negligible output\ntoken reductions. This makes code format removal a practical optimization\nstrategy for improving LLM efficiency. Further exploration reveals that both\nprompting and fine-tuning LLMs can lead to significant reductions (up to\n36.1\\%) in output code length without compromising correctness. To facilitate\npractical applications, we develop a bidirectional code transformation tool for\nformat processing, which can be seamlessly integrated into existing LLM\ninference workflows, ensuring both human readability and LLM efficiency."}
{"id": "2508.13757", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13757", "abs": "https://arxiv.org/abs/2508.13757", "authors": ["James Meaden", "Michał Jarosz", "Piotr Jodłowski", "Grigori Melnik"], "title": "COMPASS: A Multi-Dimensional Benchmark for Evaluating Code Generation in Large Language Models", "comment": null, "summary": "Current code generation benchmarks focus primarily on functional correctness\nwhile overlooking two critical aspects of real-world programming: algorithmic\nefficiency and code quality. We introduce COMPASS (COdility's Multi-dimensional\nProgramming ASSessment), a comprehensive evaluation framework that assesses\ncode generation across three dimensions: correctness, efficiency, and quality.\nCOMPASS consists of 50 competitive programming problems from real Codility\ncompetitions, providing authentic human baselines from 393,150 submissions.\nUnlike existing benchmarks that treat algorithmically inefficient solutions\nidentically to optimal ones provided they pass test cases, COMPASS\nsystematically evaluates runtime efficiency and code quality using\nindustry-standard analysis tools. Our evaluation of three leading\nreasoning-enhanced models, Anthropic Claude Opus 4, Google Gemini 2.5 Pro, and\nOpenAI O4-Mini-High, reveals that models achieving high correctness scores do\nnot necessarily produce efficient algorithms or maintainable code. These\nfindings highlight the importance of evaluating more than just correctness to\ntruly understand the real-world capabilities of code generation models. COMPASS\nserves as a guiding framework, charting a path for future research toward AI\nsystems that are robust, reliable, and ready for production use."}
{"id": "2508.13774", "categories": ["cs.SE", "cs.AI", "J.5; I.2"], "pdf": "https://arxiv.org/pdf/2508.13774", "abs": "https://arxiv.org/abs/2508.13774", "authors": ["Peer Trilcke", "Ingo Börner", "Henny Sluyter-Gäthje", "Daniil Skorinkin", "Frank Fischer", "Carsten Milling"], "title": "Agentic DraCor and the Art of Docstring Engineering: Evaluating MCP-empowered LLM Usage of the DraCor API", "comment": "Preprint, submitted to the 2nd Workshop on Computational Drama\n  Analysis at DraCor Summit 2025, September 03, 2025, Berlin, Germany", "summary": "This paper reports on the implementation and evaluation of a Model Context\nProtocol (MCP) server for DraCor, enabling Large Language Models (LLM) to\nautonomously interact with the DraCor API. We conducted experiments focusing on\ntool selection and application by the LLM, employing a qualitative approach\nthat includes systematic observation of prompts to understand how LLMs behave\nwhen using MCP tools, evaluating \"Tool Correctness\", \"Tool-Calling Efficiency\",\nand \"Tool-Use Reliability\". Our findings highlight the importance of \"Docstring\nEngineering\", defined as reflexively crafting tool documentation to optimize\nLLM-tool interaction. Our experiments demonstrate both the promise of agentic\nAI for research in Computational Literary Studies and the essential\ninfrastructure development needs for reliable Digital Humanities\ninfrastructures."}
{"id": "2508.13610", "categories": ["cs.PL", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13610", "abs": "https://arxiv.org/abs/2508.13610", "authors": ["Basile Pesin", "Celia Picard", "Cyril Allignol"], "title": "Reactive Semantics for User Interface Description Languages", "comment": "In Proceedings ICE 2025, arXiv:2508.12308", "summary": "User Interface Description Languages (UIDLs) are high-level languages that\nfacilitate the development of Human-Machine Interfaces, such as Graphical User\nInterface (GUI) applications. They usually provide first-class primitives to\nspecify how the program reacts to an external event (user input, network\nmessage), and how data flows through the program. Although these\ndomain-specific languages are now widely used to implement safety-critical\nGUIs, little work has been invested in their formalization and verification.\n  In this paper, we propose a denotational semantic model for a core reactive\nUIDL, Smalite, which we argue is expressive enough to encode constructs from\nmore realistic languages. This preliminary work may be used as a stepping stone\nto produce a formally verified compiler for UIDLs."}
{"id": "2508.13819", "categories": ["cs.SE", "K.6.3; E.0"], "pdf": "https://arxiv.org/pdf/2508.13819", "abs": "https://arxiv.org/abs/2508.13819", "authors": ["Daniel Ogenrwot", "John Businge", "Shaikh Arifuzzaman"], "title": "Structural and Connectivity Patterns in the Maven Central Software Dependency Network", "comment": "17 pages, 6 figures, 34th International Conference on Software\n  Engineering and Data Engineering", "summary": "Understanding the structural characteristics and connectivity patterns of\nlarge-scale software ecosystems is critical for enhancing software reuse,\nimproving ecosystem resilience, and mitigating security risks. In this paper,\nwe investigate the Maven Central ecosystem, one of the largest repositories of\nJava libraries, by applying network science techniques to its dependency graph.\nLeveraging the Goblin framework, we extracted a sample consisting of the top\n5,000 highly connected artifacts based on their degree centrality and then\nperformed breadth-first search (BFS) expansion from each selected artifact as a\nseed node, traversing the graph outward to capture all libraries and releases\nreachable those seed nodes. This sampling strategy captured the immediate\nstructural context surrounding these libraries resulted in a curated graph\ncomprising of 1.3 million nodes and 20.9 million edges. We conducted a\ncomprehensive analysis of this graph, computing degree distributions,\nbetweenness centrality, PageRank centrality, and connected components\ngraph-theoretic metrics. Our results reveal that Maven Central exhibits a\nhighly interconnected, scale-free, and small-world topology, characterized by a\nsmall number of infrastructural hubs that support the majority of projects.\nFurther analysis using PageRank and betweenness centrality shows that these\nhubs predominantly consist of core ecosystem infrastructure, including testing\nframeworks and general-purpose utility libraries. While these hubs facilitate\nefficient software reuse and integration, they also pose systemic risks;\nfailures or vulnerabilities affecting these critical nodes can have widespread\nand cascading impacts throughout the ecosystem."}
{"id": "2508.13611", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2508.13611", "abs": "https://arxiv.org/abs/2508.13611", "authors": ["Clemens Grabmayer", "Maurizio Murgia"], "title": "Bisimilarity and Simulatability of Processes Parameterized by Join Interactions", "comment": "In Proceedings ICE 2025, arXiv:2508.12308", "summary": "Departing from Larsen's concept of parameterized bisimilarity of processes\nwith respect to interaction with environments, we start an exploration of its\nnatural weakening: bisimilarity of unrestricted join interactions with\nenvironments. Parameterized bisimilarity relates processes p and q with respect\nto an environment e if p and q behave bi-similarly while joining --\nrespectively the same -- transitions from e. The weakened variant relates\nprocesses p and q with respect to environment e if the join-interaction\nprocesses p & e and q & e of p and q with e are bisimilar. (Hereby join\ninteractions r & f facilitate a step with label a to r' & f' if and only if r\nand f permit a-steps to r' and f' , respectively.) Join-interaction\nparameterized (ji-parameterized) bisimilarity coincides with parameterized\nbisimilarity for deterministic environments, but that it is a coarser\nequivalence in general. We explain how Larsen's concept can be recovered from\nji-parameterized bisimilarity by 'determinizing' interactions. We show that by\nadaptation to simulatability (simulation preorder) the same concept arises:\nparameterized simulatability coincides with ji-parameterized simulatability.\nFor the discrimination preorder of (ji-)parameterized simulatability on\nenvironments we obtain the same result as Larsen did for parameterized\nbisimilarity. Also, we give a modal-logic characterization of\n(ji-)parameterized simulatability. Finally we gather open problems, and provide\nan outlook on our current related work."}
{"id": "2508.13863", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13863", "abs": "https://arxiv.org/abs/2508.13863", "authors": ["Shuai Zhao", "Jieyu Jiang", "Shenlin Cai", "Yaowei Liang", "Chen Jie", "Yinjie Fang", "Wei Zhang", "Guoquan Zhang", "Yaoyao Gu", "Xiang Xiao", "Wei Qin", "Xiangzhen Ouyang", "Wanli Chang"], "title": "Tight Inter-Core Cache Contention Analysis for WCET Estimation on Multicore Systems", "comment": null, "summary": "WCET (Worst-Case Execution Time) estimation on multicore architecture is\nparticularly challenging mainly due to the complex accesses over cache shared\nby multiple cores. Existing analysis identifies possible contentions between\nparallel tasks by leveraging the partial order of the tasks or their program\nregions. Unfortunately, they overestimate the number of cache misses caused by\na remote block access without considering the actual cache state and the number\nof accesses. This paper reports a new analysis for inter-core cache contention.\nBased on the order of program regions in a task, we first identify memory\nreferences that could be affected if a remote access occurs in a region.\nAfterwards, a fine-grained contention analysis is constructed that computes the\nnumber of cache misses based on the access quantity of local and remote blocks.\nWe demonstrate that the overall inter-core cache interference of a task can be\nobtained via dynamic programming. Experiments show that compared to existing\nmethods, the proposed analysis reduces inter-core cache interference and WCET\nestimations by 52.31% and 8.94% on average, without significantly increasing\ncomputation overhead."}
{"id": "2508.13610", "categories": ["cs.PL", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13610", "abs": "https://arxiv.org/abs/2508.13610", "authors": ["Basile Pesin", "Celia Picard", "Cyril Allignol"], "title": "Reactive Semantics for User Interface Description Languages", "comment": "In Proceedings ICE 2025, arXiv:2508.12308", "summary": "User Interface Description Languages (UIDLs) are high-level languages that\nfacilitate the development of Human-Machine Interfaces, such as Graphical User\nInterface (GUI) applications. They usually provide first-class primitives to\nspecify how the program reacts to an external event (user input, network\nmessage), and how data flows through the program. Although these\ndomain-specific languages are now widely used to implement safety-critical\nGUIs, little work has been invested in their formalization and verification.\n  In this paper, we propose a denotational semantic model for a core reactive\nUIDL, Smalite, which we argue is expressive enough to encode constructs from\nmore realistic languages. This preliminary work may be used as a stepping stone\nto produce a formally verified compiler for UIDLs."}
