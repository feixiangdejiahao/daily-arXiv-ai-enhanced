<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 10]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection](https://arxiv.org/abs/2512.02197)
*Moussa Moussaoui,Tarik Houichime,Abdelalim Sadiq*

Main category: cs.SE

TL;DR: Bin2Vec is a modular framework that combines structural and behavioral program features to provide clear, explainable, and reliable software similarity analysis, suitable for security and auditing tasks.


<details>
  <summary>Details</summary>
Motivation: Existing approaches to software comparison often focus narrowly on either static features or dynamic behaviors, making their similarity assessments limited and sometimes difficult to explain. There's a need for a framework that gives a comprehensive and interpretable analysis for tasks like auditing, verification, and cybersecurity.

Method: Bin2Vec collects multiple information 'views' of a program, including both static (built-ins, imports/exports) and dynamic (instructions, memory usage) features. These views are analyzed individually with visual charts and combined into an overall similarity score, which can be used directly or processed by machine learning models. The method was evaluated on real-world software to demonstrate its practical utility and explainability.

Result: Bin2Vec effectively generates feature representations that are suitable for machine learning models, providing a clear and explainable similarity assessment of software binaries. Testing on well-known programs (PuTTY and 7-Zip) showed that Bin2Vec could distinguish their behavioral and structural patterns, leading to reliable and understandable comparisons.

Conclusion: Bin2Vec bridges the gap between low-level binary analysis and machine learning by offering an optimal, scalable, and interpretable representation of software for program comparison. Its modular design makes it adaptable to various use cases in cybersecurity, software auditing, and reverse engineering.

Abstract: We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.

</details>


### [2] [Towards autonomous normative multi-agent systems for Human-AI software engineering teams](https://arxiv.org/abs/2512.02329)
*Hoa Khanh Dam,Geeta Mahala,Rashina Hoda,Xi Zheng,Cristina Conati*

Main category: cs.SE

TL;DR: The paper proposes AI-driven autonomous agents, equipped with reasoning and regulatory frameworks, to collaborate with humans in software engineering, promising faster and more reliable development than current methods.


<details>
  <summary>Details</summary>
Motivation: The paper aims to revolutionize software engineering by proposing a paradigm where Artificial Intelligence, in the form of autonomous agents, leads the main software development tasks. The motivation stems from the desire to achieve greater speed, reliability, and adaptability in software engineering.

Method: The authors introduce a new class of software engineering agents that utilize Large Language Models. These agents are designed with human-like reasoning abilities—incorporating beliefs, desires, intentions, and memory. Their collaboration, both with humans and other agents, is managed through interactions regulated by deontic modalities (commitments, obligations, prohibitions, permissions) for compliance and coordination.

Result: The agents can collaboratively design, implement, test, and deploy software systems, outperforming current practices in terms of reliability and adaptability. The framework they operate within is scalable, transparent, and builds trust among human and AI participants.

Conclusion: The paper concludes that these innovations enable the establishment of trustworthy and efficient Human-AI software engineering teams, offering regulatory compliance and transforming the field into a more adaptive and collaborative discipline.

Abstract: This paper envisions a transformative paradigm in software engineering, where Artificial Intelligence, embodied in fully autonomous agents, becomes the primary driver of the core software development activities. We introduce a new class of software engineering agents, empowered by Large Language Models and equipped with beliefs, desires, intentions, and memory to enable human-like reasoning. These agents collaborate with humans and other agents to design, implement, test, and deploy software systems with a level of speed, reliability, and adaptability far beyond the current software development processes. Their coordination and collaboration are governed by norms expressed as deontic modalities - commitments, obligations, prohibitions and permissions - that regulate interactions and ensure regulatory compliance. These innovations establish a scalable, transparent and trustworthy framework for future Human-AI software engineering teams.

</details>


### [3] [Process-Centric Analysis of Agentic Software Systems](https://arxiv.org/abs/2512.02393)
*Shuyang Liu,Yang Chen,Rahul Krishna,Saurabh Sinha,Jatin Ganhotra,Reyhan Jabbarvand*

Main category: cs.SE

TL;DR: The study introduces Graphectory, a graph-based framework to analyze and evaluate the behaviors and processes of agentic systems powered by LLMs, showing that richer prompts or advanced models lead to more complex strategies, and identifying inefficiencies and behavioral differences depending on the system and problem.


<details>
  <summary>Details</summary>
Motivation: Existing evaluations of agentic systems overlook the detailed reasoning and strategies of agents, focusing only on final outcomes. To understand and improve agentic systems, it is necessary to develop systematic analysis tools that reveal how agents think, plan, and act during workflow execution.

Method: Graphectory encodes agentic system activities as graphs to capture both temporal and semantic relationships between tasks. The authors applied this framework to analyze 4000 problem-solving trajectories from two agentic programming agents (SWE-agent and OpenHands), each combined with four different large language models, and performed fully automated comparisons of strategies and processes across tasks of varying difficulty.

Result: The paper presents Graphectory, a framework for analyzing the process and strategies of agentic software systems—systems powered by agents and large language models (LLMs). By encoding temporal and semantic relations in agentic workflows, Graphectory enables detailed, process-centric evaluations. The authors studied 4000 trajectories from two agentic programming systems (SWE-agent and OpenHands), each utilizing different LLMs, in the context of software issue resolution tasks.

Conclusion: The authors conclude that process-centric analysis via Graphectory reveals much richer information than outcome-only assessment: advanced LLMs and better prompts correlate with complex and effective workflows, yet even successful resolutions often involve procedural inefficiency. The framework identifies both effective and inefficient agent strategies, suggesting new process-based metrics for evaluating and improving agentic systems.

Abstract: Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.
  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.

</details>


### [4] [Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System](https://arxiv.org/abs/2512.02567)
*Martin Weiss,Jesko Hecking-Harbusch,Jochen Quante,Matthias Woehrle*

Main category: cs.SE

TL;DR: This study evaluates automated C-to-Rust code translation using LLMs, comparing the effects of feedback loops, model choice, and code perturbations. While LLM choice is critical without feedback loops, feedback mechanisms equalize success rates and robustness, and introducing code diversity can further boost performance.


<details>
  <summary>Details</summary>
Motivation: Current generative AI tools for software engineering lack reliability for industrial application, especially in automated settings. Improved code translation between C and Rust is highly relevant due to Rust’s safety features. The study aims to analyze how feedback loops, LLM selection, and behavior-preserving code changes affect translation quality.

Method: The paper utilizes a generate-and-check automated system for C-to-Rust code translation, leveraging large language models (LLMs) and incorporating automated feedback loops. Generated Rust code is validated for compilability and behavior preservation compared to the original C code, with negative results triggering iterative re-prompting of the LLM.

Result: Results indicate that the choice of LLM initially strongly affects translation success. However, with feedback loops, the performance gap between models narrows. The system maintains robust performance even when the input code is perturbed, with code diversity from these perturbations occasionally enhancing results.

Conclusion: Incorporating automated feedback loops substantially improves the reliability and robustness of AI-driven code translation, reducing dependency on specific LLMs and benefiting from behavior-preserving code modifications. This approach holds promise for safe and effective software engineering automation in industrial contexts.

Abstract: The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.
  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.
  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.

</details>


### [5] [Empirical Assessment of the Perception of Software Product Line Engineering by an SME before Migrating its Code Base](https://arxiv.org/abs/2512.02707)
*Thomas Georges,Marianne Huchard,Mélanie König,Clémentine Nebut,Chouki Tibermacine*

Main category: cs.SE

TL;DR: Interview-based study at an SME migrating to SPL shows stakeholders identify migration benefits; successful risk mitigation relies on engagement, communication, and preserving established practices.


<details>
  <summary>Details</summary>
Motivation: Migrating to a software product line is complex and disruptive, especially for SMEs. Understanding developers' perceptions, risks, and ways to facilitate a smooth transition is crucial for successful SPL adoption.

Method: The study used interviews with key stakeholders from an SME undertaking SPL migration, followed by qualitative analysis of their responses to assess perceptions, anticipated benefits, risks, and resistance.

Result: All stakeholders recognized migration benefits relevant to their roles. Effective risk mitigation was found to involve stakeholder engagement, transparent communication, and retention of good practices, contributing to minimized challenges during migration.

Conclusion: Engaging stakeholders, preserving existing good practices, and maintaining communication are key for a successful migration of software variants into a software product line, minimizing resistance and challenges.

Abstract: Migrating a set of software variants into a software product line (SPL) is an expensive and potentially challenging endeavor. Indeed, SPL engineering can significantly impact a company's development process and often requires changes to established developer practices. The work presented in this paper stems from a collaboration with a Small and Medium-sized Enterprise (SME) that decided to migrate its existing code base into an SPL. In this study, we conducted an in-depth evaluation of the company's current development processes and practices, as well as the anticipated benefits and risks associated with the migration. Key stakeholders involved in software development participated in this evaluation to provide insight into their perceptions of the migration and their potential resistance to change. This paper describes the design of the interviews conducted with these stakeholders and presents an analysis of the results. Among the qualitative findings, we observed that all participants, regardless of their role in the development process, identified benefits of the migration relevant to their own activities. Furthermore, our results suggest that an effective risk mitigation strategy involves keeping stakeholders informed and engaged throughout the process, preserving as many good practices as possible, and actively involving them in the migration to ensure a smooth transition and minimize potential challenges.

</details>


### [6] [Integrative Analysis of Risk Management Methodologies in Data Science Projects](https://arxiv.org/abs/2512.02728)
*Sabrina Delmondes da Costa Feitosa*

Main category: cs.SE

TL;DR: Traditional risk management methods for data science projects miss important emerging risks, especially ethical and sociotechnical aspects. Hybrid frameworks are recommended for better outcomes, and more research is needed to close current gaps.


<details>
  <summary>Details</summary>
Motivation: Data science projects often fail due to technical and organizational issues, including poor risk management and ethical oversight. The motivation is to improve the success rate of these projects by analyzing and synthesizing existing risk management methodologies, identifying their strengths and gaps.

Method: The paper conducts an integrative literature review using indexed databases and applies a structured protocol for selection and content analysis, focusing on established risk management standards (ISO 31000, PMBOK Risk Management, NIST RMF) and specific data science frameworks (CRISP DM, DS EthiCo RMF).

Result: The review reveals that traditional risk management approaches address technical risks but offer limited coverage of current and emerging risks, such as those involving ethical and sociotechnical considerations. Contemporary frameworks, like DS EthiCo RMF, provide more multidimensional structures, integrating ethical oversight and ongoing governance.

Conclusion: The study concludes that existing frameworks have significant gaps, particularly in managing ethical and sociotechnical risks. It suggests that hybrid frameworks, which combine technical rigor, organizational alignment, and responsible data practices, are needed. The research also identifies areas where further study is required to guide future improvements.

Abstract: Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.

</details>


### [7] ["Can you feel the vibes?": An exploration of novice programmer engagement with vibe coding](https://arxiv.org/abs/2512.02750)
*Kiev Gama,Filipe Calegario,Victoria Jackson,Alexander Nolte,Luiz Augusto Morais,Vinicius Garcia*

Main category: cs.SE

TL;DR: A hackathon with diverse undergraduates tested 'vibe coding'—making software through prompts instead of direct coding. Teams collaborated fast, learned prompt skills, and produced working demos, but faced uneven code quality and narrow ideation. Human judgment and combining AI tools were key. Hackathons like this can boost confidence and learning, if they include guidance for creative thinking and realistic goals.


<details>
  <summary>Details</summary>
Motivation: The rise of generative AI and natural language-based programming raises questions about its educational impact and potential to democratize software development. However, its specific implications for novice learners and mixed-experience teams are poorly understood.

Method: A one-day hackathon at a Brazilian public university was organized with 31 participants from diverse academic backgrounds. Teams were observed, surveyed, and interviewed to gather data on their creative processes, tool usage, collaboration, and learning outcomes while using vibe coding.

Result: Vibe coding enabled rapid prototyping and interdisciplinary collaboration. Participants developed prompt engineering skills and delivered functional demos. However, ideation quickly converged and code quality was uneven, necessitating rework. Teams effectively combined multiple AI tools but human judgment remained crucial. The hackathon format boosted newcomers’ confidence and accommodated limited participant availability.

Conclusion: Vibe coding hackathons can be valuable low-stakes learning environments, particularly when paired with explicit support for divergent thinking and critical evaluation of AI outputs. They effectively build confidence and skill in participants, though realistic expectations about production quality must be maintained.

Abstract: Emerging alongside generative AI and the broader trend of AI-assisted coding, the term "vibe coding" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.

</details>


### [8] [Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior](https://arxiv.org/abs/2512.02795)
*Marcus Kessel*

Main category: cs.SE

TL;DR: This paper introduces the 'observation lakehouse', a scalable infrastructure for storing and analyzing dynamic behavior data from code executions, enabling more reliable evaluation and training of code-generating large language models (LLMs).


<details>
  <summary>Details</summary>
Motivation: Existing code-generating LLMs lack training and evaluation data that accurately reflects run-time behavior, leading to the internalization of buggy code. There's a need for a scalable, analyzable way to capture and compare true dynamic behaviors of software systems.

Method: The authors designed the observation lakehouse using a tall, append-only table built on Apache Parquet, Iceberg, and DuckDB. It ingests observation data from pipelines and enables efficient SQL queries for analysis. This infrastructure supports n-version assessment, clustering, and consensus analysis without re-execution.

Result: On a benchmark of 509 problems, the system ingested about 8.6 million observation rows (<51MiB) and enabled fast (<100ms) reconstruction and clustering tasks on a laptop, proving the feasibility of efficient behavioral data analysis without large infrastructure.

Conclusion: The observation lakehouse makes continual behavior mining and large-scale analysis practical on commodity hardware, offering a new path for behavior-aware evaluation and training in LLMs. All tools and data are open-source for the community.

Abstract: Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse

</details>


### [9] [Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits](https://arxiv.org/abs/2512.02898)
*Pedro Orvalho,Marta Kwiatkowska,Mikoláš Janota,Vasco Manquinho*

Main category: cs.SE

TL;DR: CFaults is an efficient fault localisation tool for C software and Boolean circuits using a unified MaxSAT approach to guarantee minimal and consistent diagnoses, performing competitively against leading FBFL methods.


<details>
  <summary>Details</summary>
Motivation: Existing FBFL approaches fail to guarantee a complete and minimal set of diagnoses across all failing tests, especially with multiple faults, often producing redundant results.

Method: CFaults leverages Model-Based Diagnosis (MBD) with multiple observations by aggregating all failing test cases into a unified MaxSAT formula. This guarantees consistency and simplifies fault localisation.

Result: CFaults is faster at localising faults in C software compared to BugAssist, SNIPER, and HSD. On Boolean circuits (ISCAS85), CFaults is slightly slower than HSD but remains competitive, localising faults in only 6% fewer circuits. It provides subset-minimal diagnoses, avoiding redundancy.

Conclusion: CFaults improves the fault localisation process by ensuring subset-minimal, consistent diagnoses across multiple faults and failing tests. It outperforms or matches other FBFL tools on real benchmarks, making it a strong solution for debugging tasks.

Abstract: Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.
  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).

</details>


### [10] [The Evolutionary Ecology of Software: Constraints, Innovation, and the AI Disruption](https://arxiv.org/abs/2512.02953)
*Sergi Valverde,Blai Vidiella,Salva Duran-Nebreda*

Main category: cs.SE

TL;DR: This chapter explores how software and innovation co-evolve, using modeling and case studies to reveal dynamics between novelty, imitation, and societal change. It warns that AI tools like large language models could impact software diversity and culture, stressing the need to understand these new pressures.


<details>
  <summary>Details</summary>
Motivation: The paper seeks to understand how software evolves alongside technological innovation, societal norms, and cultural dynamics, especially under new influences like AI development tools. The aim is to reveal the pressures and patterns driving software’s co-evolution with human practices.

Method: The chapter employs agent-based modeling and case studies, utilizing complex network analysis and evolutionary theory to investigate software’s evolution and the socio-technological systems governing it.

Result: The paper finds that software evolution is shaped by constraints, tinkering, frequency-dependent selection, and the interplay between novelty and imitation. The adoption of AI-driven tools such as LLMs introduces new pressures that could impact diversity and lead to cultural stagnation, echoing past declines in software ecosystem variability.

Conclusion: A nuanced ecological perspective on software evolution highlights the symbiotic relationship between technological innovation and cultural adaptation. Monitoring the impact of AI tools is crucial for anticipating changes in software diversity, societal practices, and future innovation.

Abstract: This chapter investigates the evolutionary ecology of software, focusing on the symbiotic relationship between software and innovation. An interplay between constraints, tinkering, and frequency-dependent selection drives the complex evolutionary trajectories of these socio-technological systems. Our approach integrates agent-based modeling and case studies, drawing on complex network analysis and evolutionary theory to explore how software evolves under the competing forces of novelty generation and imitation. By examining the evolution of programming languages and their impact on developer practices, we illustrate how technological artifacts co-evolve with and shape societal norms, cultural dynamics, and human interactions. This ecological perspective also informs our analysis of the emerging role of AI-driven development tools in software evolution. While large language models (LLMs) provide unprecedented access to information, their widespread adoption introduces new evolutionary pressures that may contribute to cultural stagnation, much like the decline of diversity in past software ecosystems. Understanding the evolutionary pressures introduced by AI-mediated software production is critical for anticipating broader patterns of cultural change, technological adaptation, and the future of software innovation.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [11] [Pushing Tensor Accelerators Beyond MatMul in a User-Schedulable Language](https://arxiv.org/abs/2512.02371)
*Yihong Zhang,Derek Gerstmann,Andrew Adams,Maaz Bin Safeer Ahmad*

Main category: cs.PL

TL;DR: Tensor accelerators are used mainly for ML and scientific computing via vendor libraries, but their potential is limited by programming difficulty. This paper introduces a compiler-based system using Halide and equality saturation to broaden tensor accelerator usage, achieving significant speedups in image processing pipelines.


<details>
  <summary>Details</summary>
Motivation: The motivation is to unlock the broader computational potential of tensor accelerators, which are underutilized due to programming challenges and restricted vendor library interfaces.

Method: The authors use Halide language and implement an equality saturation-based tensor instruction selector compatible with both CPU and GPU tensor accelerators. They express image processing algorithms in Halide and evaluate performance on real hardware.

Result: Image processing tasks like filtering, resampling, and denoising re-implemented using this system achieve substantial speedups, e.g., a 6.1× speedup in downsampling on an Nvidia RTX 4070 GPU.

Conclusion: The proposed system demonstrates that tensor accelerators can be effectively leveraged for diverse applications outside traditional domains, yielding substantial performance improvements.

Abstract: Tensor accelerators now represent a growing share of compute resources in modern CPUs and GPUs. However, they are hard to program, leading developers to use vendor-provided kernel libraries that support tensor accelerators. As a result, the usage of tensor accelerators is limited to the provided interface, mainly designed for traditional ML and scientific computing workloads.
  In this paper, we show that tensor accelerators can improve the performance of applications beyond simple variants of MatMul. For example, many image processing pipelines are linear transformations over matrices in disguise and can therefore utilize such specialized hardware. This is nonetheless hindered by the difficulties in programming tensor accelerators. We tackle this problem with compiler-based techniques. We use the Halide user-schedulable language and express operations as Halide algorithms succinctly. To this end, we implement a flexible tensor instruction selector based on equality saturation. The tensor instruction selector supports both CPU- and GPU-attached tensor accelerators and works with existing scheduling operations (e.g., producer-consumer fusion). Together, this enables developers to write diverse accelerator-leveraging applications in a few dozen lines.
  Using our system, we demonstrate the potential of tensor accelerators beyond their traditional domains. We implement several image processing pipelines (e.g., filtering, resampling, and denoising) in our system and evaluate them against non-accelerator-leveraging baselines. We show that these pipelines can achieve significant speedups. For example, a downsampling routine is sped up by $6.1\times$ by utilizing Tensor Cores on an Nvidia RTX 4070 GPU.

</details>


### [12] [Probabilistic energy profiler for statically typed JVM-based programming languages](https://arxiv.org/abs/2512.02738)
*Joel Nyholm,Wojciech Mostowski,Christoph Reichenbach*

Main category: cs.PL

TL;DR: The paper presents a Bayesian statistical methodology to accurately model and predict the energy consumption of source code statements in JVM-based languages like Java, considering multiple code and hardware factors and offering predictions that closely match real measurements.


<details>
  <summary>Details</summary>
Motivation: Existing energy estimation approaches focus on CPU usage with point estimates and largely ignore other hardware factors and finer granularity, such as source code statements. This limits both the accuracy of energy measurement and the potential for statistical reasoning and explainability.

Method: The paper introduces a methodology to measure the energy consumption of Bytecode patterns, mapping source code statements (in statically typed JVM languages) to bytecode and using empirical energy data to construct a Bayesian statistical model. This model predicts energy usage based on factors such as data size, data type, operation, and executing device.

Result: Experimental validation for Java shows all four factors significantly influence energy usage—including hardware differences even within the same model. The Bayesian model predicts program energy consumption closely matching real measurements, supporting the validity of the approach.

Conclusion: The methodology enables detailed, statistically sound energy modeling at the source code level for JVM-based languages. This can benefit energy-aware development and future verification tools for energy estimates.

Abstract: Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.

</details>


### [13] [Lumos: Let there be Language Model System Certification](https://arxiv.org/abs/2512.02966)
*Isha Chaudhary,Vedaant Jain,Avaljot Singh,Kavya Sachdeva,Sayan Ranu,Gagandeep Singh*

Main category: cs.PL

TL;DR: Lumos is a new programming language and framework for specifying and certifying language model behaviors, revealing safety risks in popular vision-language models and offering extensibility for future LMS certification needs.


<details>
  <summary>Details</summary>
Motivation: Existing Language Model Systems (LMS) lack formal frameworks for specifying and certifying their behaviors, particularly for complex or safety-critical applications such as vision-language models (VLMs) in autonomous driving. The rapid evolution of LMS technology requires adaptable solutions that can systematically identify risks and ensure correct behavior under varied scenarios.

Method: Lumos is an imperative probabilistic programming domain-specific language (DSL) defined over graphs. It generates i.i.d. prompts for LMS, supports structured prompt distribution specification, and provides hybrid semantics (operational and denotational) for formal interpretation. The framework integrates with statistical certifiers to validate LMS responses and is demonstrated through safety specifications applied to VLMs in autonomous driving scenarios.

Result: The proposed framework, Lumos, successfully encodes a wide range of LMS specifications, including complex relational, temporal, and new safety specifications for VLMs. The framework demonstrated that the state-of-the-art model Qwen-VL exhibits critical safety failures with at least 90% probability in specific scenarios, highlighting the necessity of formal certification.

Conclusion: Lumos establishes a systematic, flexible, and formally rigorous approach to specifying and certifying LMS behaviors. Its modular and extensible design enables quick adaptation to emerging safety concerns, suggesting it may become central to future LMS reliability and certification efforts.

Abstract: We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs. Lumos supports certifying LMS for arbitrary prompt distributions via integration with statistical certifiers. We provide hybrid (operational and denotational) semantics for Lumos, providing a rigorous way to interpret the specifications. Using only a small set of composable constructs, Lumos can encode existing LMS specifications, including complex relational and temporal specifications. It also facilitates specifying new properties - we present the first safety specifications for vision-language models (VLMs) in autonomous driving scenarios developed with Lumos. Using these, we show that the state-of-the-art VLM Qwen-VL exhibits critical safety failures, producing incorrect and unsafe responses with at least 90% probability in right-turn scenarios under rainy driving conditions, revealing substantial safety risks. Lumos's modular structure allows easy modification of the specifications, enabling LMS certification to stay abreast with the rapidly evolving threat landscape. We further demonstrate that specification programs written in Lumos enable finding specific failure cases exhibited by state-of-the-art LMS. Lumos is the first systematic and extensible language-based framework for specifying and certifying LMS behaviors, paving the way for a wider adoption of LMS certification.

</details>
