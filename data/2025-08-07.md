<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 12]
- [cs.PL](#cs.PL) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Empathy Guidelines for Improving Practitioner Well-being & Software Engineering Practices](https://arxiv.org/abs/2508.03846)
*Hashini Gunatilake,John Grundy,Rashina Hoda,Ingo Mueller*

Main category: cs.SE

TL;DR: This paper provides 17 practical empathy guidelines for software engineering, explores their real-world use, discusses implementation challenges, and offers a prioritization framework to help teams integrate sustainable empathetic practices.


<details>
  <summary>Details</summary>
Motivation: Empathy is often overlooked in software engineering (SE), despite its significant benefits for teamwork, communication, and decision-making. The authors aim to address this gap by providing practical guidance for integrating empathy in SE workplaces.

Method: The authors introduce 17 actionable empathy guidelines and examine their implementation in real-world SE practice. They analyze challenges, applications, and solutions shared by practitioners, and present a visual prioritization framework to assist with adoption of the guidelines.

Result: The paper presents a set of 17 empathy guidelines, examples of their practical application, common challenges, and a framework to help practitioners prioritize and adopt these measures based on importance, ease, and willingness.

Conclusion: Integrating empathy through practical guidelines and a prioritization tool can help SE teams translate empathy principles into sustained, everyday practices for improved teamwork and communication.

Abstract: Empathy is a powerful yet often overlooked element in software engineering
(SE), supporting better teamwork, smoother communication, and effective
decision-making. In our previous study, we identified a range of practitioner
strategies for fostering empathy in SE contexts. Building on these insights,
this paper introduces 17 actionable empathy guidelines designed to support
practitioners, teams, and organisations. We also explore how these guidelines
can be implemented in practice by examining real-world applications,
challenges, and strategies to overcome them shared by software practitioners.
To support adoption, we present a visual prioritisation framework that
categorises the guidelines based on perceived importance, ease of
implementation, and willingness to adopt. The findings offer practical and
flexible suggestions for integrating empathy into everyday SE work, helping
teams move from principles to sustainable action.

</details>


### [2] [Evaluating Software Supply Chain Security in Research Software](https://arxiv.org/abs/2508.03856)
*Richard Hegewald,Rebecca Beyer*

Main category: cs.SE

TL;DR: Research software is generally insecure, with common vulnerabilities due to poor implementation of important security practices. The study identifies these issues and provides straightforward recommendations for improvement.


<details>
  <summary>Details</summary>
Motivation: Research software is crucial for scientific integrity and reproducibility, but its security remains under-explored, especially given its reliance on open source components and distributed development, which make it vulnerable to supply chain attacks.

Method: The authors analyzed 3,248 high-quality, mostly peer-reviewed research software repositories using the OpenSSF Scorecard tool to assess their security practices.

Result: The analysis revealed that research software generally has weak security, with an average OpenSSF Scorecard score of 3.5 out of 10. Key security practices like signed releases and branch protection are rarely used.

Conclusion: Research software currently has insufficient security measures, exposing it to potential threats. The study offers practical, low-effort recommendations to help research teams strengthen their software security and thereby protect scientific integrity.

Abstract: The security of research software is essential for ensuring the integrity and
reproducibility of scientific results. However, research software security is
still largely unexplored. Due to its dependence on open source components and
distributed development practices, research software is particularly vulnerable
to supply chain attacks. This study analyses 3,248 high-quality, largely
peer-reviewed research software repositories using the OpenSSF Scorecard. We
find a generally weak security posture with an average score of 3.5/10.
Important practices, such as signed releases and branch protection, are rarely
implemented. Finally, we present actionable, low-effort recommendations that
can help research teams improve software security and mitigate potential
threats to scientific integrity.

</details>


### [3] [From App Features to Explanation Needs: Analyzing Correlations and Predictive Potential](https://arxiv.org/abs/2508.03881)
*Martin Obaidi,Kushtrim Qengaj,Jakob Droste,Hannah Deters,Marc Herrmann,Jil Klünder,Elisa Schmid,Kurt Schneider*

Main category: cs.SE

TL;DR: App properties and metadata can't reliably predict when users will need explanations; direct user feedback is still essential for designing explainable software.


<details>
  <summary>Details</summary>
Motivation: The motivation is to help developers understand users' needs for explanations when interacting with software, and to identify whether these needs can be predicted early using app metadata, thus aiding requirement mining and system design.

Method: The authors analyzed a gold standard set of 4,495 app reviews with enriched metadata. They used correlation analyses to examine relationships between app properties and explanation needs, followed by linear regression models to test predictive power, and validated their findings on a separate, manually labeled dataset of 495 reviews.

Result: There were mostly weak associations between app properties and explanation needs, with only moderate correlations for features like app version, review count, and ratings. Predictive models had very limited reliability. Some categories (e.g., Security & Privacy, System Behavior) had slightly better predictability, but others (Interaction, UI) remained difficult to predict. Overall, metadata alone was insufficient for accurately inferring explanation needs.

Conclusion: User explanation needs are highly context-dependent and cannot be predicted precisely using app metadata alone. Supplemental user feedback is necessary for creating explainable and user-centered systems.

Abstract: In today's digitized world, software systems must support users in
understanding both how to interact with a system and why certain behaviors
occur. This study investigates whether explanation needs, classified from user
reviews, can be predicted based on app properties, enabling early consideration
during development and large-scale requirements mining. We analyzed a gold
standard dataset of 4,495 app reviews enriched with metadata (e.g., app
version, ratings, age restriction, in-app purchases). Correlation analyses
identified mostly weak associations between app properties and explanation
needs, with moderate correlations only for specific features such as app
version, number of reviews, and star ratings. Linear regression models showed
limited predictive power, with no reliable forecasts across configurations.
Validation on a manually labeled dataset of 495 reviews confirmed these
findings. Categories such as Security & Privacy and System Behavior showed
slightly higher predictive potential, while Interaction and User Interface
remained most difficult to predict. Overall, our results highlight that
explanation needs are highly context-dependent and cannot be precisely inferred
from app metadata alone. Developers and requirements engineers should therefore
supplement metadata analysis with direct user feedback to effectively design
explainable and user-centered software systems.

</details>


### [4] [A Human Centric Requirements Engineering Framework for Assessing Github Copilot Output](https://arxiv.org/abs/2508.03922)
*Soroush Heydari*

Main category: cs.SE

TL;DR: Traditional benchmarks miss how AI assistants fit with real users. This paper evaluates GitHub Copilot's ability to adapt to different user types and support collaboration, introducing a new framework for measuring these human aspects. Results point toward better ways to assess AI helpers' impact on actual developer workflows.


<details>
  <summary>Details</summary>
Motivation: Although AI programming assistants like GitHub Copilot are widely adopted, current evaluation frameworks mainly focus on technical metrics (e.g., code correctness), neglecting important human factors critical for effective integration into software development workflows.

Method: The study involved analyzing Copilot's chat-based interactions with users, specifically measuring its adaptability to varying user expertise and its efficacy in supporting collaborative programming. The author developed a human-centered requirements framework with defined metrics for evaluating these human factors.

Result: The research assessed how well Copilot adapts its explanations and code generation according to user expertise and how effective it is in collaborative programming via its chat interface. The study provides empirical data and analysis on these aspects using the newly proposed requirements framework.

Conclusion: The study highlights the importance of human-centered evaluation for AI programming assistants. It presents a framework and initial findings for assessing GitHub Copilot's human factor performance, offering a foundation for future studies in this area.

Abstract: The rapid adoption of Artificial Intelligence(AI) programming assistants such
as GitHub Copilot introduces new challenges in how these software tools address
human needs. Many existing evaluation frameworks address technical aspects such
as code correctness and efficiency, but often overlook crucial human factors
that affect the successful integration of AI assistants in software development
workflows. In this study, I analyzed GitHub Copilot's interaction with users
through its chat interface, measured Copilot's ability to adapt explanations
and code generation to user expertise levels, and assessed its effectiveness in
facilitating collaborative programming experiences. I established a
human-centered requirements framework with clear metrics to evaluate these
qualities in GitHub Copilot chat. I discussed the test results and their
implications for future analysis of human requirements in automated
programming.

</details>


### [5] [Analyzing Prominent LLMs: An Empirical Study of Performance and Complexity in Solving LeetCode Problems](https://arxiv.org/abs/2508.03931)
*Everton Guimaraes,Nathalia Nascimento,Chandan Shivalingaiah,Asish Nelapati*

Main category: cs.SE

TL;DR: This paper benchmarks ChatGPT, Copilot, Gemini, and DeepSeek on 150 LeetCode coding problems in Java and Python, revealing that ChatGPT is consistently efficient, Copilot and DeepSeek handle complexity with variability, and Gemini struggles as tasks get harder. The findings help developers make informed choices about which LLM to use for different coding scenarios.


<details>
  <summary>Details</summary>
Motivation: With Large Language Models (LLMs) like ChatGPT, Copilot, Gemini, and DeepSeek becoming important tools in software engineering tasks (code generation, testing, debugging), there is a need to systematically compare their performance to help optimize their use in real-world scenarios.

Method: The study benchmarks ChatGPT, Copilot, Gemini, and DeepSeek by having them solve 150 LeetCode problems of varying difficulty (easy, medium, hard) in Java and Python. The comparison focuses on execution time, memory usage, and algorithmic complexity of generated solutions.

Result: ChatGPT shows consistent efficiency in both execution time and memory usage across different problem difficulties. Copilot and DeepSeek demonstrate greater performance variability, especially as problems get harder. Gemini performs well on easy tasks but requires more attempts as the difficulty increases.

Conclusion: There are significant differences in how major LLMs perform on coding tasks. Developers should consider these strengths and weaknesses when choosing an LLM for specific tasks. The study offers actionable recommendations based on empirical benchmarking.

Abstract: Large Language Models (LLMs) like ChatGPT, Copilot, Gemini, and DeepSeek are
transforming software engineering by automating key tasks, including code
generation, testing, and debugging. As these models become integral to
development workflows, a systematic comparison of their performance is
essential for optimizing their use in real world applications. This study
benchmarks these four prominent LLMs on one hundred and fifty LeetCode problems
across easy, medium, and hard difficulties, generating solutions in Java and
Python. We evaluate each model based on execution time, memory usage, and
algorithmic complexity, revealing significant performance differences. ChatGPT
demonstrates consistent efficiency in execution time and memory usage, while
Copilot and DeepSeek show variability as task complexity increases. Gemini,
although effective on simpler tasks, requires more attempts as problem
difficulty rises. Our findings provide actionable insights into each model's
strengths and limitations, offering guidance for developers selecting LLMs for
specific coding tasks and providing insights on the performance and complexity
of GPT-like generated solutions.

</details>


### [6] [Model Compression vs. Adversarial Robustness: An Empirical Study on Language Models for Code](https://arxiv.org/abs/2508.03949)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: Compressing language models for code saves resources but makes them more vulnerable to adversarial attacks, highlighting a need for strategies that balance efficiency and security.


<details>
  <summary>Details</summary>
Motivation: Transformer-based language models for code are effective for software analytics tasks, but their high computational costs and environmental impact hinder widespread adoption. Model compression techniques aim to address these issues, but their effects on adversarial robustness are not well understood.

Method: The authors conducted a comprehensive evaluation of common model compression strategies (pruning, quantization, knowledge distillation) on three popular code language models. They tested these on three software analytics tasks, using six evaluation metrics and four different classical adversarial attacks to assess robustness.

Result: Compressed models maintained comparable performance to uncompressed models under normal conditions. However, their robustness was significantly reduced when exposed to adversarial attacks.

Conclusion: There is a clear trade-off between model size reduction and adversarial robustness. This trade-off must be carefully considered when deploying compressed language models for code, especially in security-critical applications. More research is needed to develop compression methods that ensure both efficiency and robustness.

Abstract: Transformer-based language models for code have shown remarkable performance
in various software analytics tasks, but their adoption is hindered by high
computational costs, slow inference speeds, and substantial environmental
impact. Model compression techniques such as pruning, quantization, and
knowledge distillation have gained traction in addressing these challenges.
However, the impact of these strategies on the robustness of compressed
language models for code in adversarial scenarios remains poorly understood.
Understanding how these compressed models behave under adversarial attacks is
essential for their safe and effective deployment in real-world applications.
To bridge this knowledge gap, we conduct a comprehensive evaluation of how
common compression strategies affect the adversarial robustness of compressed
models. We assess the robustness of compressed versions of three widely used
language models for code across three software analytics tasks, using six
evaluation metrics and four commonly used classical adversarial attacks. Our
findings indicate that compressed models generally maintain comparable
performance to their uncompressed counterparts. However, when subjected to
adversarial attacks, compressed models exhibit significantly reduced
robustness. These results reveal a trade-off between model size reduction and
adversarial robustness, underscoring the need for careful consideration when
deploying compressed models in security-critical software applications. Our
study highlights the need for further research into compression strategies that
strike a balance between computational efficiency and adversarial robustness,
which is essential for deploying reliable language models for code in
real-world software applications.

</details>


### [7] [Experimental Analysis of Productive Interaction Strategy with ChatGPT: User Study on Function and Project-level Code Generation Tasks](https://arxiv.org/abs/2508.04125)
*Sangwon Hyun,Hyunjun Kim,Jinhyuk Jang,Hyojin Choi,M. Ali Babar*

Main category: cs.SE

TL;DR: This paper explores how different human-LLM interaction features affect productivity in complex code generation tasks, moving beyond simple function-level evaluations. Through user studies and comprehensive analysis, it identifies key features impacting productivity, proposes guidelines, and catalogs typical errors and solutions.


<details>
  <summary>Details</summary>
Motivation: While Large Language Models (LLMs) are increasingly used for software engineering tasks, most current studies focus on simple prompts and function-level tasks, neglecting more complex scenarios such as multi-class dependencies that are closer to real-world software development. There is a need to understand the human-LLM interaction (HLI) features that impact productivity during code generation at a higher level of complexity.

Method: The authors designed an experiment involving two project-level software engineering benchmark tasks requiring participants to interact with GPT using specific prompting patterns. A user study with 36 diverse participants was conducted, during which behavioral features and interactions were captured via screen recordings and chat logs. Both statistical and empirical analyses were performed to evaluate which HLI features affected code generation productivity.

Result: (1) Three out of 15 analyzed HLI features were found to significantly impact productivity in code generation; (2) five key guidelines were identified to improve productivity in HLI processes; (3) a taxonomy of 29 runtime and logic errors was developed, along with proposed mitigation plans for these errors.

Conclusion: The study demonstrates the importance of identifying and optimizing key HLI features to improve productivity in real-world software engineering tasks using LLMs. The provided guidelines and error taxonomy offer actionable insights for enhancing human-LLM collaboration in code generation beyond function-level tasks.

Abstract: The application of Large Language Models (LLMs) is growing in the productive
completion of Software Engineering tasks. Yet, studies investigating the
productive prompting techniques often employed a limited problem space,
primarily focusing on well-known prompting patterns and mainly targeting
function-level SE practices. We identify significant gaps in real-world
workflows that involve complexities beyond class-level (e.g., multi-class
dependencies) and different features that can impact Human-LLM Interactions
(HLIs) processes in code generation. To address these issues, we designed an
experiment that comprehensively analyzed the HLI features regarding the code
generation productivity. Our study presents two project-level benchmark tasks,
extending beyond function-level evaluations. We conducted a user study with 36
participants from diverse backgrounds, asking them to solve the assigned tasks
by interacting with the GPT assistant using specific prompting patterns. We
also examined the participants' experience and their behavioral features during
interactions by analyzing screen recordings and GPT chat logs. Our statistical
and empirical investigation revealed (1) that three out of 15 HLI features
significantly impacted the productivity in code generation; (2) five primary
guidelines for enhancing productivity for HLI processes; and (3) a taxonomy of
29 runtime and logic errors that can occur during HLI processes, along with
suggested mitigation plans.

</details>


### [8] [EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation](https://arxiv.org/abs/2508.04295)
*Chaofan Wang,Tingrui Yu,Jie Wang,Dong Chen,Wenrui Zhang,Yuling Shi,Xiaodong Gu,Beijun Shen*

Main category: cs.SE

TL;DR: EvoC2Rust is an automated framework for converting large C projects to safe, idiomatic Rust, using a multi-step process that outperforms existing methods in both safety and accuracy, making large-scale translation feasible.


<details>
  <summary>Details</summary>
Motivation: The motivation is the high demand for translating legacy C codebases to Rust, driven by Rust's compile-time safety guarantees, especially for safety-critical systems. Existing translation approaches either produce non-idiomatic, unsafe code or fail to generate semantically equivalent Rust for large codebases due to heavy dependencies and are limited to small-scale programs.

Method: The paper proposes EvoC2Rust, an automated framework using a skeleton-guided translation strategy. The process involves three evolutionary stages: (1) Decompose C projects into functional modules and use an LLM enhanced with feature-mapping to generate a compilable Rust skeleton; (2) Incrementally translate function bodies by replacing stubs; (3) Repair compilation errors by integrating LLM and static analysis.

Result: EvoC2Rust outperforms prior approaches on both open-source and industrial projects. It achieves on average 17.24% and 14.32% improvements in syntax and semantic accuracy over prior LLM-based tools, and 96.79% higher code safety compared to rule-based tools. For module-level evaluation, it achieves 92.25% compilation and 89.53% test pass rates, even for large, complex industrial projects.

Conclusion: EvoC2Rust provides a scalable, automated solution for project-level C-to-Rust translation, combining the strengths of rule-based and LLM-based approaches, significantly improving code safety and translation accuracy for complex and large-scale codebases.

Abstract: Rust's compile-time safety guarantees make it ideal for safety-critical
systems, creating demand for translating legacy C codebases to Rust. While
various approaches have emerged for this task, they face inherent trade-offs:
rule-based solutions face challenges in meeting code safety and idiomaticity
requirements, while LLM-based solutions often fail to generate semantically
equivalent Rust code, due to the heavy dependencies of modules across the
entire codebase. Recent studies have revealed that both solutions are limited
to small-scale programs. In this paper, we propose EvoC2Rust, an automated
framework for converting entire C projects to equivalent Rust ones. EvoC2Rust
employs a skeleton-guided translation strategy for project-level translation.
The pipeline consists of three evolutionary stages: 1) it first decomposes the
C project into functional modules, employs a feature-mapping-enhanced LLM to
transform definitions and macros and generates type-checked function stubs,
which form a compilable Rust skeleton; 2) it then incrementally translates the
function, replacing the corresponding stub placeholder; 3) finally, it repairs
compilation errors by integrating LLM and static analysis. Through evolutionary
augmentation, EvoC2Rust combines the advantages of both rule-based and
LLM-based solutions. Our evaluation on open-source benchmarks and six
industrial projects demonstrates EvoC2Rust's superior performance in
project-level C-to-Rust translation. On average, it achieves 17.24% and 14.32%
improvements in syntax and semantic accuracy over the LLM-based approaches,
along with a 96.79% higher code safety rate than the rule-based tools. At the
module level, EvoC2Rust reaches 92.25% compilation and 89.53% test pass rates
on industrial projects, even for complex codebases and long functions.

</details>


### [9] [Vanilla-Converter: A Tool for Converting Camunda 7 BPMN Models into Camunda 8 Models](https://arxiv.org/abs/2508.04352)
*Dragana Sunaric,Charlotte Verbruggen,Dominik Bork*

Main category: cs.SE

TL;DR: Vanilla-Converter is a tool that automates migration of BPMN models from Camunda 7 to 8, easing the process and proving effective in practical industrial cases.


<details>
  <summary>Details</summary>
Motivation: Organizations must migrate their BPMN models because Camunda 7 is reaching end-of-life, but manual migration is difficult due to significant platform differences.

Method: The authors developed Vanilla-Converter, a command-line tool that automates the transformation of BPMN models from Camunda 7 to Camunda 8. It supports various BPMN elements, provides a transformed model, and generates a detailed log of the automated and remaining manual conversion tasks.

Result: The tool was evaluated on three real-world Camunda 7 models in industrial settings, successfully converting them into valid and executable Camunda 8 models.

Conclusion: Vanilla-Converter effectively reduces manual migration effort by automating most of the BPMN model transformation process from Camunda 7 to Camunda 8, as demonstrated in multiple case studies.

Abstract: As organizations prepare for the end-of-life of Camunda 7, manual migration
remains complex due to fundamental differences between the two platforms. We
present Vanilla-Converter, a command-line tool that facilitates the migration
of BPMN models from Camunda 7 to Camunda 8. Vanilla-Converter automates the
transformation process, supports a wide range of BPMN elements, and produces a
transformed model and a detailed transformation log indicating automatic
changes and remaining manual conversion tasks. The tool's effectiveness is
demonstrated through three case studies with real industrially used Camunda 7
models, confirming its ability to convert these models into valid and
executable Camunda 8 models.

</details>


### [10] [Breaking New Ground in Software Defect Prediction: Introducing Practical and Actionable Metrics with Superior Predictive Power for Enhanced Decision-Making](https://arxiv.org/abs/2508.04408)
*Carlos Andrés Ramírez Cataño,Makoto Itoh*

Main category: cs.SE

TL;DR: By shifting from just code metrics to developer behavior-based metrics, this research offers a new, more effective, and more actionable way to predict and address software defects at the method level.


<details>
  <summary>Details</summary>
Motivation: Traditional software defect prediction heavily relies on code metrics, but often overlooks non-software, human-related factors. Since many defects are caused by human error, incorporating developer coding habits could improve prediction and provide more actionable insights.

Method: The paper introduces a novel framework to identify human error-related metrics for software defect prediction at the method level. It compares the predictive power of these new metrics against traditional code and commit history metrics across 21 large-scale open-source projects. The importance of each metric type is also analyzed.

Result: The proposed human error-based metrics lead to models that outperform state-of-the-art predictors using only code and commit history metrics. The importance of these new metrics is generally higher, and they also significantly enhance the explainability, practicality, and actionability of defect prediction models.

Conclusion: Incorporating developer coding habits—viewed through a human error framework—significantly improves defect prediction performance, insightfulness, and practical utility. This represents a meaningful advance in the field and provides practitioners with more actionable predictions.

Abstract: Software defect prediction using code metrics has been extensively researched
over the past five decades. However, prediction harnessing non-software metrics
is under-researched. Considering that the root cause of software defects is
often attributed to human error, human factors theory might offer key
forecasting metrics for actionable insights. This paper explores automated
software defect prediction at the method level based on the developers' coding
habits. First, we propose a framework for deciding the metrics to conduct
predictions. Next, we compare the performance of our metrics to that of the
code and commit history metrics shown by research to achieve the highest
performance to date. Finally, we analyze the prediction importance of each
metric. As a result of our analyses of twenty-one critical infrastructure
large-scale open-source software projects, we have presented: (1) a human
error-based framework with metrics useful for defect prediction at method
level; (2) models using our proposed metrics achieve better average prediction
performance than the state-of-the-art code metrics and history measures; (3)
the prediction importance of all metrics distributes differently with each of
the novel metrics having better average importance than code and history
metrics; (4) the novel metrics dramatically enhance the explainability,
practicality, and actionability of software defect prediction models,
significantly advancing the field. We present a systematic approach to
forecasting defect-prone software methods via a human error framework. This
work empowers practitioners to act on predictions, empirically demonstrating
how developer coding habits contribute to defects in software systems.

</details>


### [11] [Large Language Models Versus Static Code Analysis Tools: A Systematic Benchmark for Vulnerability Detection](https://arxiv.org/abs/2508.04448)
*Damian Gnieciak,Tomasz Szandala*

Main category: cs.SE

TL;DR: This paper shows that large language models outperform traditional static code-analysis tools in finding vulnerabilities in real-world software, mostly thanks to better recall and code context reasoning. However, LLMs generate more false positives and struggle with precise error localization, making them less suitable alone for high-assurance needs. The authors recommend combining both approaches in development pipelines and provide tools supporting reproducible future research.


<details>
  <summary>Details</summary>
Motivation: Modern software development depends on automated testing and quality assurance tools to prevent vulnerabilities. However, the effectiveness of traditional rule-based static code-analysis tools versus newer large language model (LLM)-based approaches for vulnerability detection has not been comprehensively compared, especially on real-world projects.

Method: The study conducts both quantitative and qualitative evaluation of six automated code analysis approaches: three rule-based static code-analysis tools (SonarQube, CodeQL, Snyk Code) and three large language models (GPT-4.1, Mistral Large, DeepSeek V3) from GitHub's platform. Ten real-world C# projects with 63 known vulnerabilities are used as benchmarks. Detection accuracy (precision, recall, F1-score), analysis latency, and developer verification effort are measured.

Result: LLMs achieved higher F1-scores (0.797, 0.753, 0.750) than traditional static analyzers (0.260, 0.386, 0.546), mainly due to their higher recall, indicating stronger ability to reason across code context. However, LLMs also produced more false positives, struggled with precise localization of vulnerabilities due to tokenization, and required more developer effort to vet results.

Conclusion: Modern LLMs can rival or outperform rule-based tools in finding real vulnerabilities, but their higher rate of false positives and imprecise localization currently limit their standalone use in safety-critical environments. A hybrid pipeline—using LLMs for broad triage early and rule-based tools for final verification—is recommended. The paper also contributes an open benchmark and result harness for future research.

Abstract: Modern software relies on a multitude of automated testing and quality
assurance tools to prevent errors, bugs and potential vulnerabilities. This
study sets out to provide a head-to-head, quantitative and qualitative
evaluation of six automated approaches: three industry-standard rule-based
static code-analysis tools (SonarQube, CodeQL and Snyk Code) and three
state-of-the-art large language models hosted on the GitHub Models platform
(GPT-4.1, Mistral Large and DeepSeek V3). Using a curated suite of ten
real-world C# projects that embed 63 vulnerabilities across common categories
such as SQL injection, hard-coded secrets and outdated dependencies, we measure
classical detection accuracy (precision, recall, F-score), analysis latency,
and the developer effort required to vet true positives. The language-based
scanners achieve higher mean F-1 scores,0.797, 0.753 and 0.750, than their
static counterparts, which score 0.260, 0.386 and 0.546, respectively. LLMs'
advantage originates from superior recall, confirming an ability to reason
across broader code contexts. However, this benefit comes with substantial
trade-offs: DeepSeek V3 exhibits the highest false-positive ratio, all language
models mislocate issues at line-or-column granularity due to tokenisation
artefacts. Overall, language models successfully rival traditional static
analysers in finding real vulnerabilities. Still, their noisier output and
imprecise localisation limit their standalone use in safety-critical audits. We
therefore recommend a hybrid pipeline: employ language models early in
development for broad, context-aware triage, while reserving deterministic
rule-based scanners for high-assurance verification. The open benchmark and
JSON-based result harness released with this paper lay a foundation for
reproducible, practitioner-centric research into next-generation automated code
security.

</details>


### [12] [Manifestations of Empathy in Software Engineering: How, Why, and When It Matters](https://arxiv.org/abs/2508.04479)
*Hashini Gunatilake,John Grundy,Rashina Hoda,Ingo Mueller*

Main category: cs.SE

TL;DR: This paper explores how empathy is shown and motivated in software engineering, using interviews and a survey, and provides insights and practical tips for integrating empathy into SE work.


<details>
  <summary>Details</summary>
Motivation: Empathy is recognized as important in software engineering, affecting collaboration, communication, and decision-making, but there is limited detailed understanding of how empathy is expressed in SE practice and what motivates its demonstration.

Method: The researchers conducted 22 interviews and a large-scale survey with 116 software practitioners to investigate how empathy is manifested, what motivates it, and what factors influence it in SE.

Result: The study identified specific ways empathy is expressed in SE, the motivations behind empathetic practices, SE activities where empathy is found to be useful or not, and additional factors that influence empathy. Practical suggestions are provided for SE practitioners and researchers.

Conclusion: The study deepens understanding of empathy in software engineering by revealing its expression, motivations, and influencing factors, while offering actionable insights for better integrating empathy into SE processes.

Abstract: Empathy plays a crucial role in software engineering (SE), influencing
collaboration, communication, and decision-making. While prior research has
highlighted the importance of empathy in SE, there is limited understanding of
how empathy manifests in SE practice, what motivates SE practitioners to
demonstrate empathy, and the factors that influence empathy in SE work. Our
study explores these aspects through 22 interviews and a large scale survey
with 116 software practitioners. Our findings provide insights into the
expression of empathy in SE, the drivers behind empathetic practices, SE
activities where empathy is perceived as useful or not, and the other factors
that influence empathy. In addition, we offer practical implications for SE
practitioners and researchers, offering a deeper understanding of how to
effectively integrate empathy into SE processes.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [13] [If-T: A Benchmark for Type Narrowing](https://arxiv.org/abs/2508.03830)
*Hanwen Guo,Ben Greenman*

Main category: cs.PL

TL;DR: This paper presents If-T, a language-independent benchmark for evaluating how type systems narrow types in gradually-typed languages. By applying If-T to major typecheckers, it reveals key strengths and weaknesses, helping designers balance precision, usability, and performance. If-T provides a standard, fair way to assess and guide future type system development.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper stems from the challenge of designing static type systems that can effectively validate dynamically-typed programs, particularly by handling how such programs rely on runtime tests and not rigid datatype-driven patterns. There is a key need for type narrowing mechanisms that can account for these practical realities, but existing approaches mostly rely on intuition and lack consensus or clear benchmarks to evaluate their tradeoffs.

Method: The paper introduces If-T, a language-agnostic design benchmark comprised of fundamental, small programs that stress-test type narrowing systems. The benchmark defines core technical dimensions, and for each, it presents programs that should and shouldn't typecheck. If-T allows deviations from its expectations if well-justified, ensuring practical flexibility. The benchmark is informed by literature review, language documentation, and practical experiments and is implemented across five popular typecheckers.

Result: Implementing If-T on TypeScript, Flow, Typed Racket, mypy, and Pyright revealed significant differences among these systems, notably in their abilities to track logical implications and handle user-defined narrowing predicates. The results highlight where increased typechecker complexity leads to tangible benefits (or not), thereby revealing the tradeoffs of different design approaches.

Conclusion: If-T establishes a practical, cross-language means for systematically evaluating type narrowing systems. It enables both researchers and language designers to better gauge the value of increased typechecker complexity and to make more informed, justified decisions regarding design tradeoffs in gradual typing systems. This helps clarify and standardize the evaluation process for future type system innovations.

Abstract: **Context:** The design of static type systems that can validate
dynamically-typed programs (**gradually**) is an ongoing challenge. A key
difficulty is that dynamic code rarely follows datatype-driven design. Programs
instead use runtime tests to narrow down the proper usage of incoming data.
Type systems for dynamic languages thus need a **type narrowing** mechanism
that refines the type environment along individual control paths based on
dominating tests, a form of flow-sensitive typing. In order to express
refinements, the type system must have some notion of sets and subsets. Since
set-theoretic types are computationally and ergonomically complex, the need for
type narrowing raises design questions about how to balance precision and
performance. **Inquiry:** To date, the design of type narrowing systems has
been driven by intuition, past experience, and examples from users in various
language communities. There is no standard that captures desirable and
undesirable behaviors. Prior formalizations of narrowing are also significantly
more complex than a standard type system, and it is unclear how the extra
complexity pays off in terms of concrete examples. This paper addresses the
problems through If-T, a language-agnostic **design benchmark** for type
narrowing that characterizes the abilities of implementations using simple
programs that draw attention to fundamental questions. Unlike a traditional
performance-focused benchmark, If-T measures a narrowing system's ability to
validate correct code and reject incorrect code. Unlike a test suite, systems
are not required to fully conform to If-T. Deviations are acceptable provided
they are justified by well-reasoned design considerations, such as compile-time
performance. **Approach:** If-T is guided by the literature on type narrowing,
the documentation of gradual languages such as TypeScript, and experiments with
typechecker implementations. We have identified a set of core technical
dimensions for type narrowing. For each dimension, the benchmark contains a set
of topics and (at least) two characterizing programs per topic: one that should
typecheck and one that should not typecheck. **Knowledge:** If-T provides a
baseline to measure type narrowing systems. For researchers, it provides
criteria to categorize future designs via its collection of positive and
negative examples. For language designers, the benchmark demonstrates the
payoff of typechecker complexity in terms of concrete examples. Designers can
use the examples to decide whether supporting a particular example is
worthwhile. Both the benchmark and its implementations are freely available
online. **Grounding:** We have implemented the benchmark for five typecheckers:
TypeScript, Flow, Typed Racket, mypy, and Pyright. The results highlight
important differences, such as the ability to track logical implications among
program variables and typechecking for user-defined narrowing predicates.
**Importance:** Type narrowing is essential for gradual type systems, but the
tradeoffs between systems with different complexity have been unclear. If-T
clarifies these tradeoffs by illustrating the benefits and limitations of each
level of complexity. With If-T as a way to assess implementations in a fair,
cross-language manner, future type system designs can strive for a better
balance among precision, annotation burden, and performance.

</details>


### [14] [A Type System for Data Privacy Compliance in Active Object Languages](https://arxiv.org/abs/2508.03831)
*Chinmayi Prabhu Baramashetru,Paola Giannini,Silvia Lizeth Tapia Tarifa,Olaf Owe*

Main category: cs.PL

TL;DR: This paper presents a new programming framework that systematically enforces GDPR privacy requirements using type systems and runtime checks, helping developers automate and verify data protection in software systems.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the difficulty of translating abstract privacy-by-design principles and data protection regulations, such as GDPR, into concrete and operationalized methods for software systems. There is a need for systematic and explicit support for GDPR compliance within programming languages and system architectures.

Method: The authors propose a language-based approach that combines static and runtime techniques, specifically using type checking and type inference within an active object language. The framework enables tracking of authorized data flows and automates the generation of runtime constraints based on user consent. The approach incorporates a type system for gathering compliance checks and monitoring changes to user consent, integrating privacy compliance verification into system execution. The feasibility is demonstrated with a soundness proof and example applications addressing GDPR requirements.

Result: The result is a language framework with a novel type system that supports the systematic and automated integration of GDPR compliance into system design. This includes tracking authorized data flows, enforcing user consent constraints, and addressing core GDPR principles like purpose limitation and data subject rights. Feasibility is proven by theoretical soundness and practical examples.

Conclusion: The paper concludes that its language-based approach significantly advances privacy-aware system design by making GDPR compliance an integral, automated, and verifiable part of programming languages. This paves the way for building trustworthy systems where data privacy is essential, particularly in sensitive domains like healthcare and finance.

Abstract: Data protection laws such as GDPR aim to give users unprecedented control
over their personal data. Compliance with these regulations requires
systematically considering information flow and interactions among entities
handling sensitive data. Privacy-by-design principles advocate embedding data
protection into system architectures as a default. However, translating these
abstract principles into concrete, explicit methods remains a significant
challenge. This paper addresses this gap by proposing a language-based approach
to privacy integration, combining static and runtime techniques. By employing
type checking and type inference in an active object language, the framework
enables the tracking of authorised data flows and the automatic generation of
constraints checked at runtime based on user consent. This ensures that
personal data is processed in compliance with GDPR constraints. The key
contribution of this work is a type system that gather the compliance checks
and the changes to users consent and integrates data privacy compliance
verification into system execution. The paper demonstrates the feasibility of
this approach through a soundness proof and several examples, illustrating how
the proposed language addresses common GDPR requirements, such as user consent,
purpose limitation, and data subject rights. This work advances the state of
the art in privacy-aware system design by offering a systematic and automated
method for integrating GDPR compliance into programming languages. This
capability has implications for building trustworthy systems in domains such as
healthcare or finance, where data privacy is crucial.

</details>


### [15] [Generating Inputs for Grammar Mining using Dynamic Symbolic Execution](https://arxiv.org/abs/2508.03832)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.PL

TL;DR: This paper introduces an automated input generation method for grammar mining, overcoming the lack of comprehensive input samples in real-world scenarios. By extending Dynamic Symbolic Execution and using a three-phase approach, it achieves high precision in extracting grammars, including edge cases, from software parsers, thus reducing manual effort and improving reconstruction of legacy system specifications.


<details>
  <summary>Details</summary>
Motivation: Software components that process structured input often lack updated or complete specifications due to continual evolution and modifications. Existing grammar mining methods depend heavily on the availability of comprehensive input samples, which are rare in practical scenarios, thus failing to reconstruct the full specification, especially missing edge cases or obsolete features. There is a need for an automated approach that can generate diverse and comprehensive input samples for grammar mining without manual intervention.

Method: The proposed method builds on the grammar miner Mimid and introduces a fully automated approach for input generation using Dynamic Symbolic Execution (DSE). This method incorporates two key innovations: (1) an iterative input expansion starting from a single character and gradually increasing complexity, and (2) a novel three-phase process for generating inputs specifically for parser functions. This approach aims to overcome the limitations of DSE for structured input parsers and is evaluated on eleven benchmark applications.

Result: The evaluation demonstrates that the proposed method achieves precision and recall in extracting grammars very close to leading grammar miners like Mimid, and importantly, it discovers subtle features and edge cases usually missed by existing methods. It performs well across different domains, and does not require any prior input samples. Empirical results verify its effectiveness, robustness, and scalability.

Conclusion: The work presents a fully automated and scalable input generation technique for grammar mining, significantly reducing manual effort while improving the comprehensiveness and accuracy of reconstructed grammars. This innovation helps researchers and software engineers recover specifications from legacy systems, enhancing robustness and efficiency in software engineering tasks.

Abstract: A vast number of software systems include components that parse and process
structured input. In addition to programming languages, which are analyzed by
compilers or interpreters, there are numerous components that process
standardized or proprietary data formats of varying complexity. Even if such
components were initially developed and tested based on a specification, such
as a grammar, numerous modifications and adaptations over the course of
software evolution can make it impossible to precisely determine which inputs
they actually accept. In this situation, grammar mining can be used to
reconstruct the specification in the form of a grammar. Established approaches
already produce useful results, provided that sufficient input data is
available to fully cover the input language. However, achieving this
completeness is a major challenge. In practice, only input data recorded during
the operation of the software systems is available. If this data is used for
grammar mining, the resulting grammar reflects only the actual processed inputs
but not the complete grammar of the input language accepted by the software
component. As a result, edge cases or previously supported features that no
longer appear in the available input data are missing from the generated
grammar. This work addresses this challenge by introducing a novel approach for
the automatic generation of inputs for grammar mining. Although input
generators have already been used for fuzz testing, it remains unclear whether
they are also suitable for grammar miners. Building on the grammar miner Mimid,
this work presents a fully automated approach to input generation. The approach
leverages Dynamic Symbolic Execution (DSE) and extends it with two mechanisms
to overcome the limitations of DSE regarding structured input parsers. First,
the search for new inputs is guided by an iterative expansion that starts with
a single-character input and gradually extends it. Second, input generation is
structured into a novel three-phase approach, which separates the generation of
inputs for parser functions. The proposed method was evaluated against a
diverse set of eleven benchmark applications from the existing literature.
Results demonstrate that the approach achieves precision and recall for
extracted grammars close to those derived from state-of-the-art grammar miners
such as Mimid. Notably, it successfully uncovers subtle features and edge cases
in parsers that are typically missed by such grammar miners. The effectiveness
of the method is supported by empirical evidence, showing that it can achieve
high performance in various domains without requiring prior input samples. This
contribution is significant for researchers and practitioners in software
engineering, offering an automated, scalable, and precise solution for grammar
mining. By eliminating the need for manual input generation, the approach not
only reduces workload but also enhances the robustness and comprehensiveness of
the extracted grammars. Following this approach, software engineers can
reconstruct specification from existing (legacy) parsers.

</details>


### [16] [Weak Memory Model Formalisms: Introduction and Survey](https://arxiv.org/abs/2508.04115)
*Roger C. Su,Robert J. Colvin*

Main category: cs.PL

TL;DR: This paper surveys formal approaches to weak memory models, discussing their specifications, reasoning tools, hardware implications, and theoretical advances. It provides an introduction to both operational and axiomatic representations, reviews historical and current developments, and points to ongoing research challenges in the field.


<details>
  <summary>Details</summary>
Motivation: Developers of safety- and security-critical, low-level software face significant challenges when dealing with weak memory effects in concurrent programming, as program order does not reliably represent execution order. Rigorous specifications of weak memory models are crucial to manage this complexity.

Method: This paper surveys the formalization of weak memory models by reviewing existing specifications, their effects on execution, and reasoning tools. It introduces two formal approaches—operational semantics (step-by-step traces) and axiomatic semantics (relations between memory events)—using simplified x86 architecture as an example. The paper also examines hardware features, historical developments, and computability/complexity results, with attention to current and future research directions.

Result: The survey compiles and elucidates various formalizations and reasoning approaches to weak memory models, clarifies hardware phenomena behind observable weak behaviors, and contextualizes theoretical and practical evolution in the field. It highlights the progress of formal tools and identifies outstanding challenges and research frontiers.

Conclusion: A rigorous and comprehensive understanding of weak memory models, their formal representations, reasoning tools, and practical consequences is fundamental for developers and researchers in safety- and security-critical software. This survey serves as a valuable reference by consolidating knowledge and outlining evolving directions in weak memory model research.

Abstract: Memory consistency models define the order in which accesses to shared memory
in a concurrent system may be observed to occur. Such models are a necessity
since program order is not a reliable indicator of execution order, due to
microarchitectural features or compiler transformations. Concurrent
programming, already a challenging task, is thus made even harder when weak
memory effects must be addressed. A rigorous specification of weak memory
models is therefore essential to make this problem tractable for developers of
safety- and security-critical, low-level software.
  In this paper we survey the field of formalisations of weak memory models,
including their specification, their effects on execution, and tools and
inference systems for reasoning about code. To assist the discussion we also
provide an introduction to two styles of formal representation found commonly
in the literature (using a much simplified version of Intel's x86 as the
example): a step-by-step construction of traces of the system (operational
semantics); and with respect to relations between memory events (axiomatic
semantics). The survey covers some long-standing hardware features that lead to
observable weak behaviours, a description of historical developments in
practice and in theory, an overview of computability and complexity results,
and outlines current and future directions in the field.

</details>
