<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 18]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM provides open-source LLMs and a dataset to automate and improve OpenACC directive generation for GPUs, making code offloading easier, more accurate, and reproducible.


<details>
  <summary>Details</summary>
Motivation: GPUs are widely used, but programming them remains complex even with directive-based standards like OpenACC, which still require significant expertise.

Method: The authors introduce ACCeLLiuM, two large language models (LLMs) specifically fine-tuned for generating OpenACC directives for data-parallel loops, trained using a supervised dataset of pragma-loop pairs collected from public GitHub C/C++ repositories.

Result: Experimental results show that LLMs fine-tuned on the ACCeLLiuM dataset generate valid OpenACC pragmas with the correct directive type for 87% of cases and exact matches for 50%, outperforming base LLMs. Generated pragmas often include correct or even more practical clauses than ground truth.

Conclusion: ACCeLLiuM, along with its models, code, and dataset, is released to encourage reproducibility and to facilitate automated GPU offloading via more accessible OpenACC pragma generation.

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [2] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: This paper systematically reviews and categorizes software security visualization techniques, underscoring the importance of innovative visual methods to address growing cybersecurity challenges.


<details>
  <summary>Details</summary>
Motivation: As software and the cybersecurity landscape become more complex, traditional analysis methods are insufficient. There’s a need for better visualization techniques to effectively interpret and respond to security threats.

Method: Systematic literature review of over 60 recent key papers, creating a taxonomy of software security visualization techniques (categorized into graph-based, notation-based, matrix-based, and metaphor-based methods).

Result: The paper categorizes existing visualization techniques, highlights two main focus areas (software development visualization and operational/cybersecurity visualization), and extracts current issues, recent advancements, and future research prospects.

Conclusion: Innovative and adaptive visualization techniques are crucial for effective security analysis. Improving these methods has practical benefits for threat detection, response, and guiding future research in software security visualization.

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [3] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: Dynamic ReAct lets ReAct agents handle thousands of tools without overloading memory, using smart selection methods to load only what's needed, halving required loading while still getting tasks done correctly.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the need for ReAct agents to work efficiently with large sets of tools (hundreds or thousands) provided via the Model Control Protocol (MCP), which exceed the memory capacity of current large language models. Loading all tools at once is computationally expensive and often impossible.

Method: The authors propose and evaluate five distinct architectures for tool selection, culminating in a 'search-and-load' mechanism. This process allows ReAct agents to intelligently select and dynamically load just the necessary tools from large sets, reducing memory and computational requirements.

Result: The approach results in a 50% reduction in tool loading compared to baseline methods, while maintaining task completion accuracy.

Conclusion: Dynamic ReAct enables general-purpose AI agents to dynamically adapt to various tasks and environments by efficiently managing tool selection and loading, even with extensive tool sets.

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [4] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: Current fairness problems in software are due to weak requirements specification. Paper proposes using knowledge graphs to formalize and verify fairness, anticipates challenges, and outlines future research directions.


<details>
  <summary>Details</summary>
Motivation: Motivated by the observation that discrimination in software often stems not only from algorithmic or data flaws, but also from insufficiently specified and verified fairness requirements, exacerbated by experts' implicit knowledge.

Method: The method proposed is the development and application of a knowledge graph-based framework to formalize fairness requirements and assist in their specification and verification.

Result: The result is primarily a conceptual contribution: identification of challenges and research questions related to fairness in software, and a roadmap for using knowledge graphs to formalize and verify fairness requirements.

Conclusion: The paper concludes that current approaches fail to sufficiently specify and verify fairness requirements in software systems, contributing to discrimination. It suggests a knowledge graph-based framework can help address this gap.

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [5] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: Online-Optimized RAG continually adapts retrieval embeddings using live feedback to fix mismatch problems, resulting in robust and improved performance in a range of real-world retrieval-augmented generation tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the embedding misalignment issue in RAG systems, resulting from imperfect embedding models or noisy tool/function descriptions, which can cause incorrect retrieval and task failures in practical applications.

Method: The proposed method applies lightweight, online gradient updates to retrieval embeddings at deployment time, using minimal feedback (such as task success), without any modification to the underlying large language model. It is designed to be plug-and-play and supports dynamic scenarios.

Result: Online-Optimized RAG consistently improves tool selection accuracy and the end-task success rate across a range of tool-use and document-retrieval settings.

Conclusion: The paper concludes that Online-Optimized RAG offers a robust and self-improving means of retrieval-augmented generation by continually adapting retrieval embeddings during deployment, leading to improved tool selection accuracy and end-task success.

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [6] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: The paper proposes a fully automated approach to verify legal contract programs written in Stipula by translating them into Java code and using the KeY tool for formal verification.


<details>
  <summary>Details</summary>
Motivation: Legal contracts, especially those involving asset transfers and obligations, require enforceable and correct implementation. The motivation is to provide formal, automated verification to ensure such contracts behave as intended, leveraging existing verification tools.

Method: Stipula code is automatically translated into Java code with embedded JML specifications. The KeY deductive verification tool is then used to verify partial and total correctness of the resulting Java code. The approach focuses on contracts with disjoint cycles for full automation.

Result: The paper introduces a methodology to formally verify programs written in Stipula, a domain-specific language for modeling legal contracts. The verification is achieved by translating Stipula contracts into Java annotated with Java Modeling Language (JML) specifications, and then using the KeY verification tool to check correctness. This process is fully automated for Stipula contracts with disjoint cycles.

Conclusion: The research shows that a general-purpose deductive verification tool like KeY can be effectively leveraged for formally verifying the correctness of Stipula contracts via a translation to Java.

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


### [7] [AI-Specific Code Smells: From Specification to Detection](https://arxiv.org/abs/2509.20491)
*Brahim Mahmoudi,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: The paper proposes SpecDetect4AI, a new tool for detecting AI-specific code smells using rule-based specification and static analysis, showing high accuracy and outperforming previous tools on large-scale AI software.


<details>
  <summary>Details</summary>
Motivation: Traditional code smell detection tools miss issues specific to AI-based systems, such as problems affecting reproducibility and model generalization.

Method: The authors introduced SpecDetect4AI, using a declarative domain-specific language for specifying code smell rules and an extensible static analysis tool for detection.

Result: SpecDetect4AI successfully specified 22 AI-specific code smells and achieved high precision (88.66%) and recall (88.89%) in detecting them on 826 systems, outperforming existing tools.

Conclusion: SpecDetect4AI efficiently and extensibly detects AI-specific code smells at scale, aiding in the analysis and maintenance of large AI-based systems.

Abstract: The rise of Artificial Intelligence (AI) is reshaping how software systems
are developed and maintained. However, AI-based systems give rise to new
software issues that existing detection tools often miss. Among these, we focus
on AI-specific code smells, recurring patterns in the code that may indicate
deeper problems such as unreproducibility, silent failures, or poor model
generalization. We introduce SpecDetect4AI, a tool-based approach for the
specification and detection of these code smells at scale. This approach
combines a high-level declarative Domain-Specific Language (DSL) for rule
specification with an extensible static analysis tool that interprets and
detects these rules for AI-based systems. We specified 22 AI-specific code
smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code),
achieving a precision of 88.66% and a recall of 88.89%, outperforming other
existing detection tools. Our results show that SpecDetect4AI supports the
specification and detection of AI-specific code smells through dedicated rules
and can effectively analyze large AI-based systems, demonstrating both
efficiency and extensibility (SUS 81.7/100).

</details>


### [8] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: A novel AI-chatbot significantly improves student learning and debugging in programming, outperforming traditional tools by combining code analysis, execution tracing, and LLMs. It enhances proficiency and engagement, illustrating how AI can foster deeper understanding, not just code completion.


<details>
  <summary>Details</summary>
Motivation: Traditional programming tools, like IDEs and static code analyzers, do not provide interactive or adaptive support for students learning to code. AI-driven code assistants focus on task completion, rather than promoting learning or conceptual understanding. There is a gap in providing pedagogically effective, AI-driven support tailored to fostering students' programming skills.

Method: A hybrid architecture chatbot was developed, integrating CodeLlama for code embedding, GPT-4 for natural language processing, and Docker-based sandboxing for secure execution. The system was evaluated using a mixed-methods approach: 1,500 student submissions for quantitative performance tests, pre- and post-test coding proficiency assessments, and qualitative student feedback from 120 participants.

Result: The chatbot achieved an 85% error resolution success rate, outperforming standalone tools like pylint (62%) and GPT-4 (73%) individually. Users experienced a 59.3% reduction in debugging time. Pre/post-assessment showed a 34% improvement in coding proficiency, notably in recursion and exception handling skills. Qualitative feedback highlighted increased clarity, accessibility, and confidence, with some critiques regarding latency and code sanitization restrictions.

Conclusion: The AI-Python-based chatbot effectively bridges the gap between code completion and pedagogy, promoting deeper learning and skill retention. Its technical innovation and educational focus offer a blueprint for future AI tools in programming education, emphasizing equity and sustainable skill development over simple task automation.

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [9] [PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects](https://arxiv.org/abs/2509.20497)
*Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: This paper analyzes technical debt in Python projects using LLM APIs, finding prompt design—especially instruction-based and few-shot prompts—is the main source. OpenAI integrations account for most SATD. The authors release a dataset and offer guidance for reducing LLM-related debt.


<details>
  <summary>Details</summary>
Motivation: With the rise of LLM integrations in software via APIs, developers face unique forms of technical debt, especially related to prompt design and LLM configuration. Understanding their prevalence and causes is crucial to improving software quality and maintainability.

Method: The authors conducted a large-scale empirical study by analyzing 93,142 Python files involving major LLM APIs. They quantified SATD origins, prevalence, and mitigation, focusing on prompt techniques and configuration issues.

Result: 54.49% of SATD stems from OpenAI API usage, and 12.35% from LangChain. Prompt design is the top SATD contributor, with notable issues in instruction-based (38.60%) and few-shot (18.13%) prompt types. The study presents a SATD dataset and guidelines for managing LLM-specific debt.

Conclusion: A significant proportion of self-admitted technical debt (SATD) in Python projects using LLM APIs originates from prompt design and configuration, especially with OpenAI integrations. Instruction-based and few-shot prompts are the most susceptible to SATD. The paper also provides a public dataset and practical guidance to help developers address SATD in LLM-powered systems.

Abstract: Large Language Models (LLMs) are increasingly embedded in software via APIs
like OpenAI, offering powerful AI features without heavy infrastructure. Yet
these integrations bring their own form of self-admitted technical debt (SATD).
In this paper, we present the first large-scale empirical study of LLM-specific
SATD: its origins, prevalence, and mitigation strategies. By analyzing 93,142
Python files across major LLM APIs, we found that 54.49% of SATD instances stem
from OpenAI integrations and 12.35% from LangChain use. Prompt design emerged
as the primary source of LLM-specific SATD, with 6.61% of debt related to
prompt configuration and optimization issues, followed by hyperparameter tuning
and LLM-framework integration. We further explored which prompt techniques
attract the most debt, revealing that instruction-based prompts (38.60%) and
few-shot prompts (18.13%) are particularly vulnerable due to their dependence
on instruction clarity and example quality. Finally, we release a comprehensive
SATD dataset to support reproducibility and offer practical guidance for
managing technical debt in LLM-powered systems.

</details>


### [10] [Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2509.20552)
*Xinyu Shi,Zhenhao Li,An Ran Chen*

Main category: cs.SE

TL;DR: FaR-Loc is a new LLM+retrieval framework for method-level fault localization in software. It beats existing approaches in accuracy and doesn't need retraining, especially benefiting from code structure-aware models like UniXcoder.


<details>
  <summary>Details</summary>
Motivation: Fault localization is essential but challenging in software debugging, especially for complex projects where large language models (LLMs) lack project-specific context and struggle with code navigation.

Method: The paper introduces FaR-Loc, a framework integrating LLMs with retrieval-augmented generation. It has three steps: (1) LLM Functionality Extraction to produce a natural language description of failing behavior; (2) Semantic Dense Retrieval to embed and match the description and code methods using a code-understanding encoder; (3) LLM Re-ranking to reorder retrieved candidates based on context relevance.

Result: FaR-Loc surpasses current LLM-based baselines (SoapFL and AutoFL) with improvements of up to 14.6% (Top-1) and 22.1% (Top-5) accuracy. It also outperforms learning-based and spectrum-based methods in all Top-N metrics without retraining. Using structured code embedding models like UniXcoder further boosts performance up to 49% in Top-1 accuracy.

Conclusion: The study demonstrates that combining LLMs with semantic retrieval significantly advances method-level fault localization. The approach is effective, efficient, and practical—especially with strong code embedding models—providing a valuable tool for software debugging.

Abstract: Fault localization (FL) is a critical but time-consuming task in software
debugging, aiming to identify faulty code elements. While recent advances in
large language models (LLMs) have shown promise for FL, they often struggle
with complex systems due to the lack of project-specific knowledge and the
difficulty of navigating large projects. To address these limitations, we
propose FaR-Loc, a novel framework that enhances method-level FL by integrating
LLMs with retrieval-augmented generation (RAG). FaR-Loc consists of three key
components: LLM Functionality Extraction, Semantic Dense Retrieval, and LLM
Re-ranking. First, given a failed test and its associated stack trace, the LLM
Functionality Extraction module generates a concise natural language
description that captures the failing behavior. Next, the Semantic Dense
Retrieval component leverages a pre-trained code-understanding encoder to embed
both the functionality description (natural language) and the covered methods
(code) into a shared semantic space, enabling the retrieval of methods with
similar functional behavior. Finally, the LLM Re-ranking module reorders the
retrieved methods based on their contextual relevance. Our experiments on the
widely used Defects4J benchmark show that FaR-Loc outperforms state-of-the-art
LLM-based baselines SoapFL and AutoFL, by 14.6% and 9.1% in Top-1 accuracy, by
19.2% and 22.1% in Top-5 accuracy, respectively. It also surpasses all
learning-based and spectrum-based baselines across all Top-N metrics without
requiring re-training. Furthermore, we find that pre-trained code embedding
models that incorporate code structure, such as UniXcoder, can significantly
improve fault localization performance by up to 49.0% in Top-1 accuracy.
Finally, we conduct a case study to illustrate the effectiveness of FaR-Loc and
to provide insights for its practical application.

</details>


### [11] [Design, Implementation and Evaluation of a Novel Programming Language Topic Classification Workflow](https://arxiv.org/abs/2509.20631)
*Michael Zhang,Yuan Tian,Mariam Guizani*

Main category: cs.SE

TL;DR: The paper introduces a high-performing SVM-based workflow for classifying and localizing programming language topics in source code, with strong results on a large dataset, offering valuable tools and insights for code analysis and software engineering.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the increasing scale and complexity of software systems, which necessitates a deeper understanding of how various programming language topics are distributed within source code. Such understanding is vital for guiding technical decisions, simplifying onboarding processes, and improving tooling and educational resources.

Method: The paper proposes a novel workflow for programming language topic classification using a multi-label Support Vector Machine (SVM) combined with a sliding window and voting strategy. This design enables fine-grained localization of language concepts within source code. The workflow is trained and evaluated using the IBM Project CodeNet dataset.

Result: The proposed model achieves an average F1 score of 0.90 for general topic classification and 0.75 in code-topic highlighting, indicating high accuracy and effective localization capabilities.

Conclusion: The research offers both empirical insights and a reusable classification pipeline, which can benefit researchers and practitioners interested in code analysis and data-driven software engineering.

Abstract: As software systems grow in scale and complexity, understanding the
distribution of programming language topics within source code becomes
increasingly important for guiding technical decisions, improving onboarding,
and informing tooling and education. This paper presents the design,
implementation, and evaluation of a novel programming language topic
classification workflow. Our approach combines a multi-label Support Vector
Machine (SVM) with a sliding window and voting strategy to enable fine-grained
localization of core language concepts such as operator overloading, virtual
functions, inheritance, and templates. Trained on the IBM Project CodeNet
dataset, our model achieves an average F1 score of 0.90 across topics and 0.75
in code-topic highlight. Our findings contribute empirical insights and a
reusable pipeline for researchers and practitioners interested in code analysis
and data-driven software engineering.

</details>


### [12] [Exploring Engagement in Hybrid Meetings](https://arxiv.org/abs/2509.20780)
*Daniela Grassi,Fabio Calefato,Darja Smite,Nicole Novielli,Filippo Lanubile*

Main category: cs.SE

TL;DR: Hybrid software meetings show similar engagement for onsite and remote members, but long, large, and afternoon meetings lower engagement—especially for remote workers. Active involvement improves engagement. The findings guide how hybrid meetings can be better managed in tech and knowledge-driven sectors.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper stems from the widespread transformation of software development practices due to the shift toward hybrid work models after COVID-19. As organizations adapt to hybrid structures, new challenges in communication and collaboration arise, particularly the risk of isolation and disengagement among remote team members in hybrid meetings.

Method: The study used a multimodal approach to measure engagement in hybrid meetings among professionals at three software companies over several weeks. Data were gathered using both self-reported questionnaires and physiological measurements via biometric devices during meetings to objectively assess engagement dynamics.

Result: Regression analyses indicated that on-site and remote participants generally maintained similar levels of engagement. However, engagement among remote participants decreased in longer meetings regardless of whether they were remote or in-person. Active participation increased engagement, but larger attendance and afternoon meetings saw decreased engagement.

Conclusion: The research provides key insights into the factors influencing engagement and disengagement in hybrid meetings, offering actionable recommendations for improving meeting effectiveness. These findings hold relevance not just for software teams but for all knowledge-intense organizations adapting to hybrid work environments.

Abstract: Background. The widespread adoption of hybrid work following the COVID-19
pandemic has fundamentally transformed software development practices,
introducing new challenges in communication and collaboration as organizations
transition from traditional office-based structures to flexible working
arrangements. This shift has established a new organizational norm where even
traditionally office-first companies now embrace hybrid team structures. While
remote participation in meetings has become commonplace in this new
environment, it may lead to isolation, alienation, and decreased engagement
among remote team members. Aims. This study aims to identify and characterize
engagement patterns in hybrid meetings through objective measurements, focusing
on the differences between co-located and remote participants. Method. We
studied professionals from three software companies over several weeks,
employing a multimodal approach to measure engagement. Data were collected
through self-reported questionnaires and physiological measurements using
biometric devices during hybrid meetings to understand engagement dynamics.
Results. The regression analyses revealed comparable engagement levels between
onsite and remote participants, though remote participants show lower
engagement in long meetings regardless of participation mode. Active roles
positively correlate with higher engagement, while larger meetings and
afternoon sessions are associated with lower engagement. Conclusions. Our
results offer insights into factors associated with engagement and
disengagement in hybrid meetings, as well as potential meeting improvement
recommendations. These insights are potentially relevant not only for software
teams but also for knowledge-intensive organizations across various sectors
facing similar hybrid collaboration challenges.

</details>


### [13] [Verification Limits Code LLM Training](https://arxiv.org/abs/2509.20837)
*Srishti Gureja,Elena Tommasone,Jingyi He,Sara Hooker,Matthias Gallé,Marzieh Fadaee*

Main category: cs.SE

TL;DR: This paper shows that strict verification practices limit code generation model performance by filtering out diverse, correct solutions. By using richer tests and relaxed criteria, training data quality and model performance improve. Verification is necessary but must be recalibrated to unlock stronger models.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) for code generation increasingly use synthetic data generated by models for training. The process is scalable but faces a bottleneck: the verification ceiling, where the quality and diversity of training data are limited by the synthetic verifiers’ capability. This paper aims to analyze and address how verification practices impact code generation performance.

Method: The authors systematically study the design and strategies of verification in synthetic data generation for coding LLMs. They analyze test suite complexity, the quantity of test cases, the impact of rigid versus relaxed pass criteria, and the necessity of verification by comparing formally correct/incorrect solutions and human evaluation.

Result: They find that richer and more complex test suites improve code generation (average +3 pass@1), while simply increasing the number of tests has diminishing returns. Loosening rigid 100% pass criteria by using relaxed or LLM-based soft verification recovers valuable data, yielding 2–4 point improvements in pass@1. However, the gains depend on the diversity and strength of test cases. Furthermore, retaining diverse correct solutions per problem yields generalization benefits.

Conclusion: Current verification practices for training data in code generation models are too rigid and filter out valuable, diverse solutions. Verification remains essential, but should be recalibrated via more nuanced and diverse approaches to break the performance ceiling of code generation models.

Abstract: Large language models for code generation increasingly rely on synthetic
data, where both problem solutions and verification tests are generated by
models. While this enables scalable data creation, it introduces a previously
unexplored bottleneck: the verification ceiling, in which the quality and
diversity of training data are fundamentally constrained by the capabilities of
synthetic verifiers. In this work, we systematically study how verification
design and strategies influence model performance. We investigate (i) what we
verify by analyzing the impact of test complexity and quantity: richer test
suites improve code generation capabilities (on average +3 pass@1), while
quantity alone yields diminishing returns, (ii) how we verify by exploring
relaxed pass thresholds: rigid 100% pass criteria can be overly restrictive. By
allowing for relaxed thresholds or incorporating LLM-based soft verification,
we can recover valuable training data, leading to a 2-4 point improvement in
pass@1 performance. However, this benefit is contingent upon the strength and
diversity of the test cases used, and (iii) why verification remains necessary
through controlled comparisons of formally correct versus incorrect solutions
and human evaluation: retaining diverse correct solutions per problem yields
consistent generalization gains. Our results show that Verification as
currently practiced is too rigid, filtering out valuable diversity. But it
cannot be discarded, only recalibrated. By combining calibrated verification
with diverse, challenging problem-solution pairs, we outline a path to break
the verification ceiling and unlock stronger code generation models.

</details>


### [14] [PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval](https://arxiv.org/abs/2509.20881)
*Yixuan Li,Xinyi Liu,Weidong Yang,Ben Fei,Shuhao Li,Mingjie Zhou,Lipeng Ma*

Main category: cs.SE

TL;DR: PseudoBridge introduces a novel code search framework using pseudo-code for logical alignment of NL queries and code, coupled with style-invariant augmentation. It achieves significant accuracy gains and generalizes well across languages and domains, surpassing previous approaches, especially in zero-shot scenarios.


<details>
  <summary>Details</summary>
Motivation: Current PLM-based code search methods struggle with the semantic gap between human intent and code execution, and their robustness to code style diversity is limited. The motivation is to provide a more precise and robust approach to align NL queries with code, enabling better retrieval across diverse programming scenarios.

Method: PseudoBridge uses a two-stage process: (1) Large Language Models generate pseudo-code to explicitly align natural language queries with code logic; (2) It augments data by generating logically equivalent code snippets in diverse styles, improving robustness against code variation and aligning them with pseudo-code across multiple PLMs.

Result: PseudoBridge, evaluated across 10 PLMs and 6 languages, achieves superior retrieval accuracy and generalization compared to baselines, particularly excelling in zero-shot domain transfer tasks (e.g., Solidity, XLCoST). The method proves effective in logical alignment and robustness to code style variation.

Conclusion: PseudoBridge significantly improves code retrieval performance and generalization through explicit alignment between natural language and code logic using pseudo-code, outperforming existing methods and demonstrating strong results under zero-shot scenarios.

Abstract: Code search aims to precisely find relevant code snippets that match natural
language queries within massive codebases, playing a vital role in software
development. Recent advances leverage pre-trained language models (PLMs) to
bridge the semantic gap between unstructured natural language (NL) and
structured programming languages (PL), yielding significant improvements over
traditional information retrieval and early deep learning approaches. However,
existing PLM-based methods still encounter key challenges, including a
fundamental semantic gap between human intent and machine execution logic, as
well as limited robustness to diverse code styles. To address these issues, we
propose PseudoBridge, a novel code retrieval framework that introduces
pseudo-code as an intermediate, semi-structured modality to better align NL
semantics with PL logic. Specifically, PseudoBridge consists of two stages.
First, we employ an advanced large language model (LLM) to synthesize
pseudo-code, enabling explicit alignment between NL queries and pseudo-code.
Second, we introduce a logic-invariant code style augmentation strategy and
employ the LLM to generate stylistically diverse yet logically equivalent code
implementations with pseudo-code, then align the code snippets of different
styles with pseudo-code, enhancing model robustness to code style variation. We
build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream
programming languages. Extensive experiments demonstrate that PseudoBridge
consistently outperforms baselines, achieving significant gains in retrieval
accuracy and generalization, particularly under zero-shot domain transfer
scenarios such as Solidity and XLCoST datasets. These results demonstrate the
effectiveness of explicit logical alignment via pseudo-code and highlight
PseudoBridge's potential as a robust, generalizable solution for code
retrieval.

</details>


### [15] [Designing for Novice Debuggers: A Pilot Study on an AI-Assisted Debugging Tool](https://arxiv.org/abs/2509.21067)
*Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel*

Main category: cs.SE

TL;DR: The paper introduces 'CodeHinter', a debugging tool for students that blends traditional and AI-based methods to promote active learning. Testing confirmed it helps fix semantic errors and is user-friendly, and personalization is key for best results.


<details>
  <summary>Details</summary>
Motivation: Novice programmers often struggle with debugging, and while many AI tools can generate code fixes, they may encourage passivity rather than active learning and skill development. The authors aim to design a tool that both helps correct errors and promotes student engagement in the debugging process.

Method: The authors developed 'CodeHinter', an intuitive debugging assistant that merges traditional debugging techniques with LLM-based (large language model) approaches. They iteratively designed and improved the tool, testing this second version with undergraduate students, and gathered feedback regarding its usability and effectiveness.

Result: The revised tool was found by students to be highly effective at resolving semantic errors and was regarded as significantly easier to use than its prior version. Error localization remained the most appreciated feature among students.

Conclusion: Personalization of AI-assisted debugging tools to individual user profiles is essential for optimizing student interactions and maximizing the effectiveness of such tools in novice programming education.

Abstract: Debugging is a fundamental skill that novice programmers must develop.
Numerous tools have been created to assist novice programmers in this process.
Recently, large language models (LLMs) have been integrated with automated
program repair techniques to generate fixes for students' buggy code. However,
many of these tools foster an over-reliance on AI and do not actively engage
students in the debugging process. In this work, we aim to design an intuitive
debugging assistant, CodeHinter, that combines traditional debugging tools with
LLM-based techniques to help novice debuggers fix semantic errors while
promoting active engagement in the debugging process. We present findings from
our second design iteration, which we tested with a group of undergraduate
students. Our results indicate that the students found the tool highly
effective in resolving semantic errors and significantly easier to use than the
first version. Consistent with our previous study, error localization was the
most valuable feature. Finally, we conclude that any AI-assisted debugging tool
should be personalized based on user profiles to optimize their interactions
with students.

</details>


### [16] [An Improved Quantum Software Challenges Classification Approach using Transfer Learning and Explainable AI](https://arxiv.org/abs/2509.21068)
*Nek Dil Khan,Javed Ali Khan,Mobashir Husain,Muhammad Sohail Khan,Arif Ali Khan,Muhammad Azeem Akbar,Shahid Hussain*

Main category: cs.SE

TL;DR: The paper analyzes quantum computing Q&A posts and successfully classifies them into challenge types using state-of-the-art transformer models, achieving higher accuracy and better interpretability than traditional methods, potentially improving the organization of quantum developer discussions online.


<details>
  <summary>Details</summary>
Motivation: Quantum software engineering (QSE) faces distinct technical challenges, yet Stack Overflow and similar forums do not categorize discussions well according to these specific challenge types. Better classification can aid in understanding and addressing common issues faced by quantum developers.

Method: The authors collected and analyzed 2829 Q&A posts tagged with quantum-related concepts from online platforms. Posts were categorized based on frequent QSE challenges using content analysis and grounded theory. Annotations were validated by both humans and ChatGPT. Multiple machine learning models, including fine-tuned transformers (BERT, DistilBERT, RoBERTa) and traditional neural networks (FNN, CNN, LSTM), were trained to automatically classify these challenges. SHAP was used for interpreting model predictions.

Result: Transformer-based models, especially BERT and DistilBERT, achieved superior accuracy (95%) compared to traditional D&ML models (FNN: 89%, CNN: 86%, LSTM: 84%). The transformer approach outperformed others by 6% and worked well without data augmentation. SHAP analysis provided insights into feature influence on predictions.

Conclusion: Classifying quantum software engineering questions by challenge type using transformer models is highly effective and interpretable. This improves organization and accessibility of QSE discussions online. Future developer-centered empirical studies are recommended for further validation.

Abstract: Quantum Software Engineering (QSE) is a research area practiced by tech
firms. Quantum developers face challenges in optimizing quantum computing and
QSE concepts. They use Stack Overflow (SO) to discuss challenges and label
posts with specialized quantum tags, which often refer to technical aspects
rather than developer posts. Categorizing questions based on quantum concepts
can help identify frequent QSE challenges. We conducted studies to classify
questions into various challenges. We extracted 2829 questions from Q&A
platforms using quantum-related tags. Posts were analyzed to identify frequent
challenges and develop a novel grounded theory. Challenges include Tooling,
Theoretical, Learning, Conceptual, Errors, and API Usage. Through content
analysis and grounded theory, discussions were annotated with common challenges
to develop a ground truth dataset. ChatGPT validated human annotations and
resolved disagreements. Fine-tuned transformer algorithms, including BERT,
DistilBERT, and RoBERTa, classified discussions into common challenges. We
achieved an average accuracy of 95% with BERT DistilBERT, compared to
fine-tuned Deep and Machine Learning (D&ML) classifiers, including Feedforward
Neural Networks (FNN), Convolutional Neural Networks (CNN), and Long Short-Term
Memory networks (LSTM), which achieved accuracies of 89%, 86%, and 84%,
respectively. The Transformer-based approach outperforms the D&ML-based
approach with a 6\% increase in accuracy by processing actual discussions,
i.e., without data augmentation. We applied SHAP (SHapley Additive
exPlanations) for model interpretability, revealing how linguistic features
drive predictions and enhancing transparency in classification. These findings
can help quantum vendors and forums better organize discussions for improved
access and readability. However,empirical evaluation studies with actual
developers and vendors are needed.

</details>


### [17] [Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach](https://arxiv.org/abs/2509.21170)
*Yongda Yu,Guohao Shi,Xianwei Wu,Haochuan He,XueMing Gu,Qianqian Zhao,Kui Liu,Qiushi Wang,Zhao Tian,Haifeng Shen,Guoping Rong*

Main category: cs.SE

TL;DR: MelcotCR is a novel fine-tuning method that equips LLMs with advanced multidimensional reasoning for code review, allowing smaller models to outperform or equal much larger ones using structured chain-of-thought prompts and improved logic retention.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) exhibit great promise for automated code review, but still fall short compared to human reviewers in multidimensional analysis, partly due to limited or vague fine-tuning data. The authors are motivated to enhance LLMs’ capabilities by improving their reasoning and context management during code review.

Method: The paper introduces MelcotCR, a chain-of-thought (COT) fine-tuning approach that leverages long COT techniques for richer, structured input, and combines Maximum Entropy modeling with pre-defined reasoning paths to address context and logical reasoning loss.

Result: Experiments on both a new MelcotCR dataset and the public CodeReviewer dataset show that a relatively small LLM, such as the 14B Qwen2.5 model fine-tuned with MelcotCR, outperforms existing state-of-the-art methods and matches the performance of a much larger 671B model (DeepSeek-R1) in identifying and describing code issues.

Conclusion: MelcotCR significantly boosts LLM reasoning for code review, enabling low-parameter models to match or surpass much larger models in code issue detection and description accuracy by leveraging robust COT fine-tuning and advanced reasoning techniques.

Abstract: Large Language Models (LLMs) have shown great potential in supporting
automated code review due to their impressive capabilities in context
understanding and reasoning. However, these capabilities are still limited
compared to human-level cognition because they are heavily influenced by the
training data. Recent research has demonstrated significantly improved
performance through fine-tuning LLMs with code review data. However, compared
to human reviewers who often simultaneously analyze multiple dimensions of code
review to better identify issues, the full potential of these methods is
hampered by the limited or vague information used to fine-tune the models. This
paper contributes MelcotCR, a chain-of-thought (COT) fine-tuning approach that
trains LLMs with an impressive reasoning ability to analyze multiple dimensions
of code review by harnessing long COT techniques to provide rich structured
information. To address context loss and reasoning logic loss issues that
frequently occur when LLMs process long COT prompts, we propose a solution that
combines the Maximum Entropy (ME) modeling principle with pre-defined reasoning
pathways in MelcotCR to enable more effective utilization of in-context
knowledge within long COT prompts while strengthening the logical tightness of
the reasoning process. Empirical evaluations on our curated MelcotCR dataset
and the public CodeReviewer dataset reveal that a low-parameter base model,
such as 14B Qwen2.5, fine-tuned with MelcotCR can surpass state-of-the-art
methods in terms of the accuracy of detecting and describing code issues, with
its performance remarkably on par with that of the 671B DeepSeek-R1 model.

</details>


### [18] [Semantic Clustering of Civic Proposals: A Case Study on Brazil's National Participation Platform](https://arxiv.org/abs/2509.21292)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: A novel topic-modeling approach using BERTopic, seed words, and LLMs can efficiently organize citizen input from digital platforms, making it easier for governments to use this data for policy decisions with minimal manual effort.


<details>
  <summary>Details</summary>
Motivation: Governments want to promote citizen participation through digital platforms, but face challenges in organizing and utilizing the large volume of contributions. Manual classification is not scalable, requires expert involvement, and must be in line with official taxonomies.

Method: The authors propose an approach that combines BERTopic (a topic modeling technique), seed words, and automatic validation using large language models to classify and organize contributions from digital platforms.

Result: The initial results suggest that the proposed method produces coherent topics that align well with institutional needs, and significantly reduces the need for human effort.

Conclusion: The methodology allows governments to efficiently convert vast amounts of citizen input into actionable data for policymaking, addressing key scalability and alignment challenges.

Abstract: Promoting participation on digital platforms such as Brasil Participativo has
emerged as a top priority for governments worldwide. However, due to the sheer
volume of contributions, much of this engagement goes underutilized, as
organizing it presents significant challenges: (1) manual classification is
unfeasible at scale; (2) expert involvement is required; and (3) alignment with
official taxonomies is necessary. In this paper, we introduce an approach that
combines BERTopic with seed words and automatic validation by large language
models. Initial results indicate that the generated topics are coherent and
institutionally aligned, with minimal human effort. This methodology enables
governments to transform large volumes of citizen input into actionable data
for public policy.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [19] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: This paper presents the creation of PWCT2, a dual-language, self-hosting visual programming language built with the new Ring language. PWCT2 is faster, more efficient, and more user-friendly than earlier VPLs, with successful real-world adoption.


<details>
  <summary>Details</summary>
Motivation: Most visual programming languages (VPLs) are domain-specific and require textual programming for development and improvement. The motivation is to create a general-purpose VPL that is self-hosting, eliminating the need for separate textual programming and supporting both Arabic and English.

Method: Developed a new textual programming language, Ring, which is dynamically typed and customizable. Used the existing PWCT VPL to visually implement the Ring Compiler and Virtual Machine. PWCT2, the new VPL, was developed using Ring and is capable of self-hosting, supporting code conversion between textual and visual formats.

Result: PWCT2 generated code about 36 times faster and required 20 times less visual source file storage than its predecessor. PWCT2 consists of roughly 92,000 lines of Ring code and 394 visual components, with strong adoption on Steam: 1772 users and over 17,000 recorded hours of use.

Conclusion: PWCT2 achieves significant improvements over previous VPLs in terms of performance, storage efficiency, and usability. It empowers users to develop and enhance the language visually, advancing general-purpose VPL design and adoption.

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [20] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: This paper integrates hash consing (a duplication-avoiding technique) into JuliaSymbolics, significantly boosting performance and reducing memory usage for symbolic computation, especially for large-scale and complex expressions.


<details>
  <summary>Details</summary>
Motivation: Symbolic computation systems face severe memory inefficiencies because they redundantly store structurally identical subexpressions (expression swell), impacting performance in both traditional and AI-based mathematical tools.

Method: The paper integrates hash consing—a technique that canonicalizes and shares identical expressions—into JuliaSymbolics using a global weak-reference hash table to eliminate duplication while ensuring compatibility with Julia's metaprogramming and just-in-time compilation systems.

Result: Benchmarks show that with hash consing, symbolic computations in JuliaSymbolics are up to 3.2 times faster, memory usage is halved, code generation is up to 5 times faster, function compilation up to 10 times faster, and numerical evaluation up to 100 times faster for larger models. The gains are less pronounced for workloads with fewer duplicate expressions but downstream steps always benefit.

Conclusion: Integrating hash consing into JuliaSymbolics greatly reduces memory consumption and boosts performance across many symbolic tasks. This enables scaling symbolic computation and provides a foundation for future improvements such as e-graph synergy in AI-driven mathematical reasoning.

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>
